<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python-os学习笔记]]></title>
    <url>%2Fz_post%2FPython-os%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python-matplotlib学习笔记]]></title>
    <url>%2Fz_post%2FPython-matplotlib%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基础知识Matplotlib是一个Python 2D绘图库，可以在各种平台上以各种硬拷贝格式和交互式环境生成出版质量数据。Matplotlib可用于Python脚本，Python和IPython shell，jupyter笔记本，Web应用程序服务器和四个图形用户界面工具。 matplotlib画板一般由以下部分组成 创建了subplot后, 如果发出绘图指令，matplotlib这时就会在你最后一个用过的subplot中（没有则创建）绘制. 12345678910111213141516171819202122232425import matplotlib.pyplot as pltimport numpy as np# 多个figurex = np.linspace(-1, 1, 50)y1 = 2*x + 1y2 = 2**x + 1# 使用figure()函数重新申请一个figure对象# 注意，每次调用figure的时候都会重新申请一个figure对象plt.figure()# 第一个是横坐标的值，第二个是纵坐标的值plt.plot(x, y1)# 第一个参数表示的是编号，第二个表示的是图表的长宽plt.figure(num = 3, figsize=(8, 5))# 当我们需要在画板中绘制两条线的时候，可以使用下面的方法：plt.plot(x, y2)plt.plot(x, y1, color='red', # 线颜色 linewidth=1.0, # 线宽 linestyle='--' # 线样式 )plt.show() # 会将所有的figure对象显示出来, 这里有2个 2D图表风格散点图12matplotlib.pyplot.scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None,alpha=None, linewidths=None, verts=None, edgecolors=None, hold=None, data=None, ** kwargs) 参数说明: x/y: 一维向量, 且长度相等 s: 标记大小, 以平方磅为单位的标记面积，指定为下列形式之一： 数值标量 ： 以相同的大小绘制所有标记。 行或列向量 ： 使每个标记具有不同的大小。x、y 和 sz 中的相应元素确定每个标记的位置和面积。sz 的长度必须等于 x 和 y 的长度。 [] ： 使用 36 平方磅的默认面积 c: 标记颜色, 指定为下列形式之一: RGB 三元数或颜色名称 - 使用相同的颜色绘制所有标记。 由 RGB 三元数组成的三列矩阵 - 对每个标记使用不同的颜色。矩阵的每行为对应标记指定一种 RGB 三元数颜色。行数必须等于 x 和 y 的长度。 向量 - 对每个标记使用不同的颜色，并以线性方式将 c 中的值映射到当前颜色图中的颜色。c 的长度必须等于 x 和 y 的长度。要更改坐标区的颜色图，请使用 colormap 函数 marker: 标记样式 linewidths: 线宽 颜色种类 样式种类 直方图 hist12matplotlib.pyplot.hist(x, bins=10, range=None, normed=False, weights=None, cumulative=False, bottom=None, histtype=u'bar', align=u'mid', orientation=u'vertical', rwidth=None, log=False, color=None, label=None, stacked=False, hold=None, **kwargs) 参数说明: x: 横轴对应的数据 bins: 指定条状图的条形个数 range: 横轴的范围, 默认为数据最小和最大的值作为范围 normed: 默认为False, 纵轴表示频数, 如果置为True, 则纵轴表示频率 rwidth: 条状图柱子与柱子之间的距离, 默认为0 饼状图 pie]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python-skimage学习笔记]]></title>
    <url>%2Fz_post%2FPython-skimage%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python-opencv学习笔记]]></title>
    <url>%2Fz_post%2FPython-opencv%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[opencv 基础知识opencv与numpyopencv的基础类型为numpy.ndarray, 因此可以直接使用 ndarray 的一些属性的方法 1234import cv2image = cv2.imread('./test.jpg')print(type(image) #&lt;class 'numpy.ndarray'&gt;print(image.shape) #(500, 1069, 3) (高, 宽, 通道), 利用 cv2.merge 方法将 numpy.ndarray 数据转换成opencv的图片数据: 123456789101112# 图片的分辨率为300*200(宽*高)，这里b, g, r设为随机值，注意dtype属性b = np.random.randint(0, 255, (200, 300), dtype=np.uint8)g = np.random.randint(0, 255, (200, 300), dtype=np.uint8)r = np.random.randint(0, 255, (200, 300), dtype=np.uint8)# 合并通道，形成图片img = cv2.merge([b, g, r]) # opencv的通道是b在最前,r在最后# 显示图片cv2.imshow('test', img)cv2.waitKey(0)cv2.destroyWindow('test') opencv 基本图像操作通道的拆分与合并12345678910111213141516# 图片的分辨率为800*200(宽*高)，这里b, g, r设为随机值，注意dtype属性b = np.random.randint(0, 255, (200, 800), dtype=np.uint8)g = np.random.randint(0, 255, (200, 800), dtype=np.uint8)r = np.random.randint(0, 255, (200, 800), dtype=np.uint8)# 合并通道，形成图片img = cv2.merge([b, g, r]) # opencv的通道是b在最前,r在最后# 显示图片cv2.imshow('test', img)cv2.waitKey(0)cv2.destroyWindow('test')# 拆分通道, 每个通道都变成了单通道数组[blue, green, red] = cv2.split(img) 用matplotlib显示图像1234b,g,r=cv2.split(img)img2=cv2.merge([r,g,b])plt.imshow(img2)plt.show() opencv 核心图像算法]]></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python-numpy学习笔记]]></title>
    <url>%2Fz_post%2FPython-numpy%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[numpy基础知识ndarray 对象表示一个 n 维数组, 描述相同类型的元素集合, 基于0的索引访问 创建 ndarray 1numpy.array(object, dtype = None, copy = True, order = None, subok = False, ndmin = 0) object: 可以返回一个数组或任何(嵌套)序列的对象。 dtype: 数据类型对象 copy: 对象是否被复制 order: C 安行, F 按列, 或者默认(A) subok: 默认情况下，返回的数组被强制为基类数组。 如果为true，则返回子类 ndmin: 指定返回数组的最小维数。 123456789101112131415# 最小维度 import numpy as npa = np.array([[1,2,3], [1,2,4]], dtype= float ,ndmin = 2)print(a)print(a.shape)print(a.dtype)print(a.ndim)print(a.size)#output:[[ 1. 2. 3.] [ 1. 2. 4.]](2, 3)float6426 numpy.array 中的 object 传入参数必须是同一结构的, 否则将进行自动类型转换, 如果指定了 dtype 参数, 则以该参数类型为准(规则与C++类似) numpy支持的数据类型 数据类型对象 dtypedtype是一个对象, 这个对象所属类的名字叫做 “数据类型” dtype 通常用于结构化数据类型: 123import numpy as npdt = np.dtype([('age',np.int8)]) print(dt) #输出如下： [('age', 'i1')] numpy基本操作比较运算符12345678910111213141516171819a = np.array([[1,2,3], [1,2,4]], dtype= float ,ndmin = 2)# 可以对ndarray中的值依次进行比较运算符, 返回bool数组print(a == 3)#out[[False False True] [False False False]]#out print(a &lt; 3) #out[[ True True False] [ True True False]]#out# 可以根据bool数组对ndarray中的值进行筛选, 返回1维数组print(a[ a&lt;3 ])#out[1. 2. 1. 2.]#out 向量运算矩阵运算矩阵运算主要注意的是axis参数的选择, axis参数的作用是, 沿着axis参数进行运算, 即运算后, 其他维度不变, axis指定的维度消失(所以维度会减1) numpy常用函数reshape, 可以对ndarray的维度重新进行调整 123456arr = np.arange(15).reshape(3, 5)arrarray([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) zeros, 生成默认元素为 0. (注意是float64类型)的ndarray 12345np.zeros ((3,4))array([[ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.]]) ones, 生成默认元素为 1. (注意是float64类型)的ndarray 12345z = np.ones ((3,4))array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]) range, 指定范围和数值间的间隔生成 array，注意范围包左不包右 1234l = np.arange(0,10,2) # 这里与python中的range不同的是, 必须指定第一个元素, 其次, 这里步长可以为小数, python的则不行[0 2 4 6 8] random 12345random, 生成0~1的随机小数,默认类型为float64, 还有其他更多类型的randomnp.random.random((2,3))array([[ 0.86166627, 0.37756207, 0.94265883], [ 0.9768257 , 0.96915312, 0.33495431]])]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集成学习方法]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[个体与集成集成学习(ensemble learning): 通过构建并结合多个学习器来完成学习任务 同质集成(homogeneous): 集成中只包含同种类型的个体学习器( 神网+神网, 决策树+决策树), 其中的个体学习器称为”基学习器”, 算法为”基学习算法”. 异质集成(heterogenous): 集成中包含不同类型的个体学习器( 神网+决策树 ), 其中的个体学习器称 “组件学习器”或”个体学习器” 要获得好的集成效果, 每个个体学习器应 “好而不同”, 即个体学习器要有一定的准确性, 同时还要有一定的差异性(否则多个学习器会退化成单一学习器,因为每个学习器都差不多) 事实上, 个体学习器的”准确性”和”差异性”本身就存在冲突, 一般的, 当准确性很高之后, 要增加多样性就需要牺牲准确性. 根据个体学习器的生成方式, 目前的集成学习方法大致可分为两大类: 个体学习器间存在依赖关系, 必须串行生成的序列化方法, eg: Boosting 个体学习器间不存在依赖关系, 可同时生成的并行化方法, eg: Bagging 和 随机森林(Random Forest) Boosting工作机制: 先从初始训练集训练出一个基学习器, 再根据基学习器的表现对训练样本进行调整, 使得先前基学习器做错的训练样本在后续受到更多关注, 然后基于调整后的样本分布来训练下一个基学习器, 如此重复进行, 直至基学习器数目达到事先指定的值T, 最终将这T个基学习器进行加权结合 Boosting族有很多种算法, 最著名的代表是 AdaBoost]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python-常用助记]]></title>
    <url>%2Fz_post%2FPython-%E5%B8%B8%E7%94%A8%E5%8A%A9%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[常用库: 1.numpy——基础，以矩阵为基础的数学计算模块，纯数学存储和处理大型矩阵。这个是很基础的扩展，其余的扩展都是以此为基础。 2.pandas——数据分析基于NumPy 的一种工具，为了解决数据分析任务而创建的。Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。最具有统计意味的工具包，某些方面优于R软件。数据结构有一维的Series，二维的DataFrame(类似于Excel或者SQL中的表，如果深入学习，会发现Pandas和SQL相似的地方很多，例如merge函数)，三维的Panel（Pan（el) + da(ta) + s，知道名字的由来了吧）。学习pandas要掌握：汇总和计算描述统计，处理缺失数据 ，层次化索引清理、转换、合并、重塑、GroupBy技术日期和时间数据类型及工具（日期处理方便地飞起）。 3.matplotlib——绘图，不推荐使用，不如用seabornpython中最著名的绘图系统.很多其他的绘图例如seaborn（针对pandas绘图而来）也是由其封装而成。这个绘图系统操作起来很复杂，和R的ggplot,lattice绘图相比显得望而却步，这也是为什么我个人不丢弃R的原因.但是matplotlib的复杂给其带来了很强的定制性。其具有面向对象的方式及Pyplot的经典高层封装。需要掌握的是：散点图，折线图，条形图，直方图，饼状图，箱形图的绘制。绘图的三大系统：pyplot，pylab(不推荐)，面向对象坐标轴的调整，添加文字注释，区域填充，及特殊图形patches的使用金融的同学注意的是：可以直接调用Yahoo财经数据绘图 4.scipy——数值计算库在NumPy库的基础上增加了众多的数学、科学以及工程计算中常用的库函数。方便、易于使用、专为科学和工程设计的Python工具包.它包括统计,优化,整合,线性代数模块,傅里叶变换,信号和图像处理,常微分方程求解器等等。 numpyskimagecv2123456789101112131415161718import cv2image_path = './test.jpg'src_image = cv2.imread(image_path) # 读取图片size = src_image.shape # 获取图片的尺寸, 返回一个元组: (height, width, depth)copy_image = src_image.copy() # 复制图片cv2.imwrite('./dst_test.jpg', copy_image) # 保存图片cv2.imshow('image', src_image) # 显示图片# 利用下标访问指定像素for x in range(src_image.shape[0]): # 以行为主, 行数=图片height for y in range(src_image.shape[1]): # 列数 = 图片width src_image[x,y] = (255,0,255) # (blue, green, red) 值越高表示对应颜色越显著, 全0为黑, 全255为白 csv12345678import csv# 只读csv文件with open('./csvfile.csv') as csv_file: csv_reader = csv.reader(csv_file) csv_head = next(csv_reader) for csv_row in csv_reader: print(csv_row) Path]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux-常用指令助记]]></title>
    <url>%2Fz_post%2FLinux-%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E5%8A%A9%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[cat指令grep指令ls指令统计文件个数更换国内镜像源清华源:1https://mirrors.tuna.tsinghua.edu.cn/ 中科大源: 1http://mirrors.ustc.edu.cn/help/homebrew-bottles.html 阿里源:123456789```# apt# pip# brew中科大 cd “$(brew —repo)”git remote set-url origin https://mirrors.ustc.edu.cn/brew.git1234# npmhttps://npm.taobao.org/ npm config set registry http://registry.npm.taobao.org```]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[项目-竞赛-Apollo]]></title>
    <url>%2Fz_post%2F%E9%A1%B9%E7%9B%AE-%E7%AB%9E%E8%B5%9B-Apollo%2F</url>
    <content type="text"><![CDATA[处理流程: https://www.kaggle.com/kmader/data-preprocessing-and-unet-segmentation-gpu https://github.com/matterport/Mask_RCNN/issues/5 遇到的问题 https://www.kaggle.com/c/cvpr-2018-autonomous-driving/discussion/56888 https://github.com/pandas-dev/pandas/issues/18355 https://github.com/matterport/Mask_RCNN/issues/44 https://github.com/matterport/Mask_RCNN/issues/628https://github.com/matterport/Mask_RCNN/issues/658https://github.com/matterport/Mask_RCNN/issues/521 https://github.com/matterport/Mask_RCNN/issues/5]]></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[LeetCode算法题(Hard)]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-LeetCode-3%2F</url>
    <content type="text"><![CDATA[004. Median of Two Sorted ArraysDescriptionThere are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). You may assume nums1 and nums2 cannot be both empty. Example 1: nums1 = [1, 3]nums2 = [2] The median is 2.0Example 2: nums1 = [1, 2]nums2 = [3, 4] The median is (2 + 3)/2 = 2.5 解法一: 根据中位数的特性题目要求需要时间复杂度为 $O(log (m+n))$. 首先我们思考中位数的作用: 中位数可以将一个数组分成两个长度相同的部分, 并且一部分中的数字总比另一部分中的小 那么对于两个数组的情况, 我们需要做的就是找到一个数字, 可以使这两个数组分别分成两部分, 并且两部分长度相同, 前一部分比后一部分的数字小 首先,我们将数组A分成两部分, 由于A有m个数字, 所以它可以有m中不同的分法, 我们以 i 为界限, 将A分成两部分, 前一部分的长度为i (从0到 i-1 ), 后一部分的长度为 m-i (从 i 到 m-1): A[1,2,…,i-1] | A[i, i+1, …, m-1] 同理,数组 B 也可以做如下分割: B[1,2,…,j-1] | B[j, j+1, …, n-1] 因此, 两个数组A和B都被分到了两部分, 将它们合起来, 第一部分的数字为 A[1,2,…,i-1] 和 B[1,2,…,j-1], 第二部分的数字为 A[i, i+1, …, m-1] 和 B[j, j+1, …, n-1], 我们并不关系两部分内部的顺序, 我们只关心一件事, 那就是: 第一部分和第二部分的长度相等, 并且第一部分的数字都比第二部分小 , 于是, i 和 j和取值就必须满足下列关系: i+j = m-i + n-j 或 m-i + n-j + 1 (加1的原因是因为有可能数组总长为奇数, 我们令前一部分比后一部分多1个元素) A[i-1] &lt;= B[j] 或 i==0 (说明A全部在后半段, 因此无需判断A的元素是否小于后半段的第一个B元素) B[j-1] &lt;= A[i] 或 i==m (说明A全部在前半段, 因此无需判断A的元素是否大于前半段的最后一个B元素) 由于上式 i+j = m-i + n-j 或 m-i + n-j + 1 , 因此有 j = (m+n+1)/2 - i ; (向下取整). 故而可以只对 i 进行判断i是否越界, 只要i满足条件, j就不会等于0或n(即不会越界) 根据上面的分析, 解题过程如: 根据两数组的长度, 将短的一方设为A数组 (j要对应较长的那个数组, 否则的话j有可能小于0 ), 令start=0, end=A.size 令 i=(start+end+1)/2 (加1 的原因是因为i代表的含义是前一部分有i个元素) 计算j = (m+n+1)/2 - i 判断当前 i和j是否满足条件,有三种情况(对这三种情况不断重复, 直到i,j位置刚刚好): A[i-1] &gt; B[j] 或 i 越界 , 说明 i 的位置过大, 令 end = i-1 B[j-1] &gt; A[i] 或 i 越界 , 说明 i 的位置过小, 令 start = i+1; 其他情况(A[i-1] &lt;= B[j] 或 i==0 并且 B[j-1] &lt;= A[i] 或 i==m), 说明 i 和 j的位置刚刚好 当i,j位置刚好时, 根据数组整体长度的奇偶, 返回正确的中位数: 奇数: 返回前半段的最大元素 偶数: 返回前半段最大元素和后半段最小元素的平均值-非递归写法 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; if(nums1.size() &gt; nums2.size())&#123; nums1.swap(nums2); &#125; int m = nums1.size(); int n = nums2.size(); int start = 0, end=m; while(start&lt;=end)&#123; int i = (start+end+1) / 2; int j = (n+m+1)/2 - i; if(i&gt;start &amp;&amp; nums1[i-1] &gt; nums2[j]) //注意 , 只要i&gt;start, j就一定不会超出数组限制 end = i-1; //i太大 else if(i&lt;end &amp;&amp; nums2[j-1] &gt; nums1[i]) start = i+1; // i太小 else&#123; int leftmax;// 取左边最大的 if(i==0) leftmax=nums2[j-1]; else if(j==0) leftmax=nums1[i-1]; else leftmax = max(nums1[i-1], nums2[j-1]) ; if( (n+m)%2 == 1) return leftmax; int rightmin; // 取右边最小的 if(i==m) rightmin = nums2[j]; else if(j==n) rightmin = nums1[i]; else rightmin = min(nums1[i] ,nums2[j]); return (leftmax+rightmin) / 2.0; &#125; &#125; // return 0.0; //因为, 两数组不会同时为空, 所以这句话主要用于调试 &#125;&#125;; 递归写法123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123;public: double findMedianSortedArrays(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; if(nums1.size() &lt;= nums2.size()) return helper(nums1, 0 , nums1.size(),nums2); else return helper(nums2, 0 , nums2.size(),nums1); &#125; double helper(vector&lt;int&gt;&amp; nums1, int start1, int end1, vector&lt;int&gt;&amp; nums2)&#123; int i = (start1+end1+1)/2; int j = (nums1.size()+nums2.size()+1)/2 - i; if(start1 &gt; end1) return 0.0; if( (i==0 || nums1[i-1]&lt;=nums2[j]) &amp;&amp; (i==nums1.size() || nums2[j-1]&lt;=nums1[i]))&#123; // 如果找到i int res11, res12; int res21, res22; // 首先将左边部分的两个数组分别赋值, 如果i或j为0, 说明对应数组在左边 //只有0个元素 , 将其赋值为INT_MIN(因为要取max(res11, res21)) if(i==0) res11= INT_MIN; else res11=nums1[i-1]; if(j==0) res21= INT_MIN; else res21=nums2[j-1]; //同理, 对右边进行处理, 取min(res12, res22) if(i==nums1.size()) res12= INT_MAX; else res12=nums1[i]; if(j==nums2.size()) res22= INT_MAX; else res22=nums2[j]; // 根据数组奇偶个数返回结果 if((nums1.size() + nums2.size())%2 == 1 )&#123; return max(res11, res21); &#125; else&#123; return ( max(res11,res21)+min(res12,res22) ) / 2.0; &#125; &#125;else if(nums1[i-1] &gt; nums2[j])&#123; return helper(nums1, start1, i-1, nums2); &#125;else&#123; return helper(nums1, i+1, end1, nums2); &#125; &#125;&#125;; 010.Description解法一: 递归实现( 速度很慢, 只超过0.97%的提交)采用递归法, 首先判断当前字母后面是否是’ * ‘, ,如果是, 则需要分别进行下面两种情况的判断: 当前字母出现0次 当前字母出现1次或以上(前提是当前字母可以匹配) 其次, 就是终止条件的判断, 总共有三种情况: 都走到了尽头, 返回ture 只有p走到了尽头, 返回false 只有s走到了尽头, 需要查看p后续的值 12345678910111213141516171819202122232425class Solution &#123;public: bool isMatch(string s, string p) &#123; return helper(s, 0, p, 0); &#125; bool helper( string&amp; s, int s_i, string&amp; p, int p_i)&#123; if(s_i == s.size() &amp;&amp; p_i == p.size()) return true; // 若都走到了最后, 则返回ture if(p_i == p.size() ) return false; // 若只有p走到了最后, 返回false if(s_i == s.size() &amp;&amp; p_i+1&lt;p.size() &amp;&amp; p[p_i+1] == '*') //若只有s走到了最后, 则需要看p后面是否有*, 如果有*, 则仍有可能匹配 return helper(s, s_i, p, p_i+2); // 若没有*,返回false else if(s_i == s.size()) return false; if(p_i + 1 &lt; p.size() &amp;&amp; p[p_i+1] == '*')&#123; //如果后面有星号, 则需要进行两种判断 bool b1 = helper(s, s_i, p, p_i+2); // 星号前的字母出现0次 bool b2 = false; if(s[s_i] == p[p_i] || p[p_i] == '.') b2 = helper(s, s_i+1, p , p_i) || helper(s, s_i+1, p, p_i+2);// 出现一次或一次以上 return b1 || b2; &#125;else if(s[s_i] == p[p_i] || p[p_i] == '.' )&#123; return helper(s, s_i+1, p, p_i+1); &#125;else&#123; return false; &#125; &#125;&#125;; 解法二: 动态规划This problem has a typical solution using Dynamic Programming. We define the state P[i][j] to be true if s[0..i) matches p[0..j) and false otherwise. Then the state equations are: P[i][j] = P[i - 1][j - 1], if p[j - 1] != ‘*’ &amp;&amp; (s[i - 1] == p[j - 1] || p[j - 1] == ‘.’); P[i][j] = P[i][j - 2], if p[j - 1] == ‘*’ and the pattern repeats for 0 times; P[i][j] = P[i - 1][j] &amp;&amp; (s[i - 1] == p[j - 2] || p[j - 2] == ‘.’), if p[j - 1] == ‘*’ and the pattern repeats for at least 1 times. Putting these together, we will have the following code. 1234567891011121314151617class Solution &#123;public: bool isMatch(string s, string p) &#123; bool dp[s.size()+1][p.size()+1]&#123;0&#125;; dp[0][0]=true; for(int i =0; i&lt;s.size()+1; i++)&#123; for(int j = 1;j&lt;p.size()+1;j++)&#123; if(p[j-1] == '*') // 注意这里是j-1 dp[i][j] = ( j &gt; 1 &amp;&amp; dp[i][j-2] )|| ( i&gt;0 &amp;&amp; (s[i-1] == p[j-2] || p[j-2] == '.') &amp;&amp; dp[i-1][j]); // 注意这里是j-2, i-1, 一定要知道这些是为什 else dp[i][j] = i&gt;0 &amp;&amp; dp[i-1][j-1] &amp;&amp; (s[i-1] == p[j-1] || p[j-1] == '.'); &#125; &#125; return dp[s.size()][p.size()]; &#125;&#125;;]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智力题汇总]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E6%99%BA%E5%8A%9B%E9%A2%98%2F</url>
    <content type="text"><![CDATA[智力题如果一个女生说，她集齐了十二个星座的前男友，我们应该如何估计她前男友的数量？https://www.zhihu.com/question/38331955 优秀面经https://www.cnblogs.com/huanyi0723/p/8470866.html 待看http://www.cnblogs.com/mrxsc/articles/6266584.html https://zhuanlan.zhihu.com/p/29633019]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>智力题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优化方法整理总结]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习/深度学习面试问题汇总]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统面试问题汇总]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++面试问题汇总]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-Cpp%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[https://zhuanlan.zhihu.com/p/46237848?utm_source=wechat_session&amp;utm_medium=social]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode算法题(Medium)]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-LeetCode-2%2F</url>
    <content type="text"><![CDATA[002. Add Two NumbersDescriptionYou are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Example: Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 0 -&gt; 8Explanation: 342 + 465 = 807. 解法一: 顺序相加, 注意进位从链表的第一个节点开始, 将两个节点的值和进位位想加, 如果大于10, 则当前结果节点的值对10取余, 同时将进位位置1, 如果小于10, 则直接赋值给当前结果节点, 同时将进位位置0. 特别注意l1和l2的长度问题, 当二者节点遇到nullptr时, 将较长的剩余部分重新赋给l1, 并继续判断 最后, 需要注意是否有进位位, 如果有, 则要申请一个新节点, 并将其置为1 时间复杂度: $O(\max(m,n))$ 空间复杂度: $O(1)$ (这种做法会破坏原有链的结构) 空间复杂度: $O(\max(m,n))$ (这种做法需要额外申请空间, 但不会破坏原有链的结构) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; int carry = 0; ListNode* head = new ListNode(0); //创建指向最终结果的头指针 if(l1!=nullptr) head-&gt;next = l1; // 虽然题目指明为非空链表, 但是最好还是做一下判断 else head-&gt;next = l2; ListNode* pre=head; // pre用于保存l1的上一个指针 while(l1!=nullptr &amp;&amp; l2!=nullptr)&#123; l1-&gt;val = l1-&gt;val + l2-&gt;val + carry; if(l1-&gt;val &gt; 9)&#123; l1-&gt;val %= 10; carry = 1; &#125;else&#123; carry = 0; &#125; pre = l1; l1 = l1-&gt;next; l2 = l2-&gt;next; &#125; if(l2!=nullptr)&#123; // 此时说明l2比l1长, 用l1的上一个指针指向当前l2剩余的部分, l1 = pre; l1-&gt;next = l2; l1 = l1-&gt;next; &#125; while(l1!=nullptr)&#123; // 此时l1为剩余(l1或l2) 的部分, 只需要考虑是否有进位即可 l1-&gt;val = l1-&gt;val + carry; if(l1-&gt;val &gt; 9)&#123; l1-&gt;val %= 10; carry = 1; &#125;else&#123; carry = 0; // 如果没有进位, 一定要将此处置0, 否则会引起错误 break; &#125; pre = l1; l1 = l1-&gt;next; &#125; if(carry == 1)&#123; // 对应 999 + 001 的特殊情况, 此时进位会不断传递, 最终数字位数加1, 最高位为1 ListNode* newnode = new ListNode(1); l1 = pre; l1-&gt;next = newnode; &#125; return head-&gt;next; &#125;&#125;; 扩展问题What if the the digits in the linked list are stored in non-reversed order? For example: $(3 \to 4 \to 2) + (4 \to 6 \to 5) = 8 \to 0 \to 7 (3→4→2)+(4→6→5)=8→0→7$ 思路: 先将链表转置 , 再用上面的方法求解 转置时间复杂度: $O(n)$转置空间复杂度: $O(1)$ 003. Longest Substring Without Repeating CharactersDescriptionGiven a string, find the length of the longest substring without repeating characters. Example 1: Input: “abcabcbb”Output: 3Explanation: The answer is “abc”, with the length of 3.Example 2: Input: “bbbbb”Output: 1Explanation: The answer is “b”, with the length of 1.Example 3: Input: “pwwkew”Output: 3Explanation: The answer is “wke”, with the length of 3. Note that the answer must be a substring, “pwke” is a subsequence and not a substring. 解法一:暴力时间复杂度: $O(n^3)$ 对于每一个字符, 子串的添加以及查重过程时间复杂度为 $O(n^2)$ , 总共n个字符, 所以为 $O(n^3)$ 时间复杂度: $O(min(n,m))$ 需要将当前子串存在起来以便查询是否相等, n为字符串length, m为字符集size 解法二: 前后两个指示变量思路: 首先构造一个哈希表, 用来存储当前子串中出现的字符, 这样, 新来的字符可以直接查询哈希表来判断字符是否存在, 构建哈希表空间复杂度为 O(min(n,m)) (m为字符集合的大小,一般为26(字母), 128(ASCII), 256(ASCII)) 然后, 使用两个指示变量, 分别指向当前未重复子串的首字符, 和超尾字符, 进行如下几个判断: 如果超尾字符与当前子串中的字符不重复, 那么将超尾字符加入到当前子串中,并将length加1 如果超尾字符与当前子串中的字符重复, 利用哈希表查的重复字符的所在位置, 将当前子串的首字符直接跳向该重复字符的下一个位置( 这样可以保证只遍历一遍 ), 并将包括重复字符在内的之前所有字符都从哈希表中删除(之前的字符不再可能组成更长的子串了), 同时将超尾字符加入, length赋予新值: 超尾位置-重复位置-1; 判断首字符与超尾字符是否相等, 如果相等, 将超尾字符加1, 并将length置为1 看当前length是否比maxlength大, 并重复以上过程,直到超尾字符超出size 时间复杂度: $O(n)$空间复杂度: $O(min(n,m))$ 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; unordered_map&lt;char,int&gt; ch_exists; if(s.size() &lt;= 0) return 0 ; int max_length = 1; int length = 1; ch_exists.insert(&#123;s[0], 0&#125;); for(int i =0,j = 1 ; j &lt; s.size() ; )&#123; if(ch_exists.count(s[j]) == 0 )&#123; // j对应的字母未重复, length增加 length++; ch_exists.insert(&#123;s[j], j&#125;); j++; &#125;else&#123; // j对应的字母重复, 将i置于重复字母的下一个(因为之前都都不可能产生更长的未重复子串了) int index = ch_exists[s[j]]; for(int k = i; k &lt;= index; k++) ch_exists.erase(s[k]); i=index + 1; ch_exists.insert(&#123;s[i], i&#125;); length = j - index - 1; &#125; if(i==j)&#123; //这里如果写在开头, j++之后有可能超过size, 导致有问题, //所以写在后面, 以便在for循环中检查j是否超过size j++; length = 1; &#125; if(length &gt; max_length) max_length = length; &#125; return max_length; &#125;&#125;; 解法二的另一种写法该写法核心思路与上面的一样, 所以时间复杂度和空间复杂度也一样, 唯一不同的是hash表, 前面的会将i与重复字符之间的都删除, 这里不删除, 利用max控制, 使i永远不会倒退 这里写法更加简洁, 应值得学习 123456789101112131415161718class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; unordered_map&lt;char, int&gt; s_hash; int max_length = 0; for(int i = 0 ,j=0 ; j&lt; s.size() ; j++)&#123; if(s_hash.count(s[j]))&#123; i = max(i,s_hash[s[j]]+1); //如果遇到重复的, 就将当前的i指向重复的下一个 // (这里用max的原因是, 没有删除当前i到重复字符之间的其他字符, 这些字符 // 后续还可能被检测到, 所以这里只取max的, 也就是i不会倒退) s_hash.erase(s[j]); // 将重复的删除, 以便赋予新的值 &#125; s_hash.insert(&#123;s[j], j&#125;); max_length = max_length &gt; (j-i+1) ? max_length : (j-i+1); &#125; return max_length; &#125;&#125;; 005. Longest Palindromic Substring(最大回文子串)DescriptionGiven a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000. Example 1: Input: “babad”Output: “bab”Note: “aba” is also a valid answer.Example 2: Input: “cbbd”Output: “bb” 解法一：最长公共子串$O(n^2)$ $O(n)$ 解法二： 穷举$O(n^3)$ $O(1)$ 解法三： 动态规划？ 解法三： 扩展中心法以每一个字符为中心， 向两边扩展， 将当前能够扩展的长度 len 和最大扩展长度 max_len 作比较, 记录较大者, 同时记录较大者的所对应的重心字符的下标 max_index. 最后, 根据最大扩展的长度max_len 和中心字符的下标 max_index 计算最大回文子串的开始位置和总长度 此处注意, 回文子串有奇偶两种情况, 可采用以下举措之一解决: 分别检查奇数和偶数的情况 向字符内插入特殊符号 ‘#’, 这样不管偶数奇数, 都可以当做奇数处理, 缺点是占用了额外的 $O(n)$ 空间 时间复杂度: $O(n^2)$ 空间复杂度: $O(1)$ 或者 $O(n)$ 注意: 既然已经使用了空间复杂度为 $O(n)$ 的方法, 实际上更应该将其该写成马拉车算法 12345678910111213141516171819202122232425262728293031// 空间复杂度 $O(1)$class Solution &#123;public: string longestPalindrome(string s) &#123; int max_len = 0; int start = 0; for(int i=0; i &lt; s.size(); i++)&#123; int len1=0,len2=0; int left=i, right = i; //通过left和right , 是的对奇偶的分别处理更方便 while( left &gt;=0 &amp;&amp; right&lt;s.size() &amp;&amp; s[left] == s[right])&#123; left--; right++; &#125; len1 = right-left-1; // 注意, 这里一定是-1, 而不是+1 left=i; right=i+1; while( left&gt;=0 &amp;&amp; right&lt;s.size() &amp;&amp; s[left] == s[right])&#123; left--; right++; &#125; len2 = right-left-1; int len = max(len1, len2); if(len&gt;max_len)&#123; max_len = len; start = i- (len-1)/2; &#125; &#125; return s.substr(start, max_len); &#125;&#125;; 1234567891011121314151617181920212223242526272829303132// 空间复杂度 $O(n)$class Solution &#123;public: string longestPalindrome(string s) &#123; char* cs = new char[s.size() * 2+1]; cs[0]='#'; for(int i=0; i&lt;s.size() ; i++)&#123; //插入 '#' cs[i*2+1] = s[i]; cs[i*2+2] = '#'; &#125; int max_len=0; int max_index = 0; for(int i =0; i&lt;s.size()*2+1 ; i++)&#123; int len=0; //记录当前扩展长度len for(int j=1; i-j&gt;=0 &amp;&amp; i+j&lt;s.size()*2+1 ;j++)&#123; if(cs[i-j] == cs[i+j])&#123; //两边字符若相等, 则len长度增1 len++; &#125;else break; &#125; if(len &gt; max_len)&#123; max_len = len; max_index = i; &#125; &#125; int start = (max_index - max_len)/2; //根据maxlen和index 计算回文子串开始坐标 int len = max_len; delete cs; return s.substr(start, len); &#125;&#125;; 解法五: 马拉车(Manacher) 算法时间复杂度: $O(n)$空间复杂度: $O(n)$ 马拉车算法的核心思想还是从中心扩展发出发, 不过他必须使用 ‘#’ 字符先对原始字符串插入, 如下所示: 接下来, 在每一次for循环当中, 都需要保存这么几个值(命名是个人习惯, 可以用其他名字代替): P: P为最大右边界下标值, 对应的是所有已检测的回文子串中, 右边界下标最大的那个 P_center: 该值是P对应的回文子串的中心下标 max_len: 对应当前最大回文子串的半径(aba的半径为1, a的半径为0) max_index: 对应当前最大回文子串的中心下标 然后, 还需要构建一个和插入’#’后的字符串长度相关的数组p_len, 里面存放着对应位置的回文串半径, 用以后续的计算, 这一步是关键, 有了这个数组 ,才能实现利用之前计算结果 接下来, 遍历 “新字符串”(即插入’#’之后的字符串) 的每一个字符, 设当前下标为 i, 则有如下情况, 分别处理: P&gt;i, 说明 i 在 P 的范围内, 可以利用前面的计算结果 P&lt;=i, 说明i不在 P 的范围内, 无法利用前面的计算结果, 只能逐个判断 对上面两种情况具体分析如下: 第一种情况: P&gt;i 找到i相对于 P_center 的对称位置，设为j，那么如果Len[j]&lt;P-i, 如下图所示: 则以i为中心的回文串的长度至少和以j为中心的回文串一样 , 即Len [i]&gt;=Len[j] , 因此可以直接从Len[j]+1开始判断回文 如果Len[j]&gt;=P-i, 如下图所示: 由对称性，说明以i为中心的回文串可能会延伸到P之外，而大于P的部分我们还没有进行匹配，所以要从P+1位置开始一个一个进行匹配，直到发生失配 第二种情况: P&lt;=i 如果i比P还要大，说明对于中点为i的回文串还一点都没有匹配，这个时候，就只能老老实实地一个一个匹配了 在这一次循环完成之前, 更新上面提及的四个变量 循环结束后, 根据 max_index 和 max_len 的值返回最长回文子串 时间复杂度分析: 对于每一个字符, 由于如果之间比较过, 那么就可以利用之前比较的结果直接判断, 所以每个字符都只进行了一次比较, 故而时间复杂度为 $O(n)$ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution &#123;public: string longestPalindrome(string s) &#123; int cs_size = s.size()*2+1; char* cs = new char[cs_size]; cs[0] = '#'; for(int i = 0;i&lt;s.size(); i++)&#123; cs[i*2 + 1] = s[i]; cs[i*2 + 2] = '#'; &#125; int P = 0; int P_center = 0; int max_index = 0; int max_len = 0; int* p_len = new int[cs_size]; for(int i =0; i&lt;cs_size; i ++)&#123; if( i &lt; P)&#123; // 如果i&lt;P, 说明可以复用前面的计算结果 int j = P_center*2 - i; // j对i关于P_center的对称点 if(P-i &gt; p_len[j])&#123; // 如果i与P之间的距离比 j 的回文串长度还大, //说明可以直接从p_len[j] + 1开始比较, 之前的子串一定是回文串 int k = p_len[j] + 1; while(i-k&gt;=0 &amp;&amp; i+k&lt;cs_size &amp;&amp; cs[i-k] == cs[i+k])&#123; k++; &#125; p_len[i] = k-1; &#125;else&#123; // 如果距离没有p_len[j] + 1大, 则从超出P的部分开始比较 int k = P - i; while(i-k&gt;=0 &amp;&amp; i+k&lt;cs_size &amp;&amp; cs[i-k] == cs[i+k])&#123; k++; &#125; p_len[i] = k-1; &#125; &#125;else&#123; //如果i不在P范围内, 则必须从1开始逐个比较, 无法利用之前的计算结果 int k = 1; while(i-k&gt;=0 &amp;&amp; i+k&lt;cs_size &amp;&amp; cs[i-k] == cs[i+k])&#123; k++; &#125; p_len[i] = k-1; &#125; if(p_len[i] &gt; max_len)&#123; max_len = p_len[i]; max_index = i; &#125; if(i+p_len[i] &gt; P)&#123; P = i+p_len[i]; P_center = i; &#125; &#125; delete cs; delete p_len; int start = (max_index - max_len)/2; int len = max_len; return s.substr(start, len); &#125;&#125;; 008.Description解法一:此题时间复杂度为 $O(n)$ , 重点考察是否考虑的全面, 主要有以下几种情况, 缺一不可: +123 dd // 返回123 +123d // 返回123 d-123 // 返回0 -123+ //返回-123 -123+4 // 返回-123 323123423423423 // 返回INT_MAX -1231238923894234 // 返回INT_MIN 1234-5 // 返回1234 123456789101112131415161718192021222324252627282930class Solution &#123;public: int myAtoi(string str) &#123; int sign =1; bool is_first = true; //记录当前非数字字符是否是第一个非空格字符, 如果是, 返回0 bool has_sign = false; // 记录正负号的出现次数, 出现多于1次的, 返回0 long res = 0; //记录当前的int值, 要出现int范围, 返回对应的INT for(int i =0 ; i&lt;str.size(); i++)&#123; if(str[i] == ' ' &amp;&amp; is_first) continue; // 空格, 且没有出现任何非空格字符(如出现了, 则空格也会跟着变成循环停止的标志) else if( !has_sign &amp;&amp; (str[i] == '+' || str[i] == '-') )&#123; // 判断符号 has_sign = true; is_first = false; sign = str[i]=='+' ? 1:-1; &#125;else if(str[i] &lt;= '9' &amp;&amp; str[i] &gt;= '0')&#123; has_sign = true; is_first = false; res = res*10 + int(str[i] - '0') * sign; // 数字累加, 注意这里使用了sign, 因此无需在后面判断正负, 直接加就可以 if (res &gt; INT_MAX) return INT_MAX; // 超限 else if(res &lt; INT_MIN) return INT_MIN; &#125;else if(is_first)&#123; //首字符为非法字符, 返回0 return 0; &#125;else&#123; break; &#125; &#125; return int(res); &#125;&#125;; 011. Container With Most WaterDescriptionGiven n non-negative integers a1, a2, …, an , where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forms a container, such that the container contains the most water. Note: You may not slant the container and n is at least 2. The below vertical lines are represented by array [1,8,6,2,5,4,8,3,7]. In this case, the max area of water (blue section) the container can contain is 49. 解法一: 暴力时间复杂度: $O(n^2)$ 用max_area标记当前最大容器的取值, 然后两个for循环遍历所有容器的可能取值 1234567891011121314class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int max_area = 0; for(int i=0; i&lt;height.size(); i++)&#123; for(int j = i+1; j &lt; height.size(); j++)&#123; if(max_area &lt; min( height[i],height[j] ) * (j-i))&#123; max_area = min( height[i],height[j] ) * (j-i); &#125; &#125; &#125; return max_area; &#125;&#125;; 解法二: 用两个指针时间复杂度: $O(n)$ 分别用两个指针指向数组的第一个元素和最后一个元素, 并计算当前的area, 然后移动指针元素值较小的一方, 移动过程中更新max_area的值 原理: 首先假设容器可以具有最大长度的宽, 也就是分别指向首尾元素, 这时候 , 我们想查看是否还有比当前最大容积更大的容器, 那么, 我们必须维持较高的垂直边不动, 而将较低的垂直边移动, 因为只有这样, 我们才 有可能 (注意不是一定)获得比当前容积更大的容器, 这个时候虽然宽变小了, 但是高度却可能增加(因为新增的边有可能大于当前较低边的高). 如果移动较高的边, 那么新增的边由于受到当前较低边的作用, 只有可能减小容器的面积 123456789101112131415161718class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int low = 0, high = height.size()-1; int max_area = 0; while(low&lt;high)&#123; int area = min( height[low], height[high] ) * (high-low); if(max_area &lt; area)&#123; max_area = area; &#125; if(height[low] &lt; height[high]) low++; else high--; &#125; return max_area; &#125;&#125;; 150. evaluate reverse polish notationDescription解法一:用栈来实现, 从到开始扫描字符串vector, 如果当前字符串不为运算符, 则直接入栈, 如果为运算符 , 则取栈顶两个元素进行运算然后将计算结果入栈. 最终, 栈中只剩一个结果值 需要注意的是: 首先要确保输入的逆波兰表达式是没有问题的, 其次还有要进行零除判断, 这几点本题没有考查, 但仍需注意 12345678910111213141516171819202122232425class Solution &#123;public: int evalRPN(vector&lt;string&gt; &amp;tokens) &#123; stack&lt;string&gt; rpn; for(int i =0;i&lt;tokens.size() ; i++)&#123; if(tokens[i] == "+" || tokens[i] == "-" || tokens[i] == "*" || tokens[i] == "/" )&#123; int num1 = stoi(rpn.top()); rpn.pop(); int num2 = stoi(rpn.top()); rpn.pop(); if(tokens[i] == "+") rpn.push(to_string(num2+num1)); if(tokens[i] == "-") rpn.push(to_string(num2-num1)); if(tokens[i] == "*") rpn.push(to_string(num2*num1)); if(tokens[i] == "/") rpn.push(to_string(num2/num1)); // 这里其实还应该进行0除判断 &#125;else rpn.push(tokens[i]); &#125; if(rpn.size() == 1) return stoi(rpn.top()); else return 0; //如果输入的polish表达式有问题, 那么输出0(其实这里应该用一个全局量来标识错误情况) &#125;&#125;; 解法二:解法与上面相同, 不同借助了异常, 显得更加简洁 12345678910111213141516171819202122232425262728class Solution &#123;public: int evalRPN(vector&lt;string&gt; &amp;tokens) &#123; stack&lt;int&gt; rpn; for(int i =0; i&lt;tokens.size(); i++)&#123; try&#123; rpn.push(stoi(tokens[i])); &#125; catch (exception e)&#123; int num1 = rpn.top(); rpn.pop(); int num2 = rpn.top(); rpn.pop(); switch(tokens[i][0])&#123; case '+': rpn.push(num2+num1);break; case '-': rpn.push(num2-num1);break; case '* ': rpn.push(num2*num1);break; case '/': rpn.push(num2/num1);break; &#125; &#125; &#125; if(rpn.size()==1) return rpn.top(); else return 0; &#125;&#125;;]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode算法题(Easy)]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-LeetCode-1%2F</url>
    <content type="text"><![CDATA[001. Two Sum题目描述Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example: Given nums = [2, 7, 11, 15], target = 9, Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 解法一: 穷举时间复杂度: $O(n^2)$空间复杂度: $O(1)$ 123456789101112131415class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; for(int i = 0; i&lt;nums.size(); i++)&#123; for(int j = i+1; j&lt;nums.size(); j++)&#123; if(nums[i] + nums[j] == target)&#123; vector&lt;int&gt; res =&#123;i,j&#125;; return res; &#125; &#125; &#125; &#125;&#125;; 解法二 : 哈希表, 两次遍历这里要特别注意: 同一个元素不能使用两次, 但是数组中的元素是可以重复的, 重复的元素看作是两个元素. hash表中最终存储的将会是重复元素的最后一个下标, 因此, 在进行比较时, 使用 i!= nums_map[target-nums[i]] 来判断它们是否为同一个元素, 而不能使用nums_map[nums[i]] != nums_map[target-nums[i]] 时间复杂度: $O(n)$ 遍历两次空间复杂度: $O(n)$ 123456789101112131415class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; unordered_map&lt;int, int&gt; nums_map; for(int i = 0 ;i&lt;nums.size(); i++)&#123; nums_map.insert(&#123;nums[i], i&#125;); &#125; for(int i = 0 ; i&lt;nums.size(); i++)&#123; if(nums_map.count(target-nums[i]) == 1 &amp;&amp; i!= nums_map[target-nums[i]])&#123; vector&lt;int&gt; res = &#123;i, nums_map[target-nums[i]]&#125;; //这里一定要用i,而不能用nums_map[nums[i]] , 上面也同理 return res; &#125; &#125; &#125;&#125;; 解法三: 哈希表 一次遍历事实上, 可以将hash表的插入和查找对应元素的操作放在 一个循环里, 这样就只需要进行一次遍历 时间复杂度: $O(n)$ 遍历一次空间复杂度: $O(n)$ 1234567891011121314class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; unordered_map&lt;int, int&gt; nums_map; for(int i = 0 ;i&lt;nums.size(); i++)&#123; if(nums_map.count(target-nums[i]) == 1 &amp;&amp; i!= nums_map[target-nums[i]])&#123; vector&lt;int&gt; res = &#123;i, nums_map[target-nums[i]]&#125;; return res; &#125; nums_map.insert(&#123;nums[i], i&#125;); &#125; &#125;&#125;; 扩展问题How would you approach the problem if the input array is very large (but limited range) and cannot fit in the memory ? This is a follow-up question for this problem. 007.解法一: 取余数这道题本身不难, 只要不断对x的绝对值取余数, 就可以得到反转的整数, 但是, 该题的核心考察点在于边界条件的判断, 稍不注意, 很容易漏解(如果不进行边界判断, 即使写出了解决方法, 面试官也很不满意) x为0 x反转后的值,超过了int型数据的表示范围, 检查方法是先用long存储, 然后看 1234567891011121314151617class Solution &#123;public: int reverse(int x) &#123; if(x==0) return x; int abs_x = abs(x); int sign_x = x&gt;0? 1:-1; long res = 0; // 为了看int是否越界,特意将res声明为long型 while( abs_x!=0 )&#123; res = res*10 + abs_x%10; if(res &gt; INT_MAX || res &lt; INT_MIN) return 0; //这一句就是最主要的考察点,看int是否越界 abs_x = abs_x/10 ; &#125; if(sign_x ==-1) return 0-res; return res; &#125;&#125;; 013. Roman to IntegerDescription解法一: 顺序扫描时间复杂度: $O(n)$ 顺序扫描, 如果当前字符比下一个字符小, 说明是 ‘4’ 或 ‘9’ 的情况, 用下一个字符的值减去当前字符的值 12345678910111213141516171819202122232425class Solution &#123;public: int romanToInt(string s) &#123; map&lt;char, int&gt; roman_char; roman_char['I'] = 1; roman_char['V'] = 5; roman_char['X'] = 10; roman_char['L'] = 50; roman_char['C'] = 100; roman_char['D'] = 500; roman_char['M'] = 1000; int res = 0; for(int i =0; i&lt;s.size() ; i++)&#123; if( i&lt;s.size()-1 &amp;&amp; roman_char[s[i]] &lt; roman_char[s[i+1]])&#123; res += roman_char[s[i+1]]-roman_char[s[i]]; i++; &#125; else res += roman_char[s[i]]; &#125; return res; &#125;&#125;; 扩展问题: 异常检测上面的解法虽然可以通过OJ, 但是此题还需要进行特别的异常诊断, 即要能够判断出当前输入的罗马输出是否合法! 如 “IVIV” 就是典型的不合法输入, 对于此输入, 上面的程序会输出 44, 这显然不正确 104. minimum depth of binary tree 题目描述Given a binary tree, find its minimum depth.The minimum depth is the number of nodes along the shortest path from the root node down to the nearest leaf node. 解法一:层次优先遍历,遇到的首个叶子结点(左右子树为空)即为最短的深度 注意: 利用while内嵌for循环的方式, 可以省去对每个结点depth的维护, 只需要每次进入for循环之前, depth++即可(因为一个for循环会将当前层所有的结点都入队列, for循环结束后, 意味着进入了下一层, 所以depth++即可) 123456789101112131415161718192021class Solution &#123;public: int run(TreeNode *root) &#123; queue&lt;TreeNode*&gt; q_node; if(root==nullptr) return 0; q_node.push(root); int depth = 0; while(!q_node.empty())&#123; const int size = q_node.size(); depth++; for(int i = 0; i&lt; size; i++)&#123; TreeNode* node = q_node.front(); q_node.pop(); if(node-&gt;left!=nullptr) q_node.push(node-&gt;left); if(node-&gt;right!=nullptr) q_node.push(node-&gt;right); if(node-&gt;left==nullptr &amp;&amp; node-&gt;right == nullptr) return depth; &#125; &#125; return -1; &#125;&#125;; 解法二(递归):让当前结点为空, 则当前结点深度为0, 若当前结点左子树为空, 则当前结点深度等于左子树深度, 反之 ,等于右子树深度. 若当前结点左右子树均不为空, 则当前结点的 最小深度 等于左右子树深度 较小者 加1 123456789101112131415class Solution &#123;public: int run(TreeNode* root) &#123; if(root== nullptr) return 0; if(root-&gt;left==nullptr) return run(root-&gt;right) + 1; else if(root-&gt;right ==nullptr) return run(root-&gt;left) + 1; else&#123; int depth1=run(root-&gt;left); int depth2=run(root-&gt;right); return depth1&lt;depth2 ? depth1+1 : depth2+1; &#125; &#125;&#125;;]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习经典算法之SVM深入解析]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E4%B9%8BSVM%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言起初让我最头疼的是拉格朗日对偶和SMO，后来逐渐明白拉格朗日对偶的重要作用是将w的计算提前并消除w，使得优化函数变为拉格朗日乘子的单一参数优化问题。而SMO里面迭代公式的推导也着实让我花费了不少时间。 对比这么复杂的推导过程，SVM的思想确实那么简单。它不再像logistic回归一样企图去拟合样本点（中间加了一层sigmoid函数变换），而是就在样本中去找分隔线，为了评判哪条分界线更好，引入了几何间隔最大化的目标。 之后所有的推导都是去解决目标函数的最优化上了。在解决最优化的过程中，发现了w可以由特征向量内积来表示，进而发现了核函数，仅需要调整核函数就可以将特征进行低维到高维的变换，在低维上进行计算，实质结果表现在高维上。由于并不是所有的样本都可分，为了保证SVM的通用性，进行了软间隔的处理，导致的结果就是将优化问题变得更加复杂，然而惊奇的是松弛变量没有出现在最后的目标函数中。最后的优化求解问题，也被拉格朗日对偶和SMO算法化解，使SVM趋向于完美。 1. 支持向量机基本概念及原理1.1 间隔与支持向量给定训练样本集 $D = {(\vec x^{(1)}, y^{(1)}), (\vec x^{(2)},y^{(2)}),..,(\vec x^{(m)},y^{(m)})}, y_i \in \{-1, +1\} (二分类问题) , \vec x^{(i)} =(x^{(i)}_1;x^{(i)}_2;…;x^{(i)}_d )$ (注意,这里用的是分号, 表示这是一个列向量), SVM做的事情就是试图把一根”木棍”放在最佳位置, 好让”木棍”的两边都有尽可能大的”间隔”. 这个”木棍”就叫做”划分超平面”, 可以用下面的线性方程来描述: \vec w^T\vec x + b = 0, 其中 $\vec w =(w_1; w_2;…; w_d)$ 为 $d$ 维法向量(注意,这里用的是分号, 表示这是一个列向量), $\vec x$ 为”木棍”上的点的坐标, $b$ 为位移项. 根据点到”直线”的距离公式,我们可以得到样本空间中任意点 $\vec x$ 到超平面 $(\vec w,b)$ 的距离为: r = \frac{|\vec w^T\vec x+b|}{\|\vec w \|}$|\vec w| = \sqrt{w_1^2 + w_2^2 + … + w_d^2}$ 为向量长度(也即向量的L2范式) 首先假设 当前的超平面可以将所有的训练样本正确分类, 那么就有如下式子: \begin{cases} \vec w^T\vec x^{(i)} + b \geq 0, & y^{(i)} = +1 \\ \vec w^T\vec x{(i)} + b \leq 0, & y_{(i)} = -1 \end{cases}上式可以统一写成如下的约束不等式:() y^{(i)}(\vec w^T\vec x^{(i)} + b) \geq 0上面的式子其实是冗余的, 因为假设样本点不在超平面上, 所以不可能出现等于0的情况, 又因为超平面方程两边都乘一个不等于0的数,还是 同一个超平面, 因此为了简化问题的表述, 我们对 $\vec w$ 和 $b$ 加上如下约束(这里的1没有什么特别的含义, 可以是任意的常数, 因为这里的点 $\vec x^{(i)}$ 不是超平面上的点, 所以所得值不为0): \min_i|\vec w^T\vec x^{(i)} +b| = 1即离超平面最近的正, 负样本距离超平面的距离为: $\frac{1}{|\vec w|}$ , 我们将这些距离超平面最近的几个训练样本点为定义”支持向量”, 那么, 两个异类支持向量到超平面的距离之和就为 $\gamma = \frac{2}{|\vec w|}$ , 我们将这称为”间隔”. 同时, 根据此约束, 我们可以消除超分类平面约束的冗余, 得到新的超分类平面约束如下: y^{(i)}(\vec w^T\vec x^{(i)} + b) \geq 1SVM的目的就是找到具有”最大间隔”的划分超平面, 也就是要找到满足约束$y^{(i)}(\vec w^T\vec x^{(i)} + b) \geq 1$中的参数 $\vec w, b$ , 使得其具有最大的间隔 $\gamma$ , 也就: \arg\max_{\vec w,b}\frac{2}{\|\vec w\|}s.t. y^{(i)}(\vec w^T \vec x{(i)} +b) \geq 1, i=1,...,m显然, 为了最大化间隔 $\gamma$ , 我们仅需要最大化 $|\vec w|^{-1}$ , 这就等于最小化 $|\vec w|^2$, 于是上式等价为: \arg\min_{\vec w,b} \frac{1}{2}\|\vec w\|^2 \arg\min_{\vec w,b} \frac{1}{2}\vec w^T\vec w \tag 1s.t. y^{(i)}(\vec w^T \vec x{(i)} +b) \geq 1, i=1,...,m下图即为SVM示意图, 注意,图中的1可以被任意常数替换(只要前面乘上对应的系数即可, =0说明在超分类平面上, !=0说明在两侧) 以上就是线性可分时的SVM基本型(现实中大多数问题是线性不可分的, 所以线性可分的SVM没有太多实用价值) 1.2 对偶问题1.2.1 问题说明凸二次规划问题(convex quadratix programming): 目标函数是变量的二次函数, 约束条件是变量的线性不等式 对偶问题(dual problem):在求出一个问题解的同时, 也给出了另一个问题的解 我们希望通过求解式(1)来得到具有最大间隔的划分超平面的模型参数,由于该式是一个凸二次规划问题 因此,对该式使用拉格朗日乘子法得到其”对偶问题” 对于式(1)的每条样本点约束添加拉格朗日乘子 $\alpha^{(i)} \geq 0$, 则该问题的拉格朗日函数为: L(\vec w,b,\alpha) = \frac{1}{2}\|\vec w\|^2 +\sum_{i=1}^{m}\alpha^{(i)} (1-y^{(i)}(\vec w^T \vec x^{(i)} +b))\tag 2其中, $\vec \alpha = (\alpha^{(1)}, \alpha^{(2)},…,\alpha^{(m)}) ,每一个\alpha^{(i)}均为标量$ .接着对 $L(\vec w,b,\vec \alpha)$ 对 $\vec w$ 和 $b$ 求偏导, 并令其为0, 可得: \frac{\partial L(\vec w,b,\vec \alpha)}{\partial \vec w} = \vec w - \sum_{i=1}^{m} \alpha^{(i)}y^{(i)}\vec x^{(i)} = 0 \tag 3\frac{\partial L(\vec w,b,\vec \alpha)}{\partial b} = -\sum_{i=1}^{m}\alpha^{(i)} y^{(i)} = 0 \tag 4将(3)和(4)代入(2)式中, 消去 $\vec w$ 和 $b$ ( 注意, 这里 $\sum_{i=1}^{m}\alpha^{(i)} y^{(i)} = 0$, 但是不代表 $\alpha^{(i)} y^{(i)} = 0$ ), 可得: L(\vec w, b, \vec \alpha) = \frac{1}{2}\bigg( \sum_{i=1}^{m}\alpha^{(i)} y^{(i)}\vec x^{(i)} \bigg)^2 + \sum_{i=1}^{m} \alpha^{(i)} - \sum_{i=1}^{m}\alpha^{(i)} y^{(i)} \Big( \sum_{j=1}^{m}\alpha^{(j)} y^{(j)} \vec x^{(j)} \Big)^T \vec x^{(i)} - \sum_{i=1}^{m} \alpha^{(i)} y^{(i)}b= \sum_{i=1}^{m}\alpha^{(i)} - \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha^{(i)} y^{(i)} \alpha^{(i)} y^{(j)} \vec x^{(i)T} \vec x^{(j)}这里 $\vec x^{(i)},\vec x^{(j)}$ 位置可互换, 为了好看,我将 $\vec x^{(i)}$ 写在了前面. 到此, 我们就得到了式(2)的对偶问题: \arg\max_{\vec \alpha} \bigg( \sum_{i=1}^{m}\alpha^{(i)} - \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha^{(i)} \alpha^{(j)} y^{(i)} y^{(j)} \vec x^{(i)T} \vec x^{(j)} \bigg) \tag 5s.t. \sum_{i=1}^{m} \alpha^{(i)} y{(i)} = 0, 其中 \alpha^{(i)} \geq 0为了满足原始问题(1) 和对偶问题(5)之间的充分必要条件, 上述推导过程还需要满足KKT(Karush-Kuhn-Tucker)条件(其中前两条已经在上述推导过程中满足) , 即要求: \begin{cases} \alpha^{(i)} \geq 0 ; \\ y^{(i)} f(\vec x^{(i)}) - 1 \geq 0 ; \\ \alpha^{(i)}(y^{(i)} f(\vec x^{(i)}) - 1 ) = 0. \end{cases}当我们解出上式得到 $\vec \alpha$ 后, 就可以通过求得 $\vec w$ 和 $b$ 的值, 进而可得到划分超平面对应的模型: f(\vec x) = \vec w ^T \vec x +b = \sum_{i=1}^{m} \alpha^{(i)} y^{(i)} \vec x^{(i)T} \vec x +b根据KKT条件我们可以轻易得出, 对任意的训练样本 $(\vec x^{(i)} , y^{(i)})$ , 总有 $\alpha^{(i)} = 0$ 或 $y^{(i)} f(\vec x^{(i)}) = 1$ . 若 $\alpha^{(i)} = 0$ , 则该项对应的样本不会出现在求和项中 ; 若 $\alpha^{(i)} &gt; 0$ , 则必有 $y^{(i)} f(\vec x^{(i)}) = 1$ , 这说明该样本点出现在最大间隔边界上, 是一个支持向量. 这显示出支持向量机的一个重要性质: 训练完成后, 大部分的训练样本都不需要保留(该样本对应的系数 $\alpha^{(i)}=0$ ), 最终模型仅与支持向量有关. 使用SMO算法求对偶问题的解从(5)式可以看出, 这仍是一个二次规划问题, 可以使用通用的二次规划法来求解, 但是, 该问题的规模正比于训练样本数量, 在实际任务中使用通用解法会造成很大的开销, 因此, 需要使用更高效的算法—-SMO(Sequential Minimal Optimization, 序列最小算法) SMO的基本思路: 先固定 $\alpha^{(i)}$ 之外的所有参数, 然后求 $\alpha^{(i)}$ 上的极值. 但是这里由于 $\alpha^{(i)}$ 之间不是互相独立的, 需要满足约束 $\sum_{i=1}^{m} \alpha^{(i)} y^{(i)}$ , 即一个分量改变, 另一个也要随之改变,因此每次在优化变量中选取两个分量 $\alpha^{(i)}$ 和 $\alpha^{(j)}$ ,并将其他参数固定, 然后在参数初始化后, 不断执行如下两个步骤直至收敛: 选取一对需要更新的变量 $\alpha^{(i)}$ 和 $\alpha^{(j)}$ 固定 $\alpha^{(i)}$ 和 $\alpha^{(j)}$ 以外的参数, 求解(5)式更新后的 $\alpha^{(i)}$ 和 $\alpha^{(j)}$ 具体的求解过程如下: 首先假设需要优化的参数是 $\alpha^{(i)}$ 和 $\alpha^{(j)}$ , 于是我们将剩下的分量 $\sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)}$ 固定, 作为常数处理, 可得下式: \alpha^{(i)} y^{(i)} + \alpha^{(j)} y^{(j)} = -\sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)} = C对上式两边同乘以 $y^{(j)}$ ,由于 $y^{(j)}\times y^{(j)} = 1$ 可得: \alpha^{(j)} = Cy^{(j)} - \alpha^{(i)} y^{(i)} y^{(j)} = y^{(j)}(C - \alpha^{(i)} y^{(i)})将上式代入(5)式, 消去变量 $\alpha^{(j)}$ , 得到一个关于 $\alpha^{(i)}$ 的单变量二次规划问题, 所有的常数项用 $C$ 表示, (5)式被转换成如下,: F(\alpha^{(i)}) = \alpha^{(i)} + \Big( y^{(j)}(C - \alpha^{(i)} y^{(i)}) \Big) - \frac{1}{2}\alpha^{(i)} \alpha^{(i)} y^{(i)}y^{(i)}\vec x^{(i)T}\vec x^{(i)} - \frac{1}{2}\Big( y^{(j)}(C - \alpha^{(i)} y^{(i)}) \Big)^2y^{(j)}y^{(j)}\vec x^{(j)T}\vec x^{(j)}- \alpha^{(i)} \Big( y^{(j)}(C - \alpha^{(i)} y^{(i)}) \Big) y^{(i)}y^{(j)}\vec x^{(i)T} \vec x^{(j)}- \alpha^{(i)}y^{(i)}\sum_{k=1,k\neq i,j}^{m}\alpha^{(k)}y^{(k)}\vec x^{(i)T} \vec x^{(k)} - \Big( y^{(j)}(C - \alpha^{(i)} y^{(i)}) \Big) y^{(j)}\sum_{k=1,k\neq i,j}^{m}\alpha^{(k)}y^{(k)}\vec x^{(j)T}\vec x^{(k)}= \alpha^{(i)} + \Big( y^{(j)}(C - \alpha^{(i)} y^{(i)}) \Big) - \frac{1}{2}(\alpha^{(i)})^2\vec x^{(i)T}\vec x^{(i)} - \frac{1}{2} \big( C - \alpha^{(i)}y^{(i)} \big)^2 \vec x^{(j)T}\vec x^{(j)} - \alpha^{(i)} \Big( (C - \alpha^{(i)} y^{(i)}) \Big) y^{(i)}\vec x^{(i)T} \vec x^{(j)} - \alpha^{(i)}y^{(i)}v^{(i)} - \big(C- \alpha^{(i)}y^{(i)} \big)v^{(j)} + C= \alpha^{(i)} + \Big( y^{(j)}(C - \alpha^{(i)} y^{(i)}) \Big) - \frac{1}{2}(\alpha^{(i)})^2K_{i,i} - \frac{1}{2} \big( C - \alpha^{(i)}y^{(i)} \big)^2 K_{j,j} - \alpha^{(i)} \Big( (C - \alpha^{(i)} y^{(i)}) \Big) y^{(i)}K_{i,j} - \alpha^{(i)}y^{(i)}v^{(i)} - \big(C- \alpha^{(i)}y^{(i)} \big)v^{(j)} + C上式为了简便, 将 $\vec x^{(i)T}\vec x^{(j)}$ 简记为 $K_{i,j}$ (后文会用K代表核函数, 这里姑且认为此时的核函数 $K$ 为恒等映射),将上式对 $\alpha^{(i)}$ 求导, 并令其等于0, 可得: \frac{\partial F(\alpha^{(i)})}{\partial \alpha^{(i)}} = 1 - y^{(i)}y^{(j)} - \alpha^{(i)}K_{i,i} + y^{(i)}(C-\alpha^{(i)} y^{(i)})K_{j,j} - \Big( C-\alpha^{(i)}y^{(i)} - \alpha^{(i)} y^{(i)} \Big)y^{(i)}K_{i,j} - y^{(i)}v^{(i)} + y^{(i)}v^{(j)}= 1-y^{(i)}y^{(j)} -\alpha^{(i)} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big) + Cy^{(i)}K_{j,j} - Cy^{(i)}K_{i,j} - y^{(i)}\big(v^{(i)} -v^{(j)} \big) = 0下面对上式进行变形, 使得可以用 $\alpha{old}^{(i)}$ 来更新 $\alpha{new}^{(i)}$ . 因为SVM对数据点的预测值为: $f(\vec x) = \sum_{i=1}^{m}\alpha^{(i)} y^{(i)} K(\vec x^{(i)},\vec x) + b$, 则 $v^{(i)}$ 以及 $v^{(j)}$ 的值可以表示成: v^{(i)} = \sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)} K_{i,k} = f(x^{(i)}) - \alpha^{(i)} y^{(i)} K_{i,i} - \alpha^{(j)} y^{(j)} K_{i,j} + bv^{(j)} = \sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)} K_{j,k} = f(x^{(j)}) - \alpha^{(j)} y^{(j)} K_{j,j} - \alpha^{(i)} y^{(i)} K_{j,i} + b将 $\alpha^{(j)} = y^{(j)}(C - \alpha^{(i)} y^{(i)})$ 带到上式, 可得到 $v^{(i)} - v^{(j)}$ 的表达式为: v^{(i)} - v^{(j)} = f(x^{(i)}) - f(x^{(j)}) - \alpha^{(i)} y^{(i)} K_{i,i} + \Big( y^{(j)}(C - \alpha^{(i)} y^{(i)}) \Big) y^{(j)} K_{j,j} - \Big( y^{(j)}(C - \alpha^{(i)} y^{(i)}) \Big) y^{(j)}K_{i,j} + \alpha^{(i)}y^{(i)}K_{j,i}= f(x^{(i)}) - f(x^{(j)}) - \alpha^{(i)}y^{(i)}K_{i,i} + CK_{j,j} - \alpha^{(i)}y^{(i)}K_{j,j} - CK_{i,j} + 2\alpha^{(i)}y^{(i)}K_{i,j}= f(x^{(i)}) - f(x^{(j)}) - \alpha^{(i)}y^{(i)} \Big( K_{i,i} + K_{j,j} -2K_{i,j} \Big)+ CK_{j,j} - CK_{i,j}注意 $v^{(i)} - v^{(j)}$ 中 $\alpha^{(i)}$ 是更新前初始化的值, 我们将其记作 $\alpha^{(i)}{old}$ ,以便与我们期望获得的更新后的分量 $\alpha^{(i)}{new}$ 相区分 , 将 $v^{(i)} - v^{(j)}$ 的表达式代入 $\frac{\partial F(\alpha^{(i)})}{\partial \alpha^{(i)}_{new}}$ 中 , 可得到: \frac{\partial F(\alpha^{(i)}_{new})}{\partial \alpha^{(i)}_{new}} = 1-y^{(i)}y^{(j)} -\alpha^{(i)}_{new} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big) + Cy^{(i)}K_{j,j} - Cy^{(i)}K_{i,j} - y^{(i)}\bigg (f(x^{(i)}) - f(x^{(j)}) - \alpha^{(i)}_{old}y^{(i)} \Big( K_{i,i} + K_{j,j} -2K_{i,j} \Big)+ CK_{j,j} - CK_{i,j} \bigg)= \big( y^{(i)} \big)^2 -y^{(i)}y^{(j)} - y^{(i)}f(x^{(i)}) + y^{(i)}f(x^{(j)}) - \alpha^{(i)}_{new} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big) + \alpha^{(i)}_{old} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big)= f(x^{(j)}) - y^{(j)} - \big( f(x^{(i)}) -y^{(i)} \big) - \alpha^{(i)}_{new} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big) + \alpha^{(i)}_{old} \Big( K_{i,i} + K_{j,j} - 2K_{i,j}\Big)我们记 $E^{(i)}$ 为SVM预测值与真实值的误差: $E^{(i)} = f(x^{(i)}) - y^{(i)}$ . 并令 $\eta = K{i,i} + K{j,j} - 2K_{i,j}$ , 则最终的一阶导数表达式可以简化为: \frac{\partial F(\alpha^{(i)}_{new})}{\partial \alpha^{(i)}_{new}} = -\eta \alpha^{(i)}_{new} + \eta \alpha^{(i)}_{old} + y^{(i)}\big(E^{(j)} - E^{(i)} \big) = 0由此, 我们可以根据当前的参数值, 直接得到更新后的参数值: \alpha^{(i)}_{new} = \alpha^{(i)}_{old} + \frac{y^{(i)}\big(E^{(j)} - E^{(i)} \big)}{\eta} => \alpha^{(i)}_{new, unclipped} \tag 6这里注意, (6)式的推导过程并未考虑下面的约束, 因此, 我们暂且将(6)式中的 $\alpha^{(i)}{new}$ 记作 $\alpha^{(i)}{new, unclipped}$, 然后考虑如下约束: \alpha^{(i)} y^{(i)} + \alpha^{(j)} y^{(j)} = -\sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)} = C0 \leq \alpha^{(i)} , \alpha^{(j)} \leq C我们分别以 $\alpha^{(i)}, \alpha^{(j)}$ 为坐标轴, 于是上述约束可以看作是一个方形约束(Bosk constraint), 在二维平面中我们可以看到这是个限制在方形区域中的直线, 如下图所示, 直线在方形区域内滑动(对应不同的截距), 同时 $\alpha^{(i)}_{new}$ 的上下边界也在改变: 当 $y^{(i)} \neq y^{(j)}$ 时(如左图), 限制条件可以写成 $\alpha^{(i)} - \alpha^{(j)} = \xi$ ,根据 $\xi$ 的正负可以得到不同的上下界, 因此 $\alpha^{(i)}_{new}$ 的上下界可以统一表示成: 下界: $L = \max(0, \alpha^{(i)}{old} - \alpha^{(j)}{old})$ 上界: $H = \min(C, C + \alpha^{(i)}{old} - \alpha^{(j)}{old})$ 当 $y^{(i)} = y^{(j)}$ 时(如右图), 限制条件可以写成 $\alpha^{(i)} + \alpha^{(j)} = \xi$ , 于是 $\alpha^{(i)}_{new}$ 的上下界为: 下界: $L = \max(0,\alpha^{(i)}{old} + \alpha^{(j)}{old} - C)$ 上界: $H = \min(C, \alpha^{(i)}{old} + \alpha^{(j)}{old})$ 根据得到的上下界, 我们可以得到”修剪”后的 $\alpha^{(i)}_{new,clipped}$ : \alpha^{(i)}_{new,clipped} = \begin{cases} H & \alpha^{(i)}_{new,unclipped} > H \\ \alpha^{(i)}_{new,unclipped} & L \leq \alpha^{(i)}_{new,unclipped} \leq H \\ L & \alpha^{(i)}_{new,unclipped} < L \end{cases} \tag 7得到了 $\alpha^{(i)}{new,clipped}$ 以后, 便可以根据 $\alpha^{(i)}{old} y^{(i)} + \alpha^{(j)}{old} y^{(j)}= \alpha^{(i)}{new}y^{(i)} + \alpha^{(j)}{new}y^{(j)}$ 得到 $\alpha^{(j)}{new}$ : \alpha^{(j)}_{new,clipped} = \alpha^{(j)}_{old} + y^{(i)}y^{(j)}\big( \alpha^{(i)}_{old} - \alpha^{(i)}_{new,clipped} \big) \tag 8通过(7)(8)式, 我们便可以高效的计算出更新后的 $\alpha^{(i)}$ 和 $\alpha^{(j)}$ . 当更新了一对 $\alpha^{(i)}$ 和 $\alpha^{(j)}$ 之后, 我们需要计算偏移项 $b$ 注意到, 对于任意支持向量 $(\vec x^{(s)} , y^{(s)})$ , 都有 $y^{(s)} f(x^{(s)}) = 1$ , 即: y^{(s)} \Big( \sum_{i \in S} \alpha^{(i)} y^{(i)} \vec x^{(i)T} \vec x^{(s)} + b\Big) = 1式中 $S$ 为所有支持向量的下标集. 理论上, 可以选取任意支持向量来获得 $b$ , 但现实中我们采取更加鲁棒的做法: 使用所有支持向量求解的平均值(式中所有量均已知, $\vec \alpha$ 使用的是支持向量对应的系数): b = \frac{1}{|S|} \sum_{s\in S} \bigg( \frac{1}{y^{(s)}} - \sum_{i \in S} \alpha^{(i)} y^{(i)}\vec x^{(i)T} \vec x^{(s)} \bigg)还有另一种更新 $b$ 的方式是, 只使用当前更新的变量 $\alpha^{(i)}{new}$ 和 $\alpha^{(j)}{new}$ 来对 $b$ 进行更新,如此一来, 为了满足KKT条件, 就有以下几种情况: 如果 $\alpha^{(i)}{new}$ 在界内(即此时 $0 &lt; \alpha^{(i)}{new} &lt; C$ , 当前对应样本为支持向量), 则 $b = b^{(i)}_{new}$ 如果 $\alpha^{(j)}{new}$ 在界内(即此时 $0 &lt; \alpha^{(j)}{new} &lt; C$ , 当前对应样本为支持向量), 则 $b = b^{(j)}_{new}$ 如果 $\alpha^{(i)}{new}$ 和 $\alpha^{(j)}{new}$ 都在界上,且 $L \neq H$时, 则 $b^{(i)}{new}$ 和 $b^{(j)}{new}$ 之间的所有的值都符合KKT条件, SMO一般选择终点作为新的偏移量: $b{new} = \frac{b^{(i)}{new} + b^{(j)}_{new}}{2}$ 以上讨论中, $b^{(i)}{new}$ 的推导过程为, 当 $\alpha^{(i)}{new}$ 在界内时, 对应的样本为支持向量 (根据KKT条件得出) , 此时 $y^{(i)}(\vec w^T \vec x^{(i)} +b) = 1$ , 两边同时乘上 $y^{(i)}$ ,得到 $\sum{k=1}^{m}\alpha^{(k)}y^{(k)}K{k,i} + b = y^{(i)}$, 将该式展开, 得到: b^{(i)}_{new} = y^{(i)} - \sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)}K_{k,i} - \alpha^{(i)}_{new}y^{(i)}K_{i,i} - \alpha^{(j)}_{new}y^{(j)}K_{j,i}其中前两项可以写成: y^{(i)} - \sum_{k=1,k\neq i,j}^{m} \alpha^{(k)} y^{(k)}K_{k,i} = -E^{(i)} + \alpha^{(i)}_{old}y^{(i)}K_{i,i} + \alpha^{(j)}_{old}y^{(j)}K_{j,i} + b_{old}于是有: b^{(i)}_{new} = -E^{(i)} - \big( \alpha^{(i)}_{new} - \alpha^{(i)}_{old} \big)y^{(i)} K_{i,i} - \big(\alpha^{(j)}_{new} - \alpha^{(j)}_{old} \big)y^{(j)}K_{j,i} + b_{old}同理有: b^{(j)}_{new} = -E^{(j)} - \big( \alpha^{(j)}_{new} - \alpha^{(j)}_{old} \big)y^{(j)} K_{j,j} - \big(\alpha^{(i)}_{new} - \alpha^{(i)}_{old} \big)y^{(j)}K_{i,j} + b_{old}如何恰当的选取需要更新的变量 $\alpha^{(i)}$ 和 $\alpha^{(j)}$采用启发式的规则来选取, 直觉上我们知道, 我们应该首先优化那些违反KKT条件最严重的样本, 因此我们首先首先遍历所有满足约束条件 $0 &lt; \alpha^{(i)} &lt; C$ 的样本点, 即位于间隔边界上的支持向量点(直觉上也能发现这些点最有可能分类错误), 检验它们是否满足KKT条件. 如果这些样本都满足KKT条件，则遍历整个训练样本集，判断它们是否满足KKT条件，直到找到一个违反KKT条件的变量 $\alpha^{(i)}$ (即使 $\alpha^{(i)}$ 位于边界上,也有可能违反KKT条件). 当找到了第一个分量 $\alpha^{(i)}$ 后, 接下来寻找第二个分类 $\alpha^{(j)}$, 而选取的标准是使得它有足够大的变化, 也就是说使选取的两变量所对应的样本之间的间隔最大, 一种直观的解释是, 这样的两个变量有很大的差别, 与对两个相似的变量进行更新相比(相似说明有可能属于同一类, 更新意义不大), 对它们进行更新会带给目标函数值更大的变化. 第二个乘子的迭代步长正比于 $|E^{(i)} - E^{(j)}|$ , 因此, 我们希望选择的乘子能够具有最大的 $|E^{(i)} - E^{(j)}|$. 即当 $E^{(i)}$ 为正时选择绝对值最大的赋值 $E^{(j)}$ , 反之, 选择正值最大的 $E^{(i)}$ 1.3 核函数在之前的讨论中,我们假设 训练样本 是线性可分的, 然而在现实任务中, 原始样本空间内也许并不存在一个能正确划分两类样本的超平面, 对于这样的问题, 可将一样本从原始空间映射到一个更高维的特征空间, 使得样本在这个特征空间内线性可分 . 需要知道, 如果原始空间是有限维, 即属性数有限, 那么一定存在一个高维特征空间使样本可分 令 $\phi(\vec x)$ 表示将 $\vec x$ 映射后的特征向量, 于是, 在特征空间中划分超平面所对应的模型可表示为: f(\vec x) = \vec w^T \phi(\vec x) + b类似式(1), 有: \arg\min_{\vec w,b} \frac{1}{2} \|w\|^2s.t. y^{(i)}\big( \vec w^T \phi (\vec x^{(i)}) + b \big), i=1,2,..,m其对偶问题为: \arg\max_{\vec \alpha} = \sum_{i=1}^{m}\alpha^{(i)} - \frac{1}{2}\sum_{i=1}^{m} \sum_{j=1}^{m} \alpha^{(i)} \alpha^{(j)} y^{(i)} y^{(j)} \phi(\vec x^{(i)})^T \phi(\vec x^{(j)}) \tag 9s.t. \sum_{i=1}^{m} \alpha^{(i)} y^{(i)} = 0, \alpha^{(i)} \geq 0 , i = 1,2,...,m求解上式涉及到计算 $\phi(\vec x^{(i)})^T \phi(\vec x^{(j)}$ , 这是样本 $\vec x^{(i)}$ 与 $\vec x^{(j)}$ 映射到特征空间之后的内积, 由于特征空间维数可能很高, 甚至是无穷维, 因此直接计算 $\phi(\vec x^{(i)})^T \phi(\vec x^{(j)}$ 是很困难的, 为了避开这个障碍, 可以设想这样一个函数: K \big(\vec x^{(i)}, \vec x^{(j)} \big) = \phi(\vec x^{(i)})^T \phi(\vec x^{(j)}即 $x^{(i)}$ 与 $x^{(j)}$ 在特征空间的内积等于它们在原始样本空间中通过函数 $K(\cdot, \cdot)$ 计算的结果. (有可能是先内积再函数映射, 也有可能是求范式再函数映射). 于是(9)式可重写为: \arg\max_{\vec \alpha} \sum_{i=1}^{m}\alpha^{(i)} - \frac{1}{2}\sum_{i=1}^{m} \sum_{j=1}^{m}\alpha^{(i)} \alpha^{(j)} y^{(i)} y^{(j)} K\big(\vec x^{(i)}, \vec x^{(j)} \big)s.t. \sum_{i=1}^{m} \alpha^{(i)} y^{(i)} = 0\alpha^{(i)} \geq 0, i=1,2,...,m注意, 前面几个小节的推导过程也用了符号 $K$ , 但是就像前面所说的, 前几个小节的 $K$ 是为了方便书写而使用的, 你可以把它看作是一个恒等映射的核函数 当我们解出上式得到 $\vec \alpha$ 后, 就可以得到划分超平面对应的模型(式中 $\vec x$ 为样本点, $f(\vec x)$ 为该样本点的预测结果): f(\vec x) = \vec w ^T \vec x +b = \sum_{i=1}^{m} \alpha^{(i)} y^{(i)} K\big(\vec x, \vec x^{(j)} \big) +b核函数定理: 令 $\chi$ 为输入空间 $K(\cdot, \cdot)$ 是定义在 $\chi \times \chi$ 上的对称函数, 则 $K(\cdot, \cdot)$ 是核函数 当且仅当 对于任意数据 $D = \{\vec x^{(1)}, \vec x^{(2)},…,\vec x ^{(m)} \}$ , 核矩阵 $K$ 总是半正定的 从以上分析可知, 核函数的选择决定了特征空间的好坏, 因此, 一个合适的核函数,就成为了支持向量机的最大变数. 下面是几种常用的核函数: 名称 表达式 参数 线性核 高斯核 拉普拉斯核 Sigoid核 此外,还可以通过函数组合得到: 若 $K_1$ 和 $K_2$ 都是核函数 ,则对任意的正数 $\gamma_1, \gamma_2$ , 其线性组合 $\gamma_1 K_1 + \gamma_2 K_2$ 也是核函数 若 $K_1$ 和 $K_2$ 为核函数, 则函数的直积 $K_1 \otimes K_2 (\vec x , \vec z) = K_1(\vec x, \vec z) K_2(\vec x, \vec z)$ 若 $K_1$ 是核函数, 则对任意函数 $g(\vec x)$, $K(\vec x, \vec z) = g(\vec x) K_1(\vec x, \vec z) g(\vec z)$ 也是核函数 1.4 软间隔与正则化在实现任务中, 往往很难确定合适的核函数, 使得训练样本在特征空间中线性可分, 即便是找到了, 也无法断定是否是由于过拟合造成的 , 因此, 我们需要 允许支持向量机在一些样本上出错 , 以缓解上面的问题. 硬间隔(hard margin)与软间隔(soft margin)的区分: 硬间隔: 所有样本都必须分类正确 软间隔: 允许某些样本不满足约束(11)式(即,预测结果和真实结果符号相反,分类错误,或预测结果绝对值小于1,相当于”改变”了支持向量的位置) 我们要在最大化间隔的同时, 使得不满足约束的样本应尽可能的少, 于是, 优化目标可写为: \min_{\vec w,b} \frac{1}{2} \|w\|^2 + C\sum_{i=1}^{m} l_{0/1} \big( y^{(i)} (\vec w^T x^{(i)}+b) - 1\big) \tag {10}y^{(i)} (\vec w^T \vec x^{(i)} +b) \geq 1 \tag {11}其中, $C&gt;0$ 是一个常数(注意与前几节推导SVM时的常数区分), $l_{0/1}$ 是 “0/1 损失函数”: l_{0/1} (z) = \begin{cases} 1, & \text{if } z < 0 ; \\ 0, & \text{otherwise}. \end{cases}当C无穷大时, (10)式就会迫使所有样本均满足约束, 也就是令所有训练样本都分类正确(容易产生过拟合), 当C取有限值时, 则允许有一些样本不满足约束(11)式. 但是, $l_{0/1}$ 非凸, 不连续, 数学性质不好, 因此, 通常使用其他函数来替代, 称为” 替代损失”, 下面为三种常用的替代损失: hinge损失: $l_{hinge}(z) = max(0,1-z)$ 指数损失(exponential loss): $l_{exp}(z) = exp(-z)$ 对率损失(logistic loss): $l_{log}(z) = log(1+ exp(-z))$ 若采用hinge损失损失, 则可以引入”松弛变量”(slack variables) $\xi^{(i)} \geq 0$ ,每一个样本都有一个对应的松弛变量, 用以表征该样本不满足约束(11)的程度 则可将(10)式重写为: \min_{\vec w, b, \xi^{(i)}} \frac{1}{2} \|\vec w\|^2 + C \sum_{i=1}^{m} \xi^{(i)} \tag {12}s.t. y^{(i)} (\vec w^T x^{(i)} + b) \geq 1- \xi ^{(i)}\xi^{(i)} \geq , i=1,2,...,m.可以看出, 上式是与之前推导相似的二次规划问题, 只不过是约束条件变的宽松了(为了允许一些样本犯错), 因此,同样利用拉格朗日乘子法求解, 首先得到上式的拉格朗日函数: L(\vec w, b, \vec \alpha, \vec \xi, \vec \mu) = \frac{1}{2} \|w\|^2 + C \sum_{i=1}^{m} \xi^{(i)} + \sum_{i=1}^{m}\alpha^{(i)}\big(1- \xi^{(i)} - y^{(i)}(\vec w^T\vec x^{(i)} +b) \big) - \sum_{i=1}^{m} \mu^{(i)} \xi^{(i)}其中, $\alpha^{(i)} \geq 0, \mu^{(i)} \geq 0$ 是拉格朗日乘子, 令 $L(\vec w, b, \vec \alpha, \vec \xi, \vec \mu)$ 对 $\vec w, b, \vec \alpha, \vec \xi$ 求偏导, 并令其为0 , 可得: \vec w =\sum_{i=1}^{m} \alpha^{(i)} y^{(i)} \vec x^{(i)}0 = \sum_{i=1}^{m} \alpha^{(i)} y^{(i)}C = \alpha^{(i)} + \mu^{(i)} 得到(12)式对应的对偶问题如下: \max_{\alpha} \sum_{i=1}^{m} \alpha^{(i)} - \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha^{(i)} \alpha^{(j)} y^{(i)} y^{(j)} K_{i,j}s.t. \sum_{i=1}^{m} \alpha^{(i)} y^{(i)} = 00 \leq \alpha^{(i)} \leq C , i=1,2,...,m可以看到, 此时, $\alpha^{(i)}$ 的约束条件变成了 $0 \leq \alpha^{(i)} \leq C$ , 上式的KKT条件要求为: \begin{cases} \alpha^{(i)} \geq 0, \mu^{(i)} \geq 0 \\ y^{(i)}f(\vec x^{(i)}) -1 +\xi^{(i)} \geq 0, \\ \alpha^{(i)} \big( y^{(i)}f(\vec x^{(i)}) - 1 + \xi^{(i)} \big) = 0, \\ \xi^{(i)} \geq 0, \mu^{(i)} \xi^{(i)} = 0 \end{cases}于是, 从KKT条件中我们可以看出, 对任意的训练样本 $(\vec x^{(i)}, y^{(i)})$, 总有 $\alpha^{(i)} = 0$ 或 $y^{(i)} f(\vec x^{(i)}) = 1 - \xi^{(i)}$. 若 $\alpha^{(i)} = 0$, 则该样本不会对 $f(\vec x)$ 产生影响. 若 $\alpha^{(i)} &gt; 0$, 则必有 $y^{(i)} f(\vec x^{(i)}) = 1 - \xi^{(i)}$, 即该样本是支持向量 因为 $C = \alpha^{(i)} + \mu^{(i)}$ , 所以, 若 $\alpha^{(i)} &lt; C$ , 则有 $\mu^{(i)} &gt; 0$ , 进而有 $\xi^{(i)} = 0$, 即该样本在最大间隔边界上(是否也就是支持向量?) 若 $\alpha^{(i)} = C$ , 则有 $\mu^{(i)} = 0$, 此时若 $\xi^{(i)} \leq 1$, 则该样本落在最大间隔内部, 若 $\xi^{(i)} &gt; 1$, 则该样本被错误分类. 以上讨论, 我们可以看出, 最终的模型依然只与支持向量有关, 保持了稀疏性(hinge损失有一块平坦的零区域,这使得SVM的解具有稀疏性) 以上是对使用hinge损失时讨论的情况, 还可以将其替换成别的损失函数以得到其他学习模型, 这些模型的性质与所用的替代函数直接相关, 但它们具有一个共性: 优化目标中的第一项用来描述划分超平面的”间隔”大小, 另一项用来表示训练集上的误差, 可写为更一般的形式: \min_{f} \Omega(f) + C\sum_{i=1}^{m} l(f(\vec x^{(i)}) , y^{(i)})其中, $\Omega(f)$ 称为”结构风险”(structural risk), 用于描述模型 $f$ 自身的性质; 第二项 $C\sum_{i=1}^{m} l(f(\vec x^{(i)})$ 称为”经验风险”(empirical risk), 用于描述模型与训练数据的契合程度. $C$ 用于到二者进行这种. 从预测误差的角度来看, 第二项相当于模型误差, 第一项相当于正则化项, 表述了模型本身的性质, 一方面, 这位引入领域知识和用户意图提供了途径, 另一方面, 该信息有助于消减假设空间, 降低过拟合风险 3. 问答为什么SVM的分类结果仅依赖于支持向量?百机p53 核函数中不同参数的影响https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&amp;mid=2247484495&amp;idx=1&amp;sn=4f3a6ce21cdd1a048e402ed05c9ead91&amp;chksm=fdb699d8cac110ce53f4fc5e417e107f839059cb76d3cbf640c6f56620f90f8fb4e7f6ee02f9&amp;scene=21#wechat_redirect 既然深度学习技术性能表现以及全面超越SVM, SVM还有存在的必要吗?6.Reference[1] https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&amp;mid=2247483937&amp;idx=1&amp;sn=84a5acf12e96727b13fd7d456c414c12&amp;chksm=fdb69fb6cac116a02dc68d948958ee731a4ae2b6c3d81196822b665224d9dab21d0f2fccb329&amp;scene=21#wechat_redirect [2] 西瓜书 [3] http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988419.html https://zhuanlan.zhihu.com/p/29212107]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>SVM</tag>
        <tag>核函数</tag>
        <tag>SMO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的动态数组]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84%E5%8A%A8%E6%80%81%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反向传播算法完整推导]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95%E5%AE%8C%E6%95%B4%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[链式法则神经网络计算过程对于神经网络中的单个神经元来说, 若输入信号为向量 $\vec x=(x_1, x_2, x_3, x_4, x_5)$ , 该层的权重为 $\vec w = (w_1, w_2, w_3, w_4, w_5)$, 偏置项为 $b$ , 那么该层的输出就为(其中$f$为激活函数): y= f(\sum_{i=1}^{n}w_i x_i +b)化简成向量形式($\vec w , \vec x$均为列向量)为: y = f(\vec w ^T \vec x +b)对于多层网络来说, 如下图所示 第一层为输入层, 神经元数量对应原始数据维数, 这一层不对数据进行输出, 直接输出 第二层为隐藏层, 可以有多个隐藏层, 每层神经元数量为中间特征维数(一般自定), 每层都具有一个权重矩阵, 将输入信号与权重矩阵做点乘运算, 加上偏置量以后按激活函数输出 第三层为输出层, 同样有一个权重矩阵, 若用于分类, 则神经元数量等于要分类的类别数 如果激活函数使用sigmoid函数, 则第二层和第三层的输出分别为(第一层输出为原始数据): 符号说明: $x$ : 向量 $x$ $x_i$ : 向量 $x$ 的第 $i$ 项 $x^{(i)}$ : 第 $i$ 个样本向量 $x_j^{(i)} : 第 $i$ 个样本向量中的 第 $j$ 项 几个重要结论 条件说明 说明及问题 结论 给定如下线性映射函数: $u = W x$ 其中 $x$ 是 $n$ 维向量, $W$ 是 $m\times n$ 的矩阵, $u$ 是 $m$维向量, 假设存在函数 $f(u)$ , 试求 $\nabla _w f$ 及 $\nabla _x f$ 因为 $w{ij}$ 只与 $u_i, x_j$ 有关(画出矩阵相乘示意图即可), 所以有: $\frac{\partial f}{\partial w{ij}} = \sum{k=1}^{m} \frac{\partial f}{\partial u_k} \frac{\partial u_k}{\partial w{ij}} = \sum{k=1}^{m} \Big( \frac{\partial f}{\partial u_k} \frac{\partial \sum{l=1}^{n} (w{kl} x_l)}{\partial w{ij}}\Big) = \frac{\partial f}{\partial ui} \frac{\partial \sum{l=1}^{n}(w{il} x_l)} {\partial w{ij}} = \frac {\partial f}{\partial ui} x_j$ 上式写成矩阵形式为: $\nabla _W f = (\nabla _u f) x^T$ 因为 $x_i$与每一个 $u_k$ 都有关, 所以可得: $\frac{\partial f}{x_i} = \sum{k=1}^{m} \frac{\partial f}{\partial uk} \frac{\partial u_k}{\partial x_i} = \sum{k=1}^{m} \Big( \frac{\partial f}{uk} \frac{\partial \sum{l=1}^{n} w{kl} x_l}{\partial x_i} \Big)= \sum{k=1}^{m} \Big( \frac{\partial f}{uk} w{ki} \Big) = [w{1i}, w{2i},…, w_{mi}]\left[ \begin{matrix} \frac{\partial f}{u_1} \ \frac{\partial f}{u_2} \ … \ \frac{\partial f}{u_2} \end{matrix} \right]$ 上式写成矩阵形式为: $\nabla _x f = W^T \nabla _u f$ 给定如下向量到向量的映射: $z=g(u)$ 写成分量形式为: $z_i = g(u_i)$ 在这里, 每个 $z_i$ 只和 $x_i$ 有关, 且每个分量采用了相同的映射函数$g$ 假设存在函数 $f(z)$, 试求 $\nabla _u f$ $\frac{\partial f}{\partial u_i} = \frac{\partial f}{\partial z_i} \frac{\partial z_i}{\partial u_i} = \frac{\partial f}{\partial z_i} g’(u_i)$ $\nabla _u f = \nabla _z f \odot g’(u)$ 给定下面的复合函数 # 推导过程说明 详细推导 简洁推导 Referencehttps://zhuanlan.zhihu.com/p/39195266 https://zhuanlan.zhihu.com/pytlab]]></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[正则化技巧总结]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[为了解决过拟合问题，通常有两种办法，第一是减少样本的特征（即维度），第二就是我们这里要说的”正则化”. 下面是一些可以帮助缓解过拟合现象的正则化技巧 使用正则项(Regularization)L1 RegularizationL1范数为: \|w\|_1 = |w_1| + |w_2| + ... + |w_n|L1正则项如下所示, 其中 $L_0$ 代表原始的不加正则项的损失函数, $L$ 代表加了正则项以后的损失函数, $m$ 则代表训练batch的样本大小 : L = L_0 + \lambda\|w\|_1 = L_0 + \lambda \sum_{w}|w|将上式对参数 $w$ 求导如下(由于正则项与 $b$ 无关, 因此参数 $b$ 的导数不变): \frac{\partial L}{\partial w} = \frac{\partial L_0}{\partial w} + \lambda sign(w)上式中 $sign(w)$ 表示 $w$ 的符号, 当 $w&gt;0$ 时, $sign(w)=1$ , 当 $w&lt;0$ 时, $sign(w)=-1$, 为了实现方便, 我们特意规定, 当 $w=0$ 时, $sign(w) = 0$ , 相当于去掉了正则项. 因此, 权重 $w$ 的更新表达式可如下表示: w \to w' = w - \eta \frac{\partial L_0}{\partial w} - \eta \lambda sign(w)L1正则化使模型参数稀疏的原理是什么?角度一: 解空间性状“百面机器学习” 角度二: 函数叠加(梯度下降更新公式)从以上的更新表达式我们可以看出, 当 $w$ 为正时, L1正则化会将更新后的 $w$ 变的再小一点, 而当 $w$ 为负时, L1正则化会将其变的更大一点—-因此L1的正则化效果就是让 $w$ 尽可能的向 $0$ 靠近, 即最终的 $w$ 参数矩阵会变的更加稀疏 角度三: 贝叶斯先验“百面机器学习” 补充: 为什么 L1 和 L2 分别对应拉普拉斯先验和高斯先验?为什么权重矩阵稀疏可以防止过拟合?可以从两个方面来理解: 1）特征选择(Feature Selection)： 大家对稀疏规则化趋之若鹜的一个关键原因在于它能实现特征的自动选择。一般来说，xi的大部分元素（也就是特征）都是和最终的输出yi没有关系或者不提供任何信息的，在最小化目标函数的时候考虑xi这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了对正确yi的预测。稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。 2）可解释性(Interpretability)： 另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型： $y=w1x1+w2x2+…+w1000*x1000+b$ （当然了，为了让 $y$ 限定在 $[0,1]$ 的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的 $w$ 就只有很少的非零元素，例如只有 5 个非零的 $wi$ ，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。但如果 1000 个 $wi$ 都非 0，医生面对这 1000 种因素，累觉不爱. $L0$ 范式和 $L1$ 范式都能实现稀疏, 为什么不选择用 $L0$ 而要用 $L1$?一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解 L2 Regulation(权重衰减/岭回归)L2范数为: \|w\|_1 = \sqrt {w_1^2 + w_2^2 + ... + w_n^2 }L2正则项如下所示, 其中 $L_0$ 代表原始的不加正则项的损失函数, $L$ 代表加了正则项以后的损失函数, 式中的系数 $\frac{1}{2}$ 主要是为了消去求导后产生的常数 $2$, 方便表示 (因为可以根据 $\lambda$ 的值来替代这些常数): L = L_0 + \lambda\|w\|^2_2 =L_0 + \lambda \sum_{w}w^2将上式对参数 $w$ 求导如下: \frac{\partial L}{\partial w} = \frac{\partial L_0}{\partial w} + 2\lambda w则, 权重 $w$ 的更新表达式可如下表示: w \to w' = w - \eta \frac{\partial L_0}{\partial w} - \eta 2\lambda w由于, $\eta, \lambda, m$ 三个值都是正的, 因此, 加上 $L2$ 正则化以后, 权重整体减小了, 这也是”权重衰减”的由来. 为何权重参数 $w$ 减小就可以防止过拟合?直观解释: 更小的权值w，从某种意义上说，表示网络的复杂度更低，对数据的拟合刚刚好（这个法则也叫做奥卡姆剃刀），而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果 “数学一点”的解释: 过拟合的时候，拟合函数的系数往往非常大，为什么？如下图所示，过拟合，就是拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大. 而正则化是通过约束参数的范数使其不要太大，所以可以在一定程度上减少过拟合情况。 L2 范式的好处是什么?防止过拟合: 最基本的好处是可以提高模型泛化能力, 防止过拟合 优化计算: 从优化或者数值计算的角度来说, L2正则化有利于提高模型训练速度, 加快计算 原因: https://www.cnblogs.com/callyblog/p/8094745.html L1 和 L2 的区别1. L1相对于L2能够产生更加稀疏的模型:原因见上面L1稀疏性的原理 2. 二者梯度下降速度不同:根据L1和L2的函数图像可以看出, L1是按照线性函数进行梯度下降的, 而L2则是按照二次函数, 因此, L1在下降时的速度是恒定的, 在接近于0的时候会很快就将参数更新成0 , 而L2在接近于0 时, 权重的更新速度放缓, 使得不那么容易更新为0 : 3. 二者解空间性状不同:这一点也可以解释为什么L1相比于L2更加稀疏的原因 数据增广(Data Augmentation)水平或垂直翻转图像、裁剪、色彩变换、扩展和旋转等等, 也可利用GAN辅助生成(不常用) DropoutDropout是指在深度网络的训练中, 以一定的概率随机的”临时丢弃”一部分神经元节点. 具体来讲, Dropout作用于每份小批量训练数据, 由于其随机丢弃部分神经元的机制, 相当于每次迭代都在训练不同结构的神经网络, 可以被认为是一种实用的大规模深度神经网络的模型继承算法. 对于包含 $N$ 个神经元节点的网络, 在Dropout的作用下可以看作为 $2^N$ 个模型的集成, 这 $2^N$ 个模型可认为是原始网络的子网络, 它们共享部分权值, 并且拥有相同的网络层数, 而模型整个的参数数目不变, 大大简化了运算. 对于任意神经元来说, 每次训练中都与一组随机挑选的不同的神经元集合共同进行优化, 这个过程会减弱全体神经元之间的联合适应性, 减少过拟合的风险, 增强泛化能力. 工作原理和实现: 应用Dropout包括训练和预测两个阶段, 在训练阶段中, 每个神经元节点需要增加一个概率系数, 在前向传播时, 会以这个概率选择是否丢弃当前的神经元 在测试阶段的前向传播计算时, 每个神经元的参数都会预先乘以概率系数p, 以恢复在训练中该神经元只有p的概率被用于整个神经网络的前向传播计算 Drop ConnectDrop Connect 是另一种减少算法过拟合的正则化策略，是 Dropout 的一般化。在 Drop Connect 的过程中需要将网络架构权重的一个随机选择子集设置为零，取代了在 Dropout 中对每个层随机选择激活函数的子集设置为零的做法。由于每个单元接收来自过去层单元的随机子集的输入，Drop Connect 和 Dropout 都可以获得有限的泛化性能 [22]。Drop Connect 和 Dropout 相似的地方在于它涉及在模型中引入稀疏性，不同之处在于它引入的是权重的稀疏性而不是层的输出向量的稀疏性。 早停早停法可以限制模型最小化代价函数所需的训练迭代次数。早停法通常用于防止训练中过度表达的模型泛化性能差。如果迭代次数太少，算法容易欠拟合（方差较小，偏差较大），而迭代次数太多，算法容易过拟合（方差较大，偏差较小）。早停法通过确定迭代次数解决这个问题，不需要对特定值进行手动设置。 Referencehttps://www.cnblogs.com/callyblog/p/8094745.html]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种损失函数深入解析]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E5%90%84%E7%A7%8D%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[常用损失函数及其形式 损失函数 形式 评分损失 各个损失函数详细解析绝对值损失别名 $L_1$ 损失 平方损失:平方损失的别名是 $L_2$ 损失 平方损失函数是由线性模型引出的. 对于最简单的线性模型, 可以用房屋面积和房屋价格来举例子, 假设我们已经知道了一些面积和价格的数据: 将其描绘出来如下图所示: 那么, 如果新来了一个面积, 我们能否根据已有的数据来预测它的价格, 这就是线性回归问题. 我们利用一条直线来拟合这些数据, 从而可以得到预测的价格, 如下图所示: 将这种最简单的线性回归一般化, 使其成为具有多个变量的线性模型, 就可以用向量的形式来表达, 如下所示: h_\theta (x) = \theta ^Tx对于上面的公式, 我们就可以求出多个不同的 $\theta$, 来得到不同的模型, 但是我们需要知道到底哪些模型是好的, 哪些是不好的, 因此, 就需要引入了评价机制来判断当前的参数 $\theta$ 是好还是坏, 这就引出了平方误差损失函数, 如下所示: J(\theta) = \frac{1}{2} \sum_{i=1}^{m}{(h_\theta(x^{(i)}) - y^{(i)})^2}这个公式本身非常好理解, 就是希望我们当前模型的参数 $\theta$ 可以让模型的输出结果与真实结果无限逼近. 但是问题是: 为什么是平方形式? 对此,数学解释如下: 一句话说明: 平方损失函数就是对theta的极大似然估计 首先, 预测结果和真实结果之间肯定是有误差的, 我们假设这个误差是 $\epsilon ^{(i)}$ , 那么就有如下公式: y^{(i)} = \theta ^T x^{(i)} + \epsilon ^{(i)}而一般在实际使用中, 我们的训练数据是海量的, 根据中心极限定力, 我们可以假定误差满足均值为0, 方差为 $\sigma ^2$ 的正态分布, 即 $\epsilon^{(i)} \sim N(0, \sigma ^2)$ : p(\epsilon^{(i)}) = \frac{1}{\sqrt {2 \pi } \sigma }exp(-\frac{(\epsilon^{(i)})^2}{2 \sigma ^2}) 这也就是说: p(y^{(i)} | x^{(i)};\theta) = \frac{1}{\sqrt {2 \pi } \sigma }exp(-\frac{(y^{(i)} - \theta ^T x^{(i)})^2}{2 \sigma ^2}) $p(y^{(i)} | x^{(i)};\theta)$ 代表在给定的 $x^{(i)}$ 和参数 $\theta$ 下, $y^{(i)}$的分布概率, 这可以看做是在给定的 $\theta$ 一个关于 $y$ 和$x$ 的函数. 与之相对的,我们也可以将其视为是关于参数 $\theta$ 的函数,如下所示: L(\theta) = L(\theta ; X, \vec y) = p(\vec y | X; \theta)注意到, $\epsilon^{(i)} , y^{(i)} , x^{(i)}$ 都是独立同分布的, 因此, 根据极大似然定理, 我们希望下面的式子能够取得最大值(也就是在给定数据的情况下, 我们希望找到一组参数 $\theta$ , 来使这些数据出现的概率最大, 也就是概率积最大) L(\theta) = \prod_{i=1}^{m}{p(y^{(i)} | x{(i)} ; \theta)} = \prod_{i=1}^{m}{\frac{1}{\sqrt{2\pi} \sigma} exp\Big( -\frac{ (y^{(i)} - \theta ^T x^{(i)})^2}{2\sigma ^2} \Big)}为方便计算, 对上式取对数, 可得: l(\theta) = log L(\theta) = log\prod_{i=1}^{m}{\frac{1}{\sqrt{2\pi} \sigma} exp\Big( -\frac{ (y^{(i)} - \theta ^T x^{(i)})^2}{2\sigma ^2} \Big)} = \sum_{i=1}^{m} log \frac{1}{sqrt{2\pi} \sigma} exp\Big( -\frac{(y^{(i)} - \theta ^T x^{(i)})^2}{2\sigma ^2} \Big) = mlog\frac{1}{\sqrt{2\pi} \sigma} - \frac{1}{\sigma ^2}\times \frac{1}{2}\sum_{i=1}^{m}(y^{(i)} - \theta ^T x^{(i)})^2为了让上面的式子取值最大, 那我们就只需要令下面的式子取值最小即可: \frac{1}{2} \sum_{i=1}^{m} ( y^{(i)} - \theta ^T x^{(i)}) ^2上面的形式恰好就是我们的平方误差损失函数(通常还需要对上面的损失函数做归一化, 也就是乘上 $\frac{1}{m}$ ), 这也是平方误差损失函数的来源. (但实际上, 要知道, 基于概率假设来说, 不一定非要是平方项, 另外, 无需在意 $\sigma$ 的具体值是什么) 交叉熵损失首先定义符号说明: $p^{(i)}$: 第i个样本类别为1的真实概率(如第i个样本真实类别为1, 则概率为1, 否则为0) $o^{(i)}$: 第i个样本预测类别为1的概率 $p_k^{(i)}$: 第i个样本类别为k的真实概率(如第i个样本真实类别为k, 则概率为1, 否则为0) $o_k^{(i)}$: 第i个样本预测类别为k的概率 面对二分类问题, 损失函数形式为: J(W,b) = -\Big[\frac{1}{m} \sum_{i=1}{m}\big(y^{(i)}logo^{(i)} + (1-y^{(i)})log(1-o^{(i)}) \big) \Big]面对多分类问题, 损失函数形式为: J(W,b) = -\Big[\frac{1}{m} \sum_{i=1}^{m} \sum_{k=1}^{n} y_k^{(i)} log o_k^{(i)} \Big]交叉熵衡量了两个分布之间的差异性, 当概率相等时, 交叉熵最大, 则损失函数达到最小(因为加了负号) 损失函数之间的区别和联系为什么分类问题要使用交叉熵损失而不用平方损失?]]></content>
      <categories>
        <category>其它</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ResNet及其多种变体深入解析]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-ResNet%2F</url>
    <content type="text"><![CDATA[1. ResNet提出动机首先文章提出了一个假设:有一个L层的深度神经网络, 如果我们在上面加入一层, 直观来讲得到的L+1层深度神经网络的效果应该至少不会比L层的差. 因为可以简单的设最后一层为前一层的恒等映射, 并且其它层参数设置不变. 但是, 通过实验发现, 当网络层数加深时, 网络的性能会下降, 也就是所谓的”模型退化”问题. 为了解决模型退化问题, 作者在基于以上假设, 作者认为,提出产生模型退化的根本原因很大程度上也许不在于过拟合, 而在于梯度消失问题. 对比到ResNet结构上就是说, 假设现有一个比较浅的网络（Shallow Net），这时在它后面再加上几个恒等映射层（Identity mapping），这样虽然增加了网络的深度，但理论上来说其性能表现不应该更差，也即更深的网络不应该带来训练集上误差的上升。 核心理论恒等短接(identity shortcut connection): ResNet提出的恒等短接模块用于直接跳过一个或多隔层, 以便让离输入层近的网络更加靠近输出层, 残差块的结构如下图所示: 他有两层, 每层的函数表达式可如下表示, 其中 $\sigma$ 代表激活函数ReLU: F(x) = \sigma(W_1 x)H(x) = F(x) + x()首先, 这里的 $H(x)$ 就是这个一块网络模型原始的拟合目标, 而x是这一段网络块的输入, 我们的最终目的是让网络学习从x 到 $H(x)$ 的映射, 也就是说, 我们希望能够让这一块网络学习到 $H(x) = x$ 的恒等映射. 同时, 为了加速计算, 我们不直接学习$H(x) = x$, 而是转而学习$H(x)$ 和 $x$ 之间的残差: $F(x)$. 也就是说, 现在的学习目的变成了 $F(x) = H(x) - x = 0$ . 并且, 由于残差结构学习的是一个恒等映射, 恒等映射在反向传播是, 可以将后一层网络的梯度值直接返回给前一层网络, 并且不会引起梯度消失问题, 因此, 即使网络变深了, 但是该网络的性能至少应该不会降低. 所以说, ResNet模块学习的只是一个恒等映射, 它可以在增加网络网络深度的同时, 不会降低它们的性能, 由此, 网络模型甚至可以打到上千层同时维持较高的模型性能 (注意,虽然,残差块内部学习的是一个恒等映射, 但是残差块之间并不是恒等映射) 下图展示了一个34层的深度残差网络结构图, 其中实线部分代表层间的维度不变, 虚线代表需要改变层间维度: F(x)和x的通道相同，则可直接相加,如果不同,则x需要变维 实线的Connection部分，表示通道相同，假如都是3x3x64的特征图，由于通道相同，所以采用计算方式为H(x)=F(x)+x 虚线的的Connection部分，表示通道不同，假如分别是3x3x64和3x3x128的特征图，则应采用相应的方案来变换维度(0填充或者线性变换$W_s x$) 对于shortcut连接的方式, 作者给出了三个选项: 使用恒等映射, 如果需要改变输出维度时, 对增加的维度用0来填充, 不会增加任何参数 在输入输出维度一致时使用恒等映射, 不一致时使用线性投影以保证维度一致, 增加部分参数 对有所的block均使用线性投影, 大量增加参数 对这三个选项都进行了实验，发现虽然在效果上 C&gt;B&gt;A，但是差距很小，由于线性变换需要引进额外的参数, 因此不推荐使用C策略，而使用0填充时，可以保证模型的复杂度最低，这对于更深的网络是更加有利的。 卷积分解简化计算: bottleneck 结构, 如下图所示: 在ResNet34中, 采用的是左图的残差结构, 而在ResNet50以上中, 采用的是右图的残差结构, 通过1×1卷积先降维再升维的方式, 来降低参数的数量, 从而减少计算量. ResNet架构的一些特点224crop horizaontal flip per-pixel mean subtracted 标准color augmentation 在每一层卷积层之后, 激活层之前, 都是用了BN 使用了msra初始化方法 使用了SGD batch size = 256 lr 从0.1开始,每当error plateaus(停滞)时, 缩小1/10 没有使用dropout 要点提问怎样理解所谓的残差 $F(x)$ 要比原始目标 $H(x)$ 更容易优化呢?假设我们要学习一种从输入x到输出H(x)的mapping, 最简单的例子, 假设解空间里的函数只有两个，就是在这两个可能的mapping 函数里面选择一个更好的。 如果是非resnet的情况，那么给定H(5)＝5.1 和H(5)＝5.2 这两个函数映射, 其对应权重参数分别是 $H(x) = wx = 5.1/5 x$ 和 $H(x) =w x = 5.2/5 x$ ，这两个函数的w近似的都近似等于1, 或者说一个w是另一个w的1.04/1.02＝1.0196倍. 也就是说，如果用sgd来选择参数w的话，是容易认为两个w很像的(导致训练慢，学错，对数据不敏感)。 但是resnet就不同了，在resnet下，原输入输出数据相当于变成了H(5)=0.1 H(5)=0.2, 这两个对应的潜在函数变成了 $F(x)=wx = 0.1/5 x$ 和 $H(x) = wx = 0.2/5 x$ , 两个w的关系变成了一个w 是另一个w的0.2／0.1 ＝ 2倍，所以w的选取对于数据集非常敏感了。 这是基于这个原因，resnet里面的参数 w会更加”准确”反映数据的细微变化。 为什么恒等映射x之前的系数是1,而不是其他的值, 比如0.5?关于为什么是 $x$ 而不是 $\lambdai x$,主要是因为如果是 $\lambda_i x$ 的话,梯度里面 就会有一项 $\prod{i=1}^{L-1}{\lambda_i}$，就是从输出到当前层之间经过的 shortcut上的所有$\lambda_i$相乘，假如$\lambda_i$都大于1那经过多层之后就会爆炸，都小于1就会趋向0而引发梯度消失. 具体公式分析可见下面关于”用简单缩放来替代恒等连接”的讨论 2. Identity Mappings在第一篇ResNet论文中提到, 1202层的ResNet出现了性能退化的问题. 本文主要是对residual block的一个改进, 也就是将BN和ReLU放到计算权重之前进行, 称为”预激活” , 如下图所示: 关于Deep ResNet的分析https://blog.csdn.net/wspba/article/details/60750007 用简单缩放来代替恒等连接设计一个简单的缩放: $h(x_l) = \lambda_l x_l$ 来代替恒等连接: x_{l+1} = \lambda_l x_l + F(x_l, W_l)于是,继续通过递归我们可以得到: x_L = (\prod_{i=l}^{L-1}) x_l + \sum_{i=l}^{L-1}{\hat F(x_i, W_i)}对上面的式子求导, 可以得到: 可以看到, 在该式子中, 由于 $\lambda$ 连乘项的存在, 可能会使这个因子变的很大或者消失, 从而阻断从短接反向传来的信号, 进而对优化造成困难 关于Skip Connections的其他实验Constant scaling考虑对 $F$ 的缩放, 训练结果显式优化变的更加困难, 因此不建议缩放 因为 $F$ 对应的是连加项, 不会出现连乘项, 所以不能说因子很指数增长或消失 Exclusive gatingShortcut-only gating1×1 卷积shortcut在ResNet34的时候, 使用了1×1的卷积(即方案C), 并且取得了较好的结果, 表明1×1卷尺短接还是有效果的. 但是当残差单元变多时, 并不能起到很好的效果 值得注意的是1××\times1的卷积捷径连接引入了更多的参数，本应该比恒等捷径连接具有更加强大的表达能力。事实上，shortcut-only gating 和1××\times1的卷积涵盖了恒等捷径连接的解空间(即，他们能够以恒等捷径连接的形式进行优化)。然而，它们的训练误差比恒等捷径连接的训练误差要高得多，这表明了这些模型退化问题的原因是优化问题，而不是表达能力的问题 Dropout shortcut这个在统计学上相当于给短接强加了一个 $\lambda=0.5$ 的缩放, 这和constant scaling很类似, 同样阻碍了信号的传播 激活函数的使用通过重新安排激活函数(ReLU和/或BN)来使得 $f$ 成为一个恒等映射. 最原始的残差连接如下图a所示, b~e展示了其他形式. 图中所有单元的组成成分相同, 只是顺序不同, e形式取得了最后的结果, 也就是full pre-activation形式 对以上形式讨论如下: BN after addition: 图b, 此种做法正好反其道而行之, 此时 $f$ 不仅包含了 ReLU, 还包含了BN, 最终导致的结果就是阻碍了信息的传递, 是性能下降 ReLU before addition: 图c, 这是一种很直接的做法, 也很天真, 直接将ReLU移动到加法之前, 这导致了F的输出非负, 然我们我们希望残差函数的值是在政府无穷区间内的 Post-activation or Pre-activation: 如图c和d, 图d通过一种非对称的转换, 使得当前块的激活函数成为一个块的预激活项, 具体转换如下图所示: 对上图的解释就是, 在原始的设计中, 激活函数会对两条路径的下一个残差单元造成影响: y_{l+1} = f(y_l) + F(f(y_l), W_{l+1})而通过这种非对称的转换, 能够让激活函数 $\hat f$ 对于任意的 $l$ , 都只对$F$ 路径造成影响: y_{l+1} = y_l + F(\hat f(y_l), W_{l+1})于是, 新的激活函数就变成了一个恒等映射. 后激活与预激活的区别是有元素级加法的存在而造成的,一个含有N层的平铺网络，包含有N−1个激活层(BN/ReLU)，而我们如何考虑它们是否是后激活或者预激活都不要紧。但是对附加的分支层来说，激活函数的位置就变得很重要了。只使用ReLU预激活的结果与原始ResNet-110/164的已经很接近。 只是用ReLU的预激活vs完全预激活 从图d中, 我们可以看到, ReLU层不与BN层连接使用，因此无法共享BN所带来的好处, 因此, 很自然的,我们将BN层移到ReLU的前面, 最终, 性能获得了较大的提升, 超过了原始ResNet-110/164 分析文章发现预激活的影响具有两个方面: 由于$f$变成了恒等映射,优化变的更加简单 在预激活中使用BN能提高模型的正则化能力 3. ResNet的其它变体ResNeXtDenseNet详见DenseNet]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度消失和梯度爆炸问题详解]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E9%97%AE%E9%A2%98%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1.为什么使用梯度下降来优化神经网络参数？反向传播（用于优化神网参数）：根据损失函数计算的误差通过反向传播的方式，指导深度网络参数的更新优化。 采取反向传播的原因：首先，深层网络由许多线性层和非线性层堆叠而来，每一层非线性层都可以视为是一个非线性函数$f(x)$(非线性来自于非线性激活函数），因此整个深度网络可以视为是一个复合的非线性多元函数。 我们最终的目的是希望这个非线性函数很好的完成输入到输出之间的映射，也就是找到让损失函数取得极小值。所以最终的问题就变成了一个寻找函数最小值的问题，在数学上，很自然的就会想到使用梯度下降来解决。 2.梯度消失、爆炸会带来哪些影响举个例子，对于一个含有三层隐藏层的简单神经网络来说，当梯度消失发生时，接近于输出层的隐藏层由于其梯度相对正常，所以权值更新时也就相对正常，但是当越靠近输入层时，由于梯度消失现象，会导致靠近输入层的隐藏层权值更新缓慢或者更新停滞。这就导致在训练时，只等价于后面几层的浅层网络的学习。 3.产生的原因以最简单的网络结构为例，加入有三个隐藏层，每层的神经元个数都是1，且对应的非线性函数为$y_i = \sigma(z_i)=\sigma(w_i x_i + b_i)$（其中 $\sigma$ 为某个激活函数）如下图： 现在假设我们需要更新参数 $b_1$ ，那么我们就要求出损失函数对参数 $b_1$ 的导数，根据链式法则，可以写成下面这样： 而对于激活函数，之前一直使用Sigmoid函数，其函数图像成一个S型，如下所示，它会将正无穷到负无穷的数映射到0~1之间： S(x) = \frac{1}{1+e^{-x}} = \frac{e^x}{e^x+1} 当我们对Sigmoid函数求导时，得到其结果如下： S(x) = S(x)(1-S(x))由此可以得到它Sigmoid函数图像，呈现一个驼峰状（很像高斯函数），从求导结果可以看出，Sigmoid导数的取值范围在0~0.25之间，而我们初始化的网络权值$|w|$通常都小于1，因此，当层数增多时，小于0的值不断相乘，最后就导致梯度消失的情况出现。同理，梯度爆炸的问题也就很明显了，就是当权值$|w|$过大时，导致 $|\sigma’(z)w| &gt; 1$，最后大于1的值不断相乘，就会产生梯度爆炸。 Sigmoid函数求导图像 4.解决办法梯度消失和梯度爆炸本质上是一样的，都是因为网络层数太深而引发的梯度反向传播中的连乘效应。 解决梯度消失、爆炸主要有以下几种方案： 4.1 换用Relu、LeakyRelu、Elu等激活函数ReLu：让激活函数的导数为1 LeakyReLu：包含了ReLu的几乎所有有点，同时解决了ReLu中0区间带来的影响 ELU：和LeakyReLu一样，都是为了解决0区间问题，相对于来，elu计算更耗时一些（为什么） 具体可以看关于各种激活函数的解析与讨论 4.2 BatchNormalizationBN本质上是解决传播过程中的梯度问题，具体待补充完善，查看BN 4.3 ResNet残差结构具体待补充完善，查看ResNet 4.4 LSTM结构LSTM不太容易发生梯度消失，主要原因在于LSTM内部复杂的“门（gates）”，具体看LSTM基本原理解析 4.4 预训练加finetunning此方法来自Hinton在06年发表的论文上，其基本思想是每次训练一层隐藏层节点，将上一层隐藏层的输出作为输入，而本层的输出作为下一层的输入，这就是逐层预训练。 训练完成后，再对整个网络进行“微调（fine-tunning）”。 此方法相当于是找全局最优，然后整合起来寻找全局最优，但是现在基本都是直接拿imagenet的预训练模型直接进行finetunning。 4.5 梯度剪切、正则这个方案主要是针对梯度爆炸提出的，其思想是设值一个剪切阈值，如果更新梯度时，梯度超过了这个阈值，那么就将其强制限制在这个范围之内。这样可以防止梯度爆炸。 另一种防止梯度爆炸的手段是采用权重正则化，正则化主要是通过对网络权重做正则来限制过拟合，但是根据正则项在损失函数中的形式： 可以看出，如果发生梯度爆炸，那么权值的范数就会变的非常大，反过来，通过限制正则化项的大小，也可以在一定程度上限制梯度爆炸的发生。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种激活函数整理总结]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E5%90%84%E7%A7%8D%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[为什么需要激活函数标准说法这是由激活函数的性质所决定来, 一般来说, 激活函数都具有以下性质: 非线性: 首先,线性函数可以高效可靠对数据进行拟合, 但是现实生活中往往存在一些非线性的问题(如XOR), 这个时候, 我们就需要借助激活函数的非线性来对数据的分布进行重新映射, 从而获得更强大的拟合能力. (这个是最主要的原因, 其他还有下面这些性质也使得我们选择激活函数作为网络常用层) 可微性: 这一点有助于我们使用梯度下降发来对网络进行优化 单调性: 激活函数的单调性在可以使单层网络保证网络是凸优化的 $f(x) \approx x:$ 当激活满足这个性质的时候, 如果参数初值是很小的值, 那么神经网络的训练将会很高效(参考ResNet训练残差模块的恒等映射); 如果不满足这个性质, 那么就需要用心的设值初始值( 这一条有待商榷 ) 如果不使用激活函数, 多层线性网络的叠加就会退化成单层网络,因为经过多层神经网络的加权计算，都可以展开成一次的加权计算 更形象的解释对于一些线性不可分的情况, 比如XOR, 没有办法直接画出一条直线来将数据区分开, 这个时候, 一般有两个选择. 如果已知数据分布规律, 那么可以对数据做线性变换, 将其投影到合适的坐标轴上, 然后在新的坐标轴上进行线性分类 而另一种更常用的办法, 就是使用激活函数, 以XOR问题为例, XOR问题本身不是线性可分的, https://www.zhihu.com/question/22334626 用ReLU解决XOR问题.首先, XOR问题如下所示: $x_1$ $x_2$ y 1 0 1 0 1 1 1 1 0 0 0 0 首先构造一个简单的神经网络来尝试解决XOR问题, 网络结构如下图所示: 先来看看不使用激活函数时的情况, 当不使用激活函数时, 整个网络的函数表达式如下所示: y = f(x_1, x_2; W, c, w ,b) = [w_1, w_2] \bigg( \bigg[\begin{matrix} W_{11} & W_{12} \\ W_{21} & W_{22} \end{matrix} \bigg] \Big[\begin{matrix} x_1 \\ x_2 \end{matrix} \Big]+ \Big[\begin{matrix} c_1 \\ c_2 \end{matrix} \Big] \bigg) + b = (w^TW^T)x + (w^Tc+b) = w'^Tx+b'可以看到, 多层无激活函数的网络叠加, 首先是会退化成单层网络, 而对于单层网络, 求解出来的参数 $w’$ 和 $b’$ 无法对非线性的数据进行分类. 再来看看进入ReLU以后, 是如何解决XOR问题的, 首先, 引入后的公式如下所示: y = f(x_1, x_2; W, c, w ,b) = [w_1, w_2] max \bigg(0 , \bigg[\begin{matrix} W_{11} & W_{12} \\ W_{21} & W_{22} \end{matrix} \bigg] \Big[\begin{matrix} x_1 \\ x_2 \end{matrix} \Big]+ \Big[\begin{matrix} c_1 \\ c_2 \end{matrix} \Big] \bigg) + b可以看到, 此时函数是无法化简, 因为此时引入了非线性的ReLU函数, 于是 ,就可以求得一个参数组合${w,W,c,b}$ 使得对于特定的输入$x_1, x_2$ ,能够得到正确的分类结果 $y$. 至于这个参数组合具体是什么, 这是需要通过梯度下降来不断学习的, 假如我们现在找到了一组参数如下(当然不一定是最优的), 来看看这组参数具体是如何解决XOR问题的: W=\bigg[ \begin{matrix} 1 & 1 \\ 1 & 1 \end{matrix} \bigg]c =\Big[ \begin{matrix} 0 \\ -1 \end{matrix} \Big]w =\Big[ \begin{matrix} 1 \\ -1 \end{matrix} \Big]b = 0然后, 分别将4种 $x_1, x_2$的值代入上式, 可以得到, y的值如下:| $x_1$ | $x_2$ | 计算过程 | y || —- | —- | —- | —- || 1 | 0 | $[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 1 \ 0 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \ -1 \end{matrix} \Big] \bigg) + 0$ | 1 || 0 | 1 | $[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 0 \ 1 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \ -1 \end{matrix} \Big] \bigg) + 0$ | 1 || 1 | 1 | $[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 1 \ 1 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \ -1 \end{matrix} \Big] \bigg) + 0$ | 0 || 0 | 0 | $[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 0 \ 0 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \ -1 \end{matrix} \Big] \bigg) + 0$ | 0 | 常用激活函数及其导数 激活函数 形式 导数形式 Sigmoid $f(x) =\frac{1}{1+e^{-x}}$ $f’(x)(1-f(x))$ Tanh $f(x) = tanh(x)= \frac{e^x-e^{-x}}{e^x+e^{-x}}$ $f’(x) = 1-(f(z))^2$ ReLU $f(x)=max(0,x)=\begin{cases} 0 &amp; x \leq 0 \ x &amp; x&gt;0 \end{cases}$ $f’(x)=\begin{cases} 0 &amp; x\leq 0 \ 1 &amp; x&gt;0 \end{cases}$ Leaky ReLU $f(x)=max(0.001 x,x)=\begin{cases} 0.001x &amp; x \leq 0 \ x &amp; x&gt;0 \end{cases}a$ $f(x)=max(0.001 x,x)=\begin{cases} 0.001 &amp; x \leq 0 \ 1 &amp; x&gt;0 \end{cases}$ PReLU $f(x)=max(\alpha x,x)=\begin{cases} \alpha x &amp; x \leq 0 \ x &amp; x&gt;0 \end{cases}$ $f(x)=max(\alpha x,x)=\begin{cases} \alpha &amp; x \leq 0 \ 1 &amp; x&gt;0 \end{cases}$ RReLU PReLU中的 $\alpha$ 随机取值 ELU $f(x) = \begin{cases} x &amp; x \geq 0 \ \alpha(e^x - 1) &amp; x&lt;0 \end{cases}$ $f(x) = \begin{cases} 1 &amp; x \geq 0 \ \alpha e^x &amp; x&lt;0 \end{cases}$ Maxout $f(x) = max(w_1^T x + b_1, w_2^T x + b_2)$ $f(x) = max(w_1, w_2)$ 常用激活函数及其导数的图像Sigmoid Tanh ReLU LeakyReLU PReLU RReLU ELU 关于各个激活函数的比较和适用场景神经元饱和问题: 当输入值很大或者很小时, 其梯度值接近于0, 此时, 不管从深层网络中传来何种梯度值, 它向浅层网络中传过去的, 都是趋近于0的数, 进而引发梯度消失问题 zero-centered: 如果数据分布不是zero-centered的话就会导致后一层的神经元接受的输入永远为正或者永远为负, 因为 $\frac{\partial f}{\partial w} = x$ , 所以如果x的符号固定,那么 $\frac{\partial f}{\partial w}$ 的符号也就固定了, 这样在训练时, weight的更新只会沿着一个方向更新, 但是我们希望的是类似于zig-zag形式的更新路径 (关于非0均值问题, 由于通常训练时是按batch训练的, 所以每个batch会得到不同的信号, 这在一定程度上可以缓解非0均值问题带来的影响, 这也是ReLU虽然不是非0 均值, 但是却称为主流激活函数的原因之一) 激活函数 优势 劣势 适用场景 Sigmoid 可以将数据值压缩到[0,1]区间内 1. 神经元饱和问题 2.sigmoid的输出值域不是zero-centered的 3. 指数计算在计算机中相对来说比较复杂 在logistic回归中有重要地位 Tanh 1. zero-centered: 可以将 $(-\infty, +\infty)$ 的数据压缩到 $[-1,1]$ 区间内 2.完全可微分的，反对称，对称中心在原点 1. 神经元饱和问题 2. 计算复杂 在分类任务中，双曲正切函数（Tanh）逐渐取代 Sigmoid 函数作为标准的激活函数 ReLU 1. 在 $(0,+\infty)$ ,梯度始终为1, 没有神经元饱和问题 2. 不论是函数形式本身,还是其导数, 计算起来都十分高效 3. 可以让训练过程更快收敛(实验结果表明比sigmoid收敛速度快6倍) 4. 从生物神经理论角度来看, 比sigmoid更加合理 1. 非zero-centered 2. 如果输入值为负值, ReLU由于导数为0, 权重无法更新, 其学习速度可能会变的很慢,很容易就会”死”掉(为了克服这个问题, 在实际中, 人们常常在初始化ReLU神经元时, 会倾向于给它附加一个正数偏好,如0.01) 在卷积神经网络中比较主流 LeakyReLU 1. 没有神经元饱和问题 2. 计算高效 3. 收敛迅速(继承了ReLU的优点) 4. 神经元不会”死”掉(因为在负值时, 输出不为0, 而是x的系数0.001) PReLU 1. 没有神经元饱和问题 2. 计算高效 3. 收敛迅速(继承了ReLU的优点) 4. 神经元不会”死”掉(因为在负值时, 输出不为0, 而是x的系数 $\alpha$ ) 5. 相对于Leaky ReLU需要通过先验知识人工赋值, PReLU通过迭代优化来自动找到一个较好的值, 更加科学合理, 同时省去人工调参的麻烦 ELU 1. 拥有ReLU所有的优点 2. 形式上更接近于zero-centered 3. 在面对负值输入时,更加健壮 1. 引入了指数计算, 使计算变的复杂 Maxout 1. 跳出了点乘的基本形式 2. 可以看作是ReLU和Leaky ReLU 的一般化形式 3. linear Regime(啥意思?)! 4. 在所有输入范围上都没有神经元饱和问题 5. 神经元永远不会”死”掉 6. 拟合能力非常强，它可以拟合任意的的凸函数。作者从数学的角度上也证明了这个结论，即只需2个maxout节点就可以拟合任意的凸函数了(相减)，前提是”隐含层”节点的个数可以任意多 1. 使得神经元个数和参数个数加倍, 导致优化困难 其他要点sigmoid 和softmax区别sigoid是将一个正负无穷区间的值映射到(0,1)区间, 通常用作二分类问题,而softmax把一个k维的实值向量映射成一个$(b_1,b_2,…,b_k)$ ,其中$b_i$为一个0~1的常数, 且它们的和为1, 可以看作是属于每一类的概览,通常用作多分类问题. 在二分类问题中, sigmoid和softmax是差不多的, 都是求交叉熵损失函数, softmax可以看作是sigmoid的扩展, 当类别k为2时, 根据softmax回归参冗余的特点, 可以将softmax函数推导成sigmoid函数 https://www.jianshu.com/p/22d9720dbf1a 其他更多激活函数https://www.jiqizhixin.com/articles/2017-10-10-3 总结 优先使用ReLU, 同时要谨慎设置初值和学习率 ( 实际操作中，如果你的learning rate 很大，那么很有可能你网络中的40%的神经元都”dead”了。 当然，如果你设置了一个合适的较小的learning rate，这个问题发生的情况其实也不会太频繁 ) 尝试使用LeakyReLU/PReLU/Maxout/ELU等激活函数 可以试下tanh, 但是一般不会有太好的结果 不要使用sigmoid]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Batch-Normalization深入解析]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Batch-Normalization%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[BN:总的来说，BN通过将每一层网络的输入进行normalization，保证输入分布的均值与方差固定在一定范围内，减少了网络中的Internal Covariate Shift问题，并在一定程度上缓解了梯度消失，加速了模型收敛；并且BN使得网络对参数、激活函数更加具有鲁棒性，降低了神经网络模型训练和调参的复杂度；最后BN训练过程中由于使用mini-batch的mean/variance每次都不同，引入了随机噪声，在一定程度上对模型起到了正则化的效果。 Normalization字面上意思就是标准化,也就是对输入的数据做标准化,可以用下面的公式表示(这里 $x_i$ 代表输入数据, n代表训练集大小): \mu = \frac{1}{n}\sum_{i=1}^{n}{x_i}\sigma^2 = \frac{1}{n} \sum_{i=1}^{n}{(x_i - \mu)}\hat x_i = \frac{x_i - \mu}{\sqrt{\sigma^2}+\varepsilon}以上可以看出, 标准化以后的数据服从均值为0,方差为1的正态分布 为什么要进行Normalization?在介绍BN之前,先说说为什么要进行Normalization 在神经网络中, 数据分布对训练会产生影响. 比如某个神经元 x 的值为1, 某个 Weights 的初始值为 0.1, 这样后一层神经元计算结果就是 Wx = 0.1; 又或者 x = 20, 这样 Wx 的结果就为 2. 现在还不能看出什么问题, 但是, 当我们加上一层激励函数, 激活这个 Wx 值的时候, 问题就来了. 如果使用 像 tanh 的激励函数, Wx 的激活值就变成了 ~0.1 和 ~1, 接近于 1 的部已经处在了 激励函数的饱和阶段, 也就是如果 x 无论再怎么扩大, tanh 激励函数输出值也还是接近1. 换句话说, 神经网络在初始阶段已经不对那些比较大的 x 特征范围 敏感了. 这样很糟糕, 想象我轻轻拍自己的感觉和重重打自己的感觉居然没什么差别, 这就证明我的感官系统失效了. 当然我们是可以用之前提到的对数据做 normalization 预处理, 使得输入的 x 变化范围不会太大, 让输入值经过激励函数的敏感部分. 但刚刚这个不敏感问题不仅仅发生在神经网络的输入层, 而且在隐藏层中也经常会发生. Normalization的效果: 如上图,当没有进行normalizatin时,数据的分布是任意的,那么就会有大量的数据处在激活函数的敏感区域外, 对这样的数据分布进行激活后, 大部分的值都会变成1或-1,造成激活后的数据分布不均衡,而如果进行了Normallizatin, 那么相对来说数据的分布比较均衡,如下图所示: 一句话总结就是: 通过Normalization让数据的分布始终处在激活函数敏感的区域 BN的提出背景https://zhuanlan.zhihu.com/p/34879333 Internal Covariate ShiftCovariate [kʌ’veərɪrt] 什么是Internal Covariate Shift: 在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程被称作Internal Covariate Shift。 带来了什么问题: 上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低 网络的训练过程容易陷入梯度饱和区,减缓网络收敛速度 如何减缓Internal Covariate Shift: (1)白化(PCA白化和ZCA白化): 使得输入特征分布具有相同的均值与方差 取出特征之间的相关性-通过白化操作，我们可以减缓ICS的问题，进而固定了每一层网络输入分布，加速网络训练过程的收敛 白化缺点: 白化过程计算成本太高，并且在每一轮训练中的每一层我们都需要做如此高成本计算的白化操作； 白化过程由于改变了网络每一层的分布，因而改变了网络层中本身数据的表达能力。底层网络学习到的参数信息会被白化操作丢失掉。 于是就提出了BN 什么是Batch Normalization传统的Normalization使用的均值和方差是整个训练集的均值和方差, 而Batch Normalization按字面意思就是对每一批数据进行归一化, 所以, 首先要将传统的标准化中的n改为m, m表示一个batch的大小,如下所示: \mu = \frac{1}{m}\sum_{i=1}^{m}{x_i}\sigma^2 = \frac{1}{m} \sum_{i=1}^{m}{(x_i - \mu)}\hat x_i = \frac{x_i - \mu}{\sqrt{\sigma^2}+\varepsilon}传统的Normalization直接使用了减均值除方差的方式来进行标准化, 但是, 这样一概而全的方法未必对所有数据来说就是最优的, 比如数据本身就不对称, 或者激活函数未必对方差为1的数据有最好的效果, 所以, BN的想法是在传统标准化之后再加上一个线性变换,如下所示: \hat y_i = \gamma \hat x_i + \beta其中,$\gamma$ 和 $\beta$ 是两个需要学习的参数, 可以看出, BN的本质就是利用参数优化来改变一下数据分布的方差大小和均值的位置. BN的优点（1）BN使得网络中每层输入数据的分布相对稳定，加速模型学习速度 （2）BN使得模型对初始化方法和网络中的参数不那么敏感，简化调参过程，使得网络学习更加稳定 （3）BN允许网络使用饱和性激活函数（例如sigmoid，tanh等），缓解梯度消失问题 （4）BN具有一定的正则化效果 原因如下: （1）BN使得网络中每层输入数据的分布相对稳定，加速模型学习速度 BN通过规范化与线性变换使得每一层网络的输入数据的均值与方差都在一定范围内，使得后一层网络不必不断去适应底层网络中输入的变化，从而实现了网络中层与层之间的解耦，更加有利于优化的过程,提高整个神经网络的学习速度。 （2）BN使得模型对初始化方法和网络中的参数不那么敏感，简化调参过程，使得网络学习更加稳定 在神经网络中，我们经常会谨慎地采用一些权重初始化方法（例如Xavier）或者合适的学习率来保证网络稳定训练。当学习率设置太高时，会使得参数更新步伐过大，容易出现震荡和不收敛…https://zhuanlan.zhihu.com/p/34879333 （3）BN允许网络使用饱和性激活函数（例如sigmoid，tanh等），缓解梯度消失问题 在不使用BN层的时候，由于网络的深度与复杂性，很容易使得底层网络变化累积到上层网络中，导致模型的训练很容易进入到激活函数的梯度饱和区；通过normalize操作可以让激活函数的输入数据落在梯度非饱和区，缓解梯度消失的问题；另外通过自适应学习 $\gamma$ 与 $\beta$ 又让数据保留更多的原始信息。 （4）BN具有一定的正则化效果 在Batch Normalization中，由于我们使用mini-batch的均值与方差作为对整体训练样本均值与方差的估计，尽管每一个batch中的数据都是从总体样本中抽样得到，但不同mini-batch的均值与方差会有所不同，这就为网络的学习过程中增加了随机噪音，与Dropout通过关闭神经元给网络训练带来噪音类似，在一定程度上对模型起到了正则化的效果。 另外，原作者也证明了网络加入BN后，可以丢弃Dropout，模型也同样具有很好的泛化效果。 使用BN时应注意的问题 测试阶段的使用 在实际应用中, 这两个参数是通过在每个batch的数据上得到的, 注意, BN在训练过程中会记录整个数据的均值和方差,训练结束后将其作为预测阶段使用的均值和方差, 或者对train阶段的每个batch的均值和方差进行加权平均来得到最终的均值和方差 隐藏层中BN的数据大小 在卷积网络隐藏层中, BN的大小不单单是batch, 而是batch和特征相应图大小的乘积. 也就是说, 在隐藏层, 层的输入是上一层的输出, 也就是上一层的神经元个数, 而对于上一层来说, 如果输出的特征相应图大小为 $w\times h$ , 那么上一层的神经元个数就应该是 $b\times w \times h$, 其中,b是指batch的大小]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>BN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种初始化方法整理总结]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E5%90%84%E7%A7%8D%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B9%E6%B3%95%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[初始化方法概览 初始化方法 说明 均匀分布 高斯分布 初始化为服从 $N(\mu, \sigma ^2)$ 的高斯分布 xavier msra 双线性初始化 初始化方法详细说明Xavier(‘zeiviə’)核心理念是: 优秀的初始化方法应该使得各层的激活值和状态梯度在传播过程中的方差保持一致 也就是说, 假如网络某一层函数表示如下: z^{(i)} = W^{(i)} x^{(i-1)}x^{(i)} = f(z^{(i)}), i=1,2,..那么, 好的初始化应该可以满足下面的条件: \forall (i,j), Var(x^i) = Var(x^j)\forall (i,j), Var(\frac{\partial Loss}{\partial z^i}) = Var(\frac{\partial Loss}{\partial z^j})再继续推导之前, 需要先提出以下假设: 首先,输入数据来说,其均值和方差应满足: $E(x)=0, Var(x)=1$ (通过BN,较容易满足) 权重矩阵 $W$ 和 网络输入 $x$ 互相独立 每层输入的每个特征方差一样 激活函数对称: 这主要是为了满足均值为0的假设 激活函数是线性的, 也就是说其导数为1 初始时, 状态值落在激活函数的线性区域, 即此时导数为1 根据状态梯度和参数的梯度公式($l$ 代表层数): \frac{\partial Loss}{\partial z_k^i} = f'(z_k^i)(W_{.,k}^{i+1})^T \frac{\partial Loss}{\partial z^{i+1}}\frac{\partial Loss}{\partial w_{l,k}^i} = h_l^{i-1} \frac{\partial Loss}{\partial z_k^i}// TODO 推导之后, 有: 为了保证前向传播和反向传播时每一层的方差一致, 则有下面的公式成立: \forall i, n_i Var[W^i] = 1\forall i, n_{i+1} Var[W^i] =1式中, $ni, n{i+1}$ 分别为当前第i层和i+1层的输入节点个数, 但是, 在实际当中, 每一层的输入个数往往不相等, 于是为了均衡考量, 最终给出的权重方差为: \forall, Var[W^i] = \frac {2}{n_i + n_{i+1}}再由概率统计中均匀分布方差的性质反推,可以得到Xavier最终的初始化分布如下: W \sim U\Big[-\frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}},\frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}} \Big]Xavier在Caffe中的具体实现: 123456789101112131415161718192021222324template &lt;typename Dtype&gt;class XavierFiller : public Filler&lt;Dtype&gt; &#123; public: explicit XavierFiller(const FillerParameter&amp; param) : Filler&lt;Dtype&gt;(param) &#123;&#125; virtual void Fill(Blob&lt;Dtype&gt;* blob) &#123; CHECK(blob-&gt;count()); int fan_in = blob-&gt;count() / blob-&gt;num(); int fan_out = blob-&gt;count() / blob-&gt;channels(); Dtype n = fan_in; // default to fan_in if (this-&gt;filler_param_.variance_norm() == FillerParameter_VarianceNorm_AVERAGE) &#123; n = (fan_in + fan_out) / Dtype(2); &#125; else if (this-&gt;filler_param_.variance_norm() == FillerParameter_VarianceNorm_FAN_OUT) &#123; n = fan_out; &#125; Dtype scale = sqrt(Dtype(3) / n); caffe_rng_uniform&lt;Dtype&gt;(blob-&gt;count(), -scale, scale, blob-&gt;mutable_cpu_data()); CHECK_EQ(this-&gt;filler_param_.sparse(), -1) &lt;&lt; "Sparsity not supported by this Filler."; &#125;&#125;; 可以看出, Caffe的Xavier实现有三种选择: (1) 初始化方法讨论为什么不能全0初始化首先, 在神经网络中, 每一层中的任意神经元都是同构的, 它们拥有相同的输入, 如果再将参数全部初始化为同样的值(如0), 那么输出也就是相同的, 反过来它们的梯度也都是相同的. 那么无论是前向传播还是反向传播的取值都是完全相同的, 那么每一个神经元都是基于input做相同的事情, 这样一来, 不同的神经元根本无法学到不同的特征, 这样就失去网络学习特征的意义了 高斯 msra]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[被忽视的Patition算法]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E8%A2%AB%E5%BF%BD%E8%A7%86%E7%9A%84Patition%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[如果你学习过算法，那么肯定听说过快速排序的大名，但是对于快速排序中用到的 partition 算法，你了解的够多吗？或许是快速排序太过于光芒四射，使得我们往往会忽视掉同样重要的 partition 算法。 Partition 可不只用在快速排序中，还可以用于Selection algorithm（在无序数组中寻找第K大的值）中。 Partition实现用 Two Pointers 的思想，保持头尾两个指针向中间扫描，每次在头部找到大于pivot的值，同时在尾部找到小于pivot的值，然后将它们做一个交换，就可以一次把这两个数字放到最终的位置。一种比较明智的写法如下： 123456789101112int partition(vector&lt;int&gt; &amp; arr, int low, int high)&#123; int pivot = arr[low]; while(low&lt;high)&#123; //比较时如果少了等于号,就有可能会陷入死循环,两个重复的数不断交换 while(low&lt;high &amp;&amp; arr[low]&lt;=pivot) low++; arr[high] = arr[low]; while(low&lt;high &amp;&amp; arr[high]&gt;=pivot) high--; arr[low] = arr[high]; &#125; arr[low] = pivot; return low;&#125; 上面的算法虽然没有显式用的swap,但实际上也相当于进行了swap操作,如下图所示: Partition应用快排1234567void quick_sort(vector&lt;int&gt; &amp; arr, int low, int high)&#123; if(low &gt;= high) return; mid = partition(arr,low,high); if(mid&gt;low) quick_sort(arr, low,mid-1); if(mid&lt;high) quick_sort(arr,mid+1, high);&#125; 复杂度:$O(nlogn)$ 寻找无序数组中第K大的值首先用 partition 将数组分为两部分，得到分界点下标 pos，然后分三种情况： pos == k-1，则找到第 K 大的值，arr[pos]； pos &gt; k-1，则第 K 大的值在左边部分的数组。 pos &lt; k-1，则第 K 大的值在右边部分的数组。 123456789101112int find_kth_number(int k)&#123; int low = 0; int high = arr.size()-1; while(low&lt; high)&#123; pos = partition(arr,low,high); if(pos==k-1) return arr[k-1]; else if (pos &lt; k-1) low = pos+1; else high = pos-1; &#125;&#125; 时间复杂度 $O(n)$ 分析:考虑最坏情况下，每次 partition 将数组分为长度为 N-1 和 1 的两部分，然后在长的一边继续寻找第 K 大，此时时间复杂度为 O(N^2 )。不过如果在开始之前将数组进行随机打乱，那么可以尽量避免最坏情况的出现。而在最好情况下，每次将数组均分为长度相同的两半，运行时间 T(N) = N + T(N/2)，时间复杂度是 O(N)。 Partition 进阶接下来先考虑这样一个问题，给定红、白、蓝三种颜色的小球若干个，将其排成一列，使相同颜色的小球相邻，三种颜色先后顺序为红，白，蓝。这就是经典的 Dutch national flag problem。 我们可以针对红，蓝，白三种颜色的球分别计数，然后根据计数结果来重新放球。不过如果我们将问题进一步抽象，也就是说将一个数组按照某个target值分为三部分，使得左边部分的值小于 target，中间部分等于 target，右边部分大于 target，这样就不能再用简单的计数来确定排序后的结果。这时候，就可以用到另一种 partition 算法： three-way-partition 。它的思路稍微复杂一点，用三个指针将数组分为四个部分，通过一次扫描最终将数组分为 &lt;，=，&gt; 的三部分，如下图所示:]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习轻松学》]]></title>
    <url>%2Fz_post%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BD%BB%E6%9D%BE%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[第七章 网络结构7.1 关于网络结构，我们更关心什么模型结构的关注点有以下几个： 模型的总深度：代表了模型潜在的学习能力和模型的复杂度。 模型的参数总量：同样代表了模型的学习能力和复杂的复杂度。 模型前向计算所需的内存量：模型的大小 7.2 网络结构的演化7.2.1 VGG哲学AlexNet：采用类7*7的卷积核 VGGNet：用3个3×3个卷积核代替了7×7的卷积核，效果差不多，但是参数量降低了。同时增加了非线性层，过去一个卷积层加一个非线性，现在替换成了三个卷积核加三个非线性。另外，在VGG中，卷积层的操作不会改变输入数据的维度，通常会通过padding来维持输出的大小。而只通过pooling层来改变输出的大小。 提问： 卷积的时候为什么要进行padding？ 回答：对于一些通过卷积减小维度的模型来说，对于不同的输入尺度，卷积后的输出维度各不一样，所以模型不容易适配更多的场景，而如果只用pooling层改变场长宽维度，整体模型的维度计算就方便了许多。 7.2.2 GooLeNet：丰富模型层的内部结构NIN网络和Inception Module这类结构非常看中模型在局部区域的拟合能力。它们认为：一张图像通常具有总体特征和细节特征这两类特征，一般小卷积核能够更好的捕捉一些细节特征，随着深层网络的小卷积不断计算下去，总体特征也会慢慢的被提炼出来，但是这样存在一个问题，那就是在如果只采用小卷积，那么网络结构的前段一般只有细节特征，后段才慢慢有一些总体特征，而我们希望这两方面的特征总是能够一起发挥作用，因此，上面的两种模型考虑采用更多不同尺寸的卷积核来提取特征，并把这些特征连接起来，一起送到后面的网络中去计算，使得网络可以获取到更多的特征信息。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《百面机器学习》]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[第一章 特征工程7. 图像数据不足时的处理方法在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？一个模型的信息来源主要有两个方面： 训练数据中蕴含的信息 模型形成过程中（包括构造、学习、推理等），人们提供的先验信息 当训练数据不足时，说明模型从原始数据中获取的信息比较少，这种情况下要想保证模型的效果，就需要更多的先验信息 先验信息可以作用在模型上，例如让模型采用特定的内在结构、条件假设或添加其他一些约束条件 先验信息也可以直接施加在数据集上，让其展现处更多的、更有用的信息、以利于后续模型的训练和学习。 具体到图像分类任务上，训练数据不足带来的问题主要表现在 过拟合方面。所以，对应的处理方法大致分为两类： 基于模型的方法：采用降低过拟合风险的措施，包括简化模型（如将非线性简化成线性）、添加约束项以缩小假设空间（如L1和L2正则化）、集成学习、Dropout超参数等 基于数据的方法，主要通过数据扩充（Data Augmentation），即根据一些先验知识，在保持特定信息的前提下，对原始数据进行适合变换以达到扩充数据集的效果。 在图像分类任务中，在保持图像类别不变的前提下，可以对训练集中的每幅图像进行以下变换： 观察角度：一定程度内的随机旋转、平移、缩放、裁剪、填充、左右翻转等 噪声扰动：椒盐噪声、高斯白噪声 颜色变换：在RGB颜色空间上进行主成分分析 其他：亮度、清晰度、对比度、锐度 其他扩充数据方法：特征提取——&gt;在图像的特征空间内进行变换：数据扩充or上采样技术，如SMOTE（Synthetic Minority Over-sampling Technique)。 最后，迁移学习或者用GAN合成一些新样本也可帮助解决数据不足问题。 第三章 经典算法1. 支持向量机知识点: SVM模型推导, 核函数, SMO(Sequential Minimal Optimizaiton)算法 问题1: 在空间上线性可分的两类点, 分别向SVM分类的超平面上做投降, 这些点在超平面上的投影仍然是线性可分的吗首先明确下题目概念: 当前的空间已经是线性可分的空间,有可能是样本空间,也有可能是映射后的特征空间. 题目问的是将当前空间中的点全部投影都当前的分类超平面上, 提问在分类超平面上投影的点是否仍然线性可分. 先说结论: 对于任意线性可分的两组点, 它们在SVM分类的超平面上的投影都是线性不可分的 解释一(反证法直观推导): 首先根据拉格朗日对偶优化问题的公式和KKT条件要求,可以知道, SVM的分类结果仅仅依赖于支持向量, 那么此时我们假设存在一个SVM分类超平面使所有支持向量在该超平面上的投影依然线性可分, 那么根据初等几何只是我们可以知道, 两个类别中距离最近的两个点, 它们连线的中垂线所组成的新的超平面是相较于当前超平面更优的解. 这与我们的假设相矛盾, 故线性可分的两组点, 投影到超平面上以后是线性不可分的.(具体可画图或看p53) 解释二(超平面分离定理,Separatin Hyperplane Theorem, SHT): STH定理描述: 对于不想交的两个凸集, 存在一个超平面, 将两个凸集分离. 对于二维的情况, 两个凸集间的距离最短两点连线的中垂线就是一个将它们分离的超平面 根据此定理, 我们先对线性可分的这两组点求格子的凸包, 而SVM求得的超平面就是这两个凸包上距离最短的两点连线的中垂线,根据凸包的性质容易知道, 凸包上的点要么是样本点, 要么是两个样本点之间连线上的点, 那么, 两个凸包之间距离最短的两个点可以分为三个情况: 1)两边都是样本点, 2)两边都不是样本点, 3)一边是一边不是. 不论对于哪种情况, 当对中垂线(超平面)投影后, 两类点都是线性不可分的(具体可画图或者看p54) 问题2: 是否存在一组参数使SVM训练误差为0?问题详细描述: 一个使用高斯核( $K(x,z) = e^{-| x- z|^2/\gamma^2})$ 训练的SVM中, 试证明若给定训练集中 不存在两个点在同一个位置 (如果在同一个位置,则这两个点不可分), 则存在一组参数 $\vec \alpha$ 和参数 $\gamma$, 使得SVM的训练误差为0. 结论:存在(可想象成是过拟合) 公式证明: //TODO 以上推导证明可以看出, 对于任意样本的预测结果 $f(\vec x^{(i)})$, 与样本真实标签 $y^{(i)}$ 的距离都小于1 , 因此, 当训练样本为正例时, 由于 $y^{(i)}=1$, 则必有 $f(\vec x^{(i)}) &gt;0 $, 样本被预测为正例. 负例也是同理. 因此所有样本的类别都被正确预测, 训练误差为0. 问题3: 训练误差为0的SVM分类器一定存在吗问题详细描述: 虽然在问题2中找到了一组参数使得SVM的训练误差为0, 但是这组参数不一定是满足SVM条件的一个解, 在实际训练一个 不加入松弛变量 的SVM模型时, 是否能保证得到的SVM分类器满足训练误差为0呢? 结论: 存在 上一题找到了一组参数使得SVM的分类器训练误差为0, 但是训练误差为0的参数并不一定是SVM模型的一个解, 它还需要满足限制条件 $y^{(i)} f(x^{(i)}) \geq 1$ . 因为SVM模型中解的限制条件为 $y^{(i)} f(x^{(i)}) \geq 1$ (等号为支持向量样本点) , 而上题我们只得到了 $y^{(i)} f(x^{(i)}) &gt; 0$, 因此需要找到另一组参数满足更强的条件 // TODO公式推导 根据以上推导过程, 可以找到一个SVM的解, 同时一定使模型分类误差为0 问题4: 加入松弛变量的SVM的训练误差可以为0吗结论: 不一定能得到训练误差为0的模型(但不是一定不能, 具体看问题) 这是由于加入松弛变量后, 优化目标变成了 $\min{\vec w, b, \xi^{(i)}} \frac{1}{2} |\vec w|^2 + C \sum{i=1}^{m} \xi^{(i)}$ ,并不再是仅仅使训练误差最小, 同时还会考虑后面的惩罚项, 而当C的取值较小时, 一个带有训练误差, 但参数项较小的点将会称为更优的结果. 第七章 优化算法1. 有监督学习的损失函数损失函数定义了模型的评估指标. 不同的损失函数优化难度不同, 最终得到的模型参数也不同, 针对具体的问题需要选取合适的损失函数. 问题: 有监督学习涉及的损失函数有哪些? 请列举并简述它们的特点Hinge损失: L_{hinge}(f,y) = max{0, 1-fy}在 $fy=1$ 处不可导, 因此不能用梯度下降法优化 Logistic损失 平方损失 交叉熵损失 其他更多: 各种损失函数深入解析 2. 机器学习中的优化问题问题: 机器学习中的优化问题, 哪些是凸优化问题, 哪些是非凸优化问题? 请各举一个例子凸函数的定义: $$ ## 7. L1正则化与稀疏性 此类的相关题目在面试中常被问道, 可以考察面试者对于机器学习模型各个相关环节的了解程度. 在回答时, **不能只给出一些大概的理解, 一定要深入且清晰的回答** **稀疏性的概念:** 说白了就是模型中的参数很多都是0, 这相当于对模型进行了一次特征选择, 只留下一些比较重要的特征, 提高模型的泛化能力.(以免学到过多的个性特征) **稀疏性的另一个重要性:** 机器学习模型的输入动辄几百上千万维, 要想在线上系统中毫秒级响应要求下完成千万维特征的提取以及模型的预测, 还要在分布式环境下在内存中驻留这样一个大的模型, 往往很难做到. ### 问题 L1 正则化使得模型参数具有稀疏性的原理是什么? #### 角度1: 解空间性状 源自于西瓜书第11章, 比较权威且直观的解释, 大多数面试者都是从这个角度出发的. ![](https://wx2.sinaimg.cn/mw690/d7b90c85ly1fvxplq8m55j208u089js0.jpg) ![](https://wx3.sinaimg.cn/mw690/d7b90c85ly1fvxplqd0l9j208u089q3l.jpg) 首先, 假定输入想了 $\vec x$ 仅仅有两个属性, 那么 L1 和 L2 的 $\vec w$ 也只有两个分量, 分别是 $w_1, w_2$, 将这两个分量作为两个坐标轴, 分别绘制出 "无正则平方误差项" 和 "正则项" 的 "等值线": 即在 $(w_1, w_2)$ 空间中取值相同的点. 首先, 根据引入L1和L2范式的损失函数的定义, 我们可以画出上面的解空间图, 其中, 坐标轴上面方形和分别是 L1 和 L2 范式的等值线, 而右上角的"年轮式"椭圆, 就是无正则误差项的等值线. 最终我们的模型需要在误差项和正则项之间折中, 体现在上图中就是误差项与正则项等值线相交的地方. 因此, 可以看到, 采用L1函数时, 误差项与正则项等值线的交点常常出现在坐标轴上, 而采用L2 范式时, 交点常常出现在某个象限中, 所以L1 比L2 范式更易于得到稀疏解. 扩展问题: **为什么加入正则项就是定义了一个解空间约束:** 这个可以从优化的角度来理解, 首先把损失函数看做是一个优化问题, 而加入一个正则项就相当于是给该优化问题加入了一个约束, 即参数 $\vec w$ 的 Lp 范式不能大于m, m不是一个具体的值, 就代表了一种限制, 然后利用拉格朗日函数来解这个在范式约束条件下的最优解问题. **为什么L1和L2的解空间是不是同的:** 他俩的参数运算公式不同, 解空间当然不同 #### 角度2: 函数叠加(梯度下降更新公式) 根据求导公式解释, L1求导区域将最终的权重向 0 靠拢 当 $w$ 为正时, L1求导为负, $w$ 为负时, L1求导为正 而L2求导, 无论 $w$ 的值是什么, 都为负, 因此L2只有减小 $w$ 绝对值的作用, 对解空间的稀疏性没有贡献. (即只会令 $w$ 减小, 但不要求其小到0, 在0附近时就可以) 公式求导过程见 [正则化深入解析]() #### 角度3: 贝叶斯先验 L1 的正则化相当于对模型参数 $w$ 引入了拉普拉斯先验, L2 相当于引入了高斯先验, 而拉普拉斯先验使参数为 0 的可能性更大 联想高斯分布的图像可知, 高斯分布在极值点(0点)附近取不通知的可能性是很接近的, 也就是高斯先验分布认为 $w$ 在极值点附近取不同值的可能性是接近的, 所有它只会要求 $w$ 接近于0, 而不会要求其等于0. 相反, 拉普拉斯分布曲线图在极值点(0dm)处是一个尖峰, 所以拉普拉斯先验分布中参数 $w$ 在极值点(0点)取值的可能性更高 **至于为什么 L1 和 L2 分别对应拉普拉斯先验和高斯先验的证明, 可看[正则化深入解析]()** # 第九章 前向神经网络 ## 2. 深度神经网络中的激活函数 为什么要使用激活函数: 在现实世界里, 往往会遇到线性不可分问题(如XOR异或函数), 需要非线性变换对数据的分布进行重新映射. 对于深度神经网络, 我们在每一层线性变换后叠加一个非线性激活函数, **以避免多层网络等效于单层线性函数, 从而获得更强大的学习和拟合能力** ### 问题1: 写出常用激活函数及其导数 | 激活函数 | 形式 | 导数形式 | | --- | --- | --- | | Sigmoid | $f(x) =\frac{1}{1+e^{-x}}$ | $f'(x)(1-f(x))$ | | Tanh | $f(x) = tanh(x)= \frac{e^x-e^{-x}}{e^x+e^{-x}}$ | $f'(x) = 1-(f(z))^2$ | | ReLU | $f(x)=max(0,x)=\begin{cases} 0 & x \leq 0 \\ x & x>0 \end{cases}$ | $f'(x)=\begin{cases} 0 & x\leq 0 \\ 1 & x>0 \end{cases}$ | | Leaky ReLU | $f(x)=max(\alpha x,x)=\begin{cases} \alpha x & x \leq 0 \\ x & x>0 \end{cases} \alpha 通常为0.1$ | $f(x)=max(\alpha x,x)=\begin{cases} \alpha & x \leq 0 \\ 1 & x>0 \end{cases}$ | | Maxout | $f(x) = max(w_1^T x + b_1, w_2^T x + b_2)$ | $f(x) = max(w_1, w_2)$ | | ELU | $f(x) = \begin{cases} x & x \geq 0 \\ \alpha(e^x - 1) & x]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的函数指针和函数对象]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E5%92%8C%E5%87%BD%E6%95%B0%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[函数指针函数指针：指向函数地址的指针变量。 在C++编译时，每一个函数都有一个入口地址，该地址是存储函数机器语言代码的内存的开始地址。函数指针主要有两方面的用途：调用函数和用作函数参数。函数指针的声明方法如下所示： 123456789101112double pam(int);double (* pf)(int); //将星号与函数名括起来，表示当前星号修饰的是函数名，而不是类型 //可以理解为将pam替换成了(*pf)//通常，要声明指向特定类型的指针，可以首先编写这种函数的原型，然后用(*pf)替换函数名即可pf = pam; // 函数名pam本身就是函数地址，所以可直接赋值，无需用取址符，但是要求pam的特征标必须与pf相同pf = &amp;pam; //但实际上，也可以使用取址符，效果与上面 等价（why？）//以下三种方式都是合法且等价的double x = pam(4);double y = (*pf)(5);double z = pf(6); 从上面的语句可以看出，C++同时允许使用带星号和不带星号的函数指针，最神奇的是效果居然是等价的（对于给函数指针赋值时，函数名带取址符和不带取址符的效果也是等价的！）！ 导致以上“神奇事情”发生的原因是，在C++指定函数指针标准时，出现了两种不同的声音：一种学派认为，由于pf是函数指针，而*pf是函数，因此应将(*pf)()用作函数调用。另一种学派认为，由于函数名是指向该函数的指针，指向函数的指针的行为应该与函数名相似，因此应将pf()用作函数调用使用。C++进行了折衷——这两种方式都是正确的，虽然看上去它们在逻辑上是相冲突的。 下面的声明语句指出了一个函数指针数组，其中每个指针都指向这样的函数：将const double*和int作为参数，返回一个const double *1const double* (*pa[3]) (const double *, int ) = &#123; f1,f2,f3&#125;; 这里不能使用auto，因为auto智能用于单值初始化，而不能用于初始化列表，但声明数组pa后，可以使用auto：1auto pb = pa; // pa和pb都是指向函数指针的指针，使用时可以用下标法，也可以当做指针使用：123456const double *px = pa[0](av,3);const double *py = (*pa[0])(av,3); //如果带星号，则不能少括号//要获得值，可使用运算符const double *x = *pa[0](av,3); //少了括号以后，会取得返回值地址指向的值const double *y = *(*pb[1])(av,3); 如果继续声明了指向函数指针整个数组的指针，则使用方法又有些不同，见下面：12345auto pc = &amp;pa; //pc指向pa的地址*pc[3]; // 相当于 pa[3],代表一个包含三个指针的指针数组(*pc)[3]; // 代表pc是一个函数指针，指向含3个元素的指针数组 函数对象函数对象的实质是对运算符()的重载。 ＃ 函数对象与函数指针的比较 函数对象的优势在于，可以把附加对象保存在函数对象中，也可以存储一些其他的额外信息，甚至可以用来封装类成员函数指针。 但是，函数对象本身并不是指针，因此在使用函数指针的场合中，往往无能为力。例如，不能将对象传给qsort函数！因为它只接受函数指针。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11新特性enable_if与SFINAE用法解析]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84enable-if%E7%94%A8%E6%B3%95%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[SFINAESDINAE的全称是Substitution failure is not an error。意思是“匹配失败并非错误” 通常，在使用模板时，编译器会根据传入的参数来推导最适合的模板函数，在这个推导过程中只要有一个可以正确推导出来（但是不能有多个，否则会引起歧义），那么其他几个模板推导就是会产生编译错误，程序也可以正常通过。如下面的代码所示：123456789101112131415struct Test &#123; typedef int foo;&#125;;template &lt;typename T&gt;void f(typename T::foo) &#123;&#125; // Definition #1template &lt;typename T&gt;void f(T) &#123;&#125; // Definition #2int main() &#123; f&lt;Test&gt;(10); // Call #1. f&lt;int&gt;(10); // Call #2. Without error (even though there is no int::foo) //thanks to SFINAE.&#125; std::enable_if这是一个模板类，该模板可能的实现如下：（也许会有其他版本，但大意都差不多）12345template&lt;bool B, class T = void&gt;struct enable_if &#123;&#125;; //在C++中，struct和class除了默认访问权限不同外，无任何差异template&lt;class T&gt;struct enable_if&lt;true, T&gt; &#123; typedef T type; &#125;; 以上表示，若B为true，则std::enable_if模板类拥有公开成员typedef type ，等于T；否则，无该成员。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第十七章～第十八章]]></title>
    <url>%2Fz_post%2FCpp-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CppPrimerPlusChapter17-18%2F</url>
    <content type="text"><![CDATA[18.3 新的类功能18.3.1 特殊的成员函数18.3.2 默认的方法和禁用的方法在C++中，如果只在程序中提供了移动构造函数，那么编译器将不会自动创建默认的构造函数、复制构造函数和复制赋值构造函数。在这种情况下，可以使用关键字default显式的声明这些方法的默认版本：（即只给出函数头，后接=default，则这些方法的默认版本就会被创建） 12345678class Someclass&#123; public: Someclass(Someclass &amp;&amp;); Someclass() = default; Someclass(const Someclass &amp;) = default; Someclass&amp; operator=(const Someclass &amp;) = default;&#125; 另一方面，关键字delete可用于禁止编译器使用特定的方法，例如，要禁止复制对象，可禁用复制构造函数和复制赋值运算符（之前是通过将其访问权限设值为private来实现的，现在的实现方法更容易理解，且不易犯错）：12 关键字default智能用于6个特殊的成员函数，但delete可用于任何成员函数。delete的一种可能用法是禁止特定的转换。 18.6 可变参数模板]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的mt19937]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84mt19937%2F</url>
    <content type="text"><![CDATA[std::mersenne_twister_engine该类型是一个基于梅森缠绕器算啊费的随机数生成器，可以产生高质量的无符号随机整数 mt19937 和 mt19937_64这两个类型分别是具有预先定义参数的随机数引擎，有松本与西村设计 成员函数seed、operator、discard、min、max 等等 非成员函数operator==、operator!=、等等 成员对象word_size、state_size等等 具体见：https://zh.cppreference.com/w/cpp/numeric/random/mersenne_twister_engine]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的pragma和#ifndef组合语句的联系与区别]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84pragma%E5%92%8Cifndef%E7%BB%84%E5%90%88%E8%AF%AD%E5%8F%A5%E7%9A%84%E8%81%94%E7%B3%BB%E4%B8%8E%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[在C++中，为了避免同一个文件被include多次，常常需要在文中加上一些保证，主要有两种方式，二者用法如下：1#pragma once 12345#ifndef __HEAD__#define __HEAD__#endif 通常，在能够支持这两种方式的编译器上，二者没有太大的区别。下面简介说一下二者格子的优缺点： 对于#ifndef方式来说，不光可以保证同一个文件不会被包含多级，也能保证内容完全相同的两个文件不会被不小心同时包含，但这样就需要编译器每次都扫描头文件内部，因此会使得编译时间相对较长。另外一个缺点就是该方式需要自定义宏名称，当项目很大时，宏名称有“撞车”的风险。 对于#pragma once方式来说，首先是需要code的代码很少，另外不需要自定义宏名称，避免了“撞车”的风险，但是#pragma once提供的保证仅仅是：同一个物理意义上的文件不会被包含多次。如果两个文件内容完全一样，则该方式仍然会重复包含。 结合以上分析，我个人倾向于使用#pragma once，因为需要code的代码更少，无需自想宏名称，另外，出现包含多个内容相同的文件的情况也很很少的（除非有意，否则不太可能出现这种情况）。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《OpenCV3编程入门》]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-OpenCV3%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的有关int的各种形式以及为什么要有size_t类型]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E6%9C%89%E5%85%B3int%E7%9A%84%E5%90%84%E7%A7%8D%E5%BD%A2%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[int,int32_t,int64_t 数据类型特别是int相关的类型在不同位数机器的平台下长度不同。C99标准并不规定具体数据类型的长度大小，只规定级别。作下比较： 16位平台 char 1个字节8位short 2个字节16位int 2个字节16位long 4个字节32位指针 2个字节 32位平台 char 1个字节8位short 2个字节16位int 4个字节32位long 4个字节long long 8个字节指针 4个字节 64位平台 char 1个字节short 2个字节int 4个字节long 8个字节（区别）long long 8个字节指针 8个字节（区别） 为了保证平台的通用性，程序中尽量不要使用long数据库型。同时，通过int_32t等形式来明确int型数据所占有的位数。 另外 还有size_t size_t是一些C/C++标准在stddef.h中定义的。这个类型足以用来表示对象的大小。 size_t的真实类型与操作系统有关，在32位架构中被普遍定义为： typedef unsigned int size_t; 而在64位架构中被定义为： typedef unsigned long size_t;size_t在32位架构上是4字节，在64位架构上是8字节，在不同架构上进行编译时需要注意这个问题。而int在不同架构下都是4字节，与size_t不同；且int为带符号数，size_t为无符号数。 size_t 这个类型的意义：size_t和unsigned int有所不同,size_t的取值range是目标平台下最大可能的数组尺寸,一些平台下size_t的范围小于int的正数范围,又或者大于unsigned int.最典型的,在x64下,int还是4,但size_t是8.这意味着你在x64下最大可能开辟的数组尺寸是2^64.如果你使用int或者unsigned int,那么在x64下如果你的代码中全部使用uint作为数组的尺寸标记,那么你就会失去控制2^32尺寸以上的数组的机会.虽然现在在x64上开辟一个大于2^32大小的连续数组依然是个不大可能的事情,但是……….“640K内存对于任何人来说都足够了”——比尔盖茨 学过计算机组成原理应该不会对此有疑问。int小于等于数据线宽度，size_t大于等于地址线宽度。size_t存在的最大原因可能是因为：地址线宽度历史中经常都是大于数据线宽度的。在数据只有8位的年代，地址率先进入10位，12位，在数据16位的年代，地址也已经进入了20位，24位。目前的int普遍是32位，而size_t在主流平台中都是64位。size_t为什么存在？因为无论int还是unsigned都很可能小于size_t需要的大小，所以必须有个size_t。—补充：据说题主对_t有疑惑。这个问题很简单，仅仅是因为作者选择这样的命名作为编码规范而已。类型名与变量名共享相同的命名空间，所以通常需要在命名方面刻意区分出来。在遥远的 C 时代，发明者很可能是想建议所有的类型名后面加_t，只不过这并没有成为更普遍的编码规范罢了。而现今Java的规范倒比较容易让人接受：大写开头的是类型名，小写开头的是变量名跟函数名，虽然具体细则有不同，但原意都是一样的：变量与类型共享同一个命名空间，因而需要在命名规则上刻意区分开来。 为什么size_t 重要？https://jeremybai.github.io/blog/2014/09/10/size-t 前言：使用size_t可能会提高代码的可移植性、有效性或者可读性，或许同时提高这三者。 在标准C库中的许多函数使用的参数或者返回值都是表示的用字节表示的对象大小，比如说malloc(n) 函数的参数n指明了需要申请的空间大小，还有memcpy(s1, s2, n)的最后一个参数，表明需要复制的内存大小，strlen(s)函数的返回值表明了以’\0’结尾的字符串的长度（不包括’\0’），其返回值并不是该字符串的实际长度，因为要去掉’\0’。 或许你会认为这些参数或者返回值应该被申明为int类型（或者long或者unsigned），但是事实上并不是。C标准中将他们定义为size_t。标准中记载malloc的申明应该出现在，定义为： void *malloc(size_t n); memcpy和strlen的申明应该出现在中： void memcpy(void s1, void const s2, size_t n);size_t strlen(char const s); size_t还经常出现在C++标准库中，此外，C++库中经常会使用一个相似的类型size_type，用的可能比size_t还要多。 据我所知，大部分的C和C++程序员害怕这些库使用size_t，因为他们不知道size_t代表什么或者为什么这些库需要使用它，归根结底，原因在于他们什么时候什么地方需要用到它。 可移植性问题 早期的C语言（由Brian Kernighan 和 Dennis Ritchie 在The C Programming Language书中所写，Prentice-Hall, 1978）并没有提供size_t类型，C标准委员会为了解决移植性问题将size_t引入，举例如下： 让我们来写一个可移植的标准memcpy函数，我们将会看到一些不同的申明和它们在不同平台不同大小的地址空间上编译下的情况。 回忆memcpy(s1, s2, n)函数，它将s2指向地址开始的n个字节拷贝到s2指向的地址，返回s1，这个函数可以拷贝任何数据类型，所以参数和返回值的类型应该为可以指向任何类型的void，同时，源地址不应该被改变，所以第二个参数s2类型应该为const void，这些都不是问题。 真正的问题在于我们如何申明第三个参数，它代表了源对象的大小，我相信大部分程序员都会选择int： void memcpy(void s1, void const *s2, int n); 使用int类型在大部分情况下都是可以的，但是并不是所有情况下都可以。int是有符号的，它可以表示负数，但是，大小不可能是复数。所以我们可以使用unsigned int代替它让第三个参数表示的范围更大。 在大部分机器上，unsigned int的最大值要比int的最大值大两倍，比如说再也给16位的机器上，unsigned int的最大值为65535，int的最大值为32767。 尽管int类型的大小依赖于C编译器的实现，但是在给定的平台上int对象的大小和unsigned int对象的大小是一样的。因此，使用unsigned int修饰第三个参数的代价与int是相同的： void memcpy(void s1, void const *s2, unsigned int n); 这样似乎没有问题了，unsigned int可以表示最大类型的对象大小了，这种情况只有在整形和指针类型具有相同大小的情况下，比如说在IP16中，整形和指针都占2个字节（16位），而在IP32上面，整形和指针都占4个字节（32位）。（参见下面C数据模型表示法） C数据模型表示法 最近，我偶然发现几篇文章，他们使用简明的标记来表述不同目标平台下c语言数据的实现。我还没有找到这个标记的来源，正式的语法，甚至连名字都没有，但他似乎很简单，即使没有正规的定义也可以很容易使用起来。这些标记的一边形式形如： I nI L nL LL nLL P nP。 其中每个大写字母（或成对出现）代表一个C的数据类型，每一个对应的n是这个类型包含的位数。I代表int，L代表long，LL代表long long，以及P代表指针（指向数据，而不是函数）。每个字母和数字都是可选的。 例如，I16P32架构支持16位int和32位指针类型，没有指明是否支持long或者long long。如果两个连续的类型具有相同的大小，通常省略第一个数字。例如，你可以将I16L32P32写为I16LP32，这是一个支持16位int，32位long，和32位指针的架构。 标记通常把字母分类在一起，所以可以按照其对应的数字升序排列。例如，IL32LL64P32表示支持32位int，32位long，64位long long和32位指针的架构；然而，通常写作ILP32LL64。 不幸的是，这种memcpy的申明在I16LP32架构上（整形是16-bit 长整形和指针类型时32-bits）显得不够用了，比如说摩托罗拉第一代处理器68000，在这种情况下，处理器可能拷贝的数据大于65535个字节，但是这个函数第三个参数n不能处理这么大的数据。 什么？你说很容易就可以改正？只需要把memcpy的第三个参数的类型修改一下： void memcpy(void s1, void const *s2, unsigned long n); 你可以在I16LP32目标架构上使用这个函数了，它可以处理更大的数据。而且在IP16和IP32平台上效果也还行，说明它确实给出了memcpy的一种移植性较好的申明。但是，在IP16平台上相比于使用unsigned int，你使用unsigned long可能会使你的代码运行效率大打折扣（代码量变大而且运行变慢）。 在标准C中规定，长整形（无论无符号或者有符号）至少占用32位，因此在IP16平台上支持标准C的话，那么它一定是IP16L32 平台。这些平台通常使用一对16位的字来实现32位的长整形。在这种情况下，移动一个长整形需要两条机器指令，每条移动一个16位的块。事实上，这个平台上的大部分的32位操作都需要至上两条指令。 因此，以可移植性为名将memcpy的第三个参数申明为unsigned long而降低某些平台的性能是我们所不希望看到的。使用size_t可以有效避免这种情况。 size_t类型是一个类型定义，通常将一些无符号的整形定义为size_t，比如说unsigned int或者unsigned long，甚至unsigned long long。每一个标准C实现应该选择足够大的无符号整形来代表该平台上最大可能出现的对象大小。 使用size_t size_t的定义在, , , , 和这些标准C头文件中，也出现在相应的C++头文件, 等等中，你应该在你的头文件中至少包含一个这样的头文件在使用size_t之前。 包含以上任何C头文件（由C或C++编译的程序）表明将size_t作为全局关键字。包含以上任何C++头文件（当你只能在C++中做某种操作时）表明将size_t作为std命名空间的成员。 根据定义，size_t是sizeof关键字（注：sizeof是关键字，并非运算符）运算结果的类型。所以，应当通过适当的方式声明n来完成赋值： n = sizeof(thing); 考虑到可移植性和程序效率，n应该被申明为size_t类型。类似的，下面的foo函数的参数也应当被申明为sizeof： foo(sizeof(thing)); 参数中带有size_t的函数通常会含有局部变量用来对数组的大小或者索引进行计算，在这种情况下，size_t是个不错的选择。 适当地使用size_t还会使你的代码变得如同自带文档。当你看到一个对象声明为size_t类型，你马上就知道它代表字节大小或数组索引，而不是错误代码或者是一个普通的算术值。 在我接下来的一些文章的例子中会使用size_t，敬请期待！]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的aligned_alloc]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84aligned-alloc%2F</url>
    <content type="text"><![CDATA[std::aligned_alloc定义于头文件 void* aligned_alloc( std::size_t alignment, std::size_t size );(C++17 起) 分配 size 字节的未初始化存储，由 alignment 指定其对齐。 size 参数必须是 alignment 的整数倍。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[轻量级深度学习框架ZeroTensor：（二）tensor类的设计与实现]]></title>
    <url>%2Fz_post%2F%E9%A1%B9%E7%9B%AE-ZeroTensor-Tensor%E7%B1%BB%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[Tensor类Tensor类是zerotensor框架的所有数据的基类，它的成员变量和成员函数如下所示： 有关类内部的具体实现可以在源码中的/src/data/tensor.h中看到。]]></content>
      <categories>
        <category>项目</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++中的lambda表达式]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[C++中的lambda与函数对象lambda表达式是C++11中引入的一项新技术，利用lambda表达式可以编写内嵌的匿名函数，用以替换独立函数或者函数对象，并且使代码更可读。但是从本质上来讲，lambda表达式只是一种语法糖，因为所有其能完成的工作都可以用其它稍微复杂的代码来实现。但是它简便的语法却给C++带来了深远的影响。 如果从广义上说，lambda表达式产生的是函数对象。函数对象的本质上是一个类而不是一个函数，在类中，对象重载了函数调用运算符()，从而使对象能够项函数一样被调用，我们称这些对象为函数对象（Function Object）或者仿函数（Functor）。相比lambda表达式，函数对象有自己独特的优势。下面我们开始具体讲解这两项黑科技。 lambda表达式先从一个简单的例子开始，我们定义一个输出字符串的lambda表达式，如下所示，表达式一般都是从方括号[]开始，然后结束于花括号{}：12auto basic_lambda = []&#123;cout&lt;&lt;"Hello Lambda"&lt;&lt;endl;&#125; //定义简单的lambda表达式basic_lambda(); //调用 下面分别是包含参数和返回类型的lambda表达式：12auto add = [] (int a, int b)-&gt;int &#123; return a+b;&#125; //返回类型需要用`-&gt;`符号指出auto multiply = [](int a, int b) &#123;return a*b;&#125; //一般可以省略返回类型，通过自动推断就能得到返回类型 lambda表达式最前面的方括号提供了“闭包”功能。每当定义一个lambda表达式以后，编译器会自动生成一个 匿名类 ，并且这个类重载了()运算符，我们将其称之为闭包类型（closure type）。在运行时，这个lambda表达式会返回一个匿名的闭包实例，并且该实例是一个右值。闭包的一个强大之处在于其可以通过传值或引用的方式捕捉其封装作用域内的变量，lambda表达式前面的方括号就是用来定义捕捉模式以及变量的lambda捕捉块，如下所示：123456int main()&#123; int x = 10; // 定义作用域内的x，方面下面的lambda捕捉 auto add_x = [x](int a)&#123; return a+x; &#125; // 传值捕捉x auto multiply_x = [&amp;x](int a) &#123;return a*x;&#125; //引用捕捉x&#125; 当lambda捕捉块为空时，表示没有捕捉任何变量。对于传值方式捕捉的变量x，lambda表达式会在生成的匿名类中添加一个非静态的数据成员，由于闭包类重载()运算符是使用了const属性，所以不能在lambda表达式中修改传值方式捕捉的变量，但是如果把lambda标记为mutable，则可以改变，如下所示：12345int x = 10;auto add_x = [x](int a) mutable&#123; x * = 2; return a+x;&#125;cout&lt;&lt;add_x(10)&lt;&lt;endk; //输出30return 0; 而对于引用方式捕捉的变量，无论是否标记为mutable，都可以对变量进行修改，至于会不会在匿名类中创建数据成员，需要看不同编译器的具体实现。 lambda表达式只能作为右值，也就是说，它是不能被赋值的12345auto a=[]&#123; cout&lt;&lt;"A"&lt;&lt;endl; &#125;auto b=[]&#123; cout&lt;&lt;"B"&lt;&lt;endl; &#125;a = b; // 非法，lambda表达式变量只能做右值auto c = a; // 合法，生成一个副本 造成以上原因是因为禁用了赋值运算符：1ClosureType&amp; operator=(const ClosureType&amp;) = delete; 但是没有禁用复制构造函数，所以仍然可以用是一个lambda表达式去初始化另一个（通过产生副本）。 关于lambda的捕捉块，主要有以下用法： []：默认不捕捉变量 [=]：默认以值捕捉所有变量（最好不要用） [&amp;]：默认以引用捕捉所有变量（最好不要用） [x]：仅以值捕捉变量x，其他变量不捕捉 [&amp;x]：仅以引用捕捉x，其他变量不捕捉 [=, &amp;x]：默认以值捕捉所有变量，但是x是例外，通过引用捕捉 [&amp;, x]：默认以引用捕捉所有变量，但是x是例外，通过值捕捉 [this]：通过引用捕捉当前对象（其实是复制指针） [* this]：通过传值方式捕捉当前对象 通过以上的说明，可以看到lambda表达式可以作为返回值，赋值给对应类型的函数指针，但是使用函数指针貌似并不是那么方便，于是STL在头文件&lt;functional&gt;中定义了一个多态的函数对象封装std::function，其功能类似于函数指针。它可以绑定到任何类函数对象，只要参数与返回类型相同。如下面的返回一个bool且接收两个int的函数包装器：1std::function&lt;bool(int, int)&gt; wrapper = [](int x, int y) &#123; return x&lt;y; &#125; lambda表达式还有一个很重要的应用是其可以作为函数的参数，如下所示：1234int value = 3;vector&lt;int&gt; v&#123;1,2,3,4,5,6,7&#125;;int count == std::count_if(v.begin, v.end(), [value](int x)&#123;return x&gt;value;&#125;); 下面给出lambda表达式的完整语法：1234567// 完整语法[ capture-list ] ( params ) mutable(optional) constexpr(optional)(c++17) exception attribute -&gt; ret &#123; body &#125;// 可选的简化语法[ capture-list ] ( params ) -&gt; ret &#123; body &#125; [ capture-list ] ( params ) &#123; body &#125; [ capture-list ] &#123; body &#125; capture-list：捕捉列表，这个不用多说，前面已经讲过，记住它不能省略； params：参数列表，可以省略（但是后面必须紧跟函数体）； mutable：可选，将lambda表达式标记为mutable后，函数体就可以修改传值方式捕获的变量； constexpr：可选，C++17，可以指定lambda表达式是一个常量函数； exception：可选，指定lambda表达式可以抛出的异常； attribute：可选，指定lambda表达式的特性； ret：可选，返回值类型； body：函数执行体。 lambda新特性（C++14）在C++14中，lambda又得到了增强，一个是泛型lambda表达式，一个是lambda可以捕捉表达式。 lambda捕捉表达式前面讲过，lambda表达式可以按传值或者引用捕捉在其作用域范围内的变量。而有时候，我们希望捕捉不在其作用域范围内的变量，而且最重要的是我们希望捕捉右值。所以C++14中引入了表达式捕捉，其允许用任何类型的表达式初始化捕捉的变量，如下：12345678// 利用表达式捕获，可以更灵活地处理作用域内的变量int x = 4;auto y = [&amp;r = x, x = x + 1] &#123; r += 2; return x * x; &#125;();// 此时 x 更新为6，y 为25// 直接用字面值初始化变量auto z = [str = "string"]&#123; return str; &#125;();// 此时z是const char* 类型，存储字符串 string 可以看到捕捉表达式扩大了lambda表达式的捕捉能力，有时候你可以用std::move初始化变量。这对不能复制只能移动的对象很重要，比如std::unique_ptr，因为其不支持复制操作，你无法以值方式捕捉到它。但是利用lambda捕捉表达式，可以通过移动来捕捉它： 123auto myPi = std::make_unique&lt;double&gt;(3.1415);auto circle_area = [pi = std::move(myPi)](double r) &#123; return *pi * r * r; &#125;;cout &lt;&lt; circle_area(1.0) &lt;&lt; endl; // 3.1415 泛型lambda表达式从C++14开始，lambda表达式支持泛型：其参数可以使用自动推断类型的功能，而不需要显示地声明具体类型。这就如同函数模板一样，参数要使用类型自动推断功能，只需要将其类型指定为auto，类型推断规则与函数模板一样。这里给出一个简单例子： 1234auto add = [](auto x, auto y) &#123; return x + y; &#125;;int x = add(2, 3); // 5double y = add(2.5, 3.5); // 6.0 函数对象函数对象是一个广泛的概念，因为所有具有函数行为的对象都可以称为函数对象。这是一个高级抽象，我们不关心对象到底是什么，只要其具有函数行为即可。函数行为是指可以使用()调用并传递参数，如下所示：1function(arg1, arg2, ...); //函数调用 由此，lambda表达式也是一个函数对象。该函数对象实际上是一个匿名类的实例，且这个类实现了函数调用运算符()。 泛型提供了高级抽象，不论是lambda表达式、函数对象、还是函数指针，都可以传入到STL算法中（如for_each）。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的枚举类]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84%E6%9E%9A%E4%B8%BE%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[p372一、简述 强类型枚举（Strongly-typed enums），号称枚举类型，是C++11中的新语法，用以解决传统C++枚举类型存在的缺陷。传统C++中枚举常量被暴漏在外层作用域中，这样若是同一作用域下有两个不同的枚举类型，但含有相同的枚举常量也是不可的，比如： enum Side{Right,Left};enum Thing{Wrong,Right};这是不能一起用的。 另外一个缺陷是传统枚举值总是被隐式转换为整形，用户无法自定义类型。C++11中的强类型枚举解决了这些问题。————————————————————————— 二、强类型枚举 强类型枚举使用enum class语法来声明，如下： enum class Enumeration{ VAL1, VAL2, VAL3=100, VAL4};这样，枚举类型时安全的，枚举值也不会被隐式转换为整数，无法和整数数值比较，比如（Enumeration：：VAL4==10会触发编译错误）。 另外枚举类型所使用的类型默认为int类型，也可指定其他类型，比如： enum calss Enum:unsigned int{VAL1,VAL2};正如前面所说，强类型枚举能解决传统枚举不同枚举类下同枚举值名的问题，使用枚举类型的枚举名时，必须指明所属范围，比如：Enum::VAL1，而单独的VAL1则不再具有意义。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重写C++中异常类的what方法]]></title>
    <url>%2Fz_post%2FCpp-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95-%E9%87%8D%E5%86%99Cpp%E4%B8%AD%E5%BC%82%E5%B8%B8%E7%B1%BB%E7%9A%84what%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[待补充完善：错误原因以及为什么这么修改坑源在实现项目ZeroTensor的专属异常类时，需要实现exception类的what方法。 出现问题及解决办法首先需要看一下exception基类中关于what方法的原始定义： 12 下面是正确的重写方式 1const char *what() const throw() override &#123; return error_msg_.c_str(); &#125; 如果去掉throw() ， 则会报错： 12looser throw specifier for ‘virtual const char* zerotensor::ZerotensorError::what() const’ const char *what() const override &#123; return error_msg_.c_str(); &#125; 如果将char * 改为 string，则会报错： 12error: ‘const string zerotensor::ZerotensorError::what() const’ cannot be overloaded const string what() const throw() override &#123; return error_msg_; &#125;]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>踩坑记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的mutable关键字]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84mutable%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[在C++中，mutable是为了突破const的限制而设置的。被mutable修饰的变量，将永远处于可变的状态，即使在一个const函数中，甚至结构体变量或者类对象为const，其mutable成员也可以被修改。 mutable在类中只能够修饰非静态数据成员。mutable 数据成员的使用看上去像是骗术，因为它能够使const函数修改对象的数据成员。然而，明智地使用 mutable 关键字可以提高代码质量，因为它能够让你向用户隐藏实现细节，而无须使用不确定的东西。我们知道，如果类的成员函数不会改变对象的状态，那么这个成员函数一般会声明成const的。但是，有些时候，我们需要在const的函数里面修改一些跟类状态无关的数据成员，那么这个数据成员就应该被mutalbe来修饰。 12345678910111213141516171819202122232425262728293031323334struct tagData&#123; int a; mutable int b;&#125;;class clsData&#123;public: int a; mutable int b; void show() const &#123; a = 2;//错误，不能在const成员函数中修改普通变量 b = 5;//正确 printf("a: %d, b: %d\r\n"); &#125;&#125;;int _tmain(int argc, _TCHAR* argv[])&#123; //结构体变量为const，其mutable成员也可以被修改 const tagData dat = &#123;0, 0&#125;; dat.a = 8;//编译错误 dat.b = 9;//编译通过 //类对象为const，其mutable成员也可以被修改 clsData cls; cls.show(); return 0;&#125; const承诺的是一旦某个变量被其修饰，那么只要不使用强制转换(const_cast)，在任何情况下该变量的值都不会被改变，无论有意还是无意，而被const修饰的函数也一样，一旦某个函数被const修饰，那么它便不能直接或间接改变任何函数体以外的变量的值，即使是调用一个可能造成这种改变的函数都不行。这种承诺在语法上也作出严格的保证，任何可能违反这种承诺的行为都会被编译器检查出来。 mutable的承诺是如果某个变量被其修饰，那么这个变量将永远处于可变的状态，即使在一个const函数中。这与const形成了一个对称的定义，一个永远不变，而另外一个是永远可变。 看一个变量或函数是否应该是const，只需看它是否应该是constant或invariant，而看一个变量是否应该是mutable，也只需看它是否是forever mutative。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用CUDA进行一维数组的矢量求和]]></title>
    <url>%2Fz_post%2FCUDA-CUDA%E7%A4%BA%E4%BE%8B%E5%AD%A6%E4%B9%A0-%E4%B8%80%E7%BB%B4%E6%95%B0%E7%BB%84%E7%9A%84%E7%9F%A2%E9%87%8F%E6%B1%82%E5%92%8C%2F</url>
    <content type="text"><![CDATA[基于GPU的一维数组的矢量求和 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;#include &lt;cstdio&gt;#define N 20//如果忘记写global，会报错：error: a host function call cannot be configured__global__ void add(int *a, int *b, int *c)&#123; int tid = blockIdx.x; if(tid&lt; N)&#123; c[tid] = a[tid] + b[tid]; &#125;&#125;int main()&#123; int a[N]; int b[N]; int c[N]; int *dev_a, *dev_b, *dev_c; /*cudaMalloc((void**)&amp;dev_a, N*sizeof(int));*/ /*cudaMalloc((void**)&amp;dev_b, N*sizeof(int));*/ /*cudaMalloc((void**)&amp;dev_c, N*sizeof(int));*/ cudaMalloc(&amp;dev_a, N*sizeof(int)); cudaMalloc(&amp;dev_b, N*sizeof(int)); cudaMalloc(&amp;dev_c, N*sizeof(int)); for(int i =0 ; i&lt;N; i++)&#123; a[i] = i; b[i] = i; &#125; cudaMemcpy(dev_a, a, N*sizeof(int), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, N*sizeof(int), cudaMemcpyHostToDevice); add&lt;&lt;&lt;N,1&gt;&gt;&gt;(dev_a,dev_b,dev_c); cudaMemcpy(c, dev_c, N*sizeof(int), cudaMemcpyDeviceToHost); cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c); for(int i =0 ;i&lt;N; i++)&#123; //如果错误的访问量dev_c[i]，会报告段错误 std::cout&lt;&lt;c[i]&lt;&lt;std::endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA示例学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第十六章]]></title>
    <url>%2Fz_post%2FCpp-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CppPrimerPlusChapter16%2F</url>
    <content type="text"><![CDATA[第十六章 string类和标准模板库16.1 string 类头文件： string：支持的是string类 string.h / cstring： 支持的是C-风格字符串的C库字符串函数 16.1.1 构造字符串string类的构造函数如下（用ctor标识，这是传统C++中构造函数的缩写，表中的NBTS（null-terminated string）标识以空字符结束的字符串——传统的C字符串，size_type 是一个依赖于实现的整型，在头文件string中定义）： 构造函数 描述 string(const char *s) 将string对象初始化为s指向的NBTS string(size_type n, char c) 创建一个包含n个元素的string对象，其中每个元素都被初始化为字符c string(const string &amp;str) 将一个string对象初始化为string对象str（复制构造函数） string() 创建一个默认的string对象，长度为0（默认构造函数） string(const char *, size_type n) 将string对象初始化为s指向的NBTS的前n个字符，即使超过了NBTS的结尾 template string(Iter begin, Iter end) 将string对象初始化为区间[begin,end)内的字符，其中begin和end的行为就像指针，用于指定位置，范围包括begin在内，但不包括end string(const string &amp;str, size_type pos = 0, size_type n = npos) 将一个stirng对象初始化为对象str从位置pos开始到结尾的字符，或从pos开始的n个字符 string(string &amp;&amp; str) noexcept C++11新增，它将一个string对象初始化为对象str，并可能修改str（移动构造函数） string(initializer_list il) C++11新增，它将一个string对象初始化为初始化列表il中的字符 在使用构造函数时都进行了简化，即隐藏了这样一个事实：string实际上是模板具体化basic_string&lt;char&gt;的一个typedef，同时省略了与内存管理相关的参数 16.1.2 string类输入对于C-风格字符串，有3种方式：12345char info[100];cin &gt;&gt; info; //read a word 遇到空格换行停止cin.getline(info, 100); // read a line, discard \ncin.get(info, 100); // read a line, leave \n in queue 对于string对象，有两种方式：123string stuff;cin &gt;&gt; stuff; // read a wordgetline(cin, stuff); // read a line, discard \n 两个版本的getline都有一个可选参数，用于指定使用哪个字符来确定输入的边界。在功能上，它们之间主要的区别在于，string版本的getline()将自动调整目标string对象的大小，使之刚好能够存储输入的字符。1234567char fname[10];string lname;cin &gt;&gt; fname; // could be a problem if input size &gt; 9 chcin &gt;&gt; lname; // can read a very,very long wordcin.getline(fname,10); // may truncate inputgetline(cin, fname); // no truncation 在设计方面的一个区别是，读取C-风格字符串的函数是istream类的方法，而string版本是独立的函数。这就是对于C-风格字符串输入，cin是调用对象；而对于string对象输入，cin是一个函数参数的原因。这种规则也适用于&lt;&lt;形式：1123cin.operator&gt;&gt;(fname);operator&gt;&gt;(cin, lname); string类可以自动调整对象的大小，使之与输入匹配，但也存在一些限制： string对象的最大允许长度： 由常量string::npos 指定，通常是最大的unsigned int值 程序可以使用的内存量 string版本的getline()函数从输入中读取字符，并将其存储到目标string中，知道发生下列三种情况之一： 到达文件尾，在这种情况下，输入流的eofbit将被设置，这意味着方法fail()和eof()都将返回true； 遇到分界字符（默认为\n），在这种情况下，将把分解字符从输入流中删除，但不存储它 读取的字符数打到最大允许值（string::npos与可供分配的内存字节数中较小的一个），在这种情况下，将设置输入流的failbit，这意味着方法fail()返回true。 16.1.3 使用字符串C++对每个关系运算符进行了重载，以便能够将string对象与另一个string对象或C-风格字符穿进行比较：123operator&lt;(const string &amp;, const string &amp;);operator==(const string &amp;, const char *);operator!=(const char *, const string &amp;); size()和length()方法都返回字符串中的字符数，二者没有区别，前者是为提供STL兼容性添加的，后者是较早版本的string类使用的方法名。 可以以多种不同的方式在字符串中搜索给定的子字符串或字符。下表描述是了find()方法的4个版本。 方法原型 描述 size_type find(const string &amp;st ,size_type pos=0) const 从字符串的pos位置开始，查找子字符串str。如果找到，则返回该字符串首次出现时其首字符的索引；否则，返回string::npos size_type find(const char* s, size_type pos=0) const 从字符串的pos位置开始，查找子字符串s。如果找到，则返回该字符串首次出现时其首字符的索引；否则，返回string::npos size_type find(const char *s, size_type pos=0,size_type n) 从字符串的pos位置开始，查找s的前n个字符组成的子字符串。如果找到，则返回该子字符串首次出现时其首字符的索引；否则，返回string::npos size_type find(char ch, size_type pos = 0) const 从字符串的pos位置开始，查找字符ch。如果找到，则返回该字符首次出现的位置；否则，返回string::npos 除此之外，string库还提供了其他相关的方法：rfind() ,find_first_of(), find_last_of(), find_first_not_of(), find_last_not_of()等等。 16.1.4 stirng类还提供了哪些功能还有很多功能，具体可看p665或者附录F。 16.1.5 字符串种类表面上看起来string类是基于char类型的，但是，实际上，string库是基于一个模板类的：12345template&lt; class CharT, class Traits = std::char_traits&lt;CharT&gt;, class Allocator = std::allocator&lt;CharT&gt;&gt; class basic_string; 模板basic_string有多个具体化，每个具体化都有一个typedef名称，如string、wstring、u16string等等。 16.2 智能指针模板类智能指针是行为类似于指针的 类对象 。共有三种可以帮助管理动态内存分配的智能指针模板： auto_ptr unique_ptr shared_ptr 模板auto_ptr是C++98提供的解决方案，C++11已将其摒弃，并提供了后两种解决方案。 16.2.1 使用智能指针以上三个智能指针模板（auto_prt,unique_ptr,shared_ptr)都定义了类似指针的对象，可以将new获得的地址赋给这种对象。 当智能指针过期时，其析构函数将使用delete来释放内存，因此，如果将new返回的地址赋给这种对象，将无需记住稍后释放这些内存。（要创建智能指针，需包含头文件memory） 16.2.2 有关智能指针的注意事项当多个指针对象指向同一个对象时，三种智能指针的区别： auto_ptr：调用多次析构函数，执行多次delete，报错 unique_ptr：建立所有权（ownership）概念，对于特定的对象，只能有一个智能指针可拥有它，在删除后，会将所有权转让 shared_ptr：利用引用计数（reference counting），仅当最后一个指针过期时，才调用delete。 16.2.3 unique_ptr为何优于auto_prtunique_ptr更安全： 它使用了C++11新增的移动构造函数和右值引用unique_ptr可以用于数组的变体：auto_ptr智能使用new和delete，而unique_ptr可以还可以使用new []和delete []。 警告： 使用new分配内存时，才能使用auto_ptr和shared_ptr，使用new[]分配内存时，不能使用它们 不使用new分配内存时，不能使用auto_ptr和shared_ptr 不使用new和new[]分配内存时，不能使用unique_ptr 16.2.4 选择智能指针如果程序要使用多个指向同一个对象的指针，应选择shared_ptr。 16.3 标准模板库STL提供了一组表示容器、迭代器、函数对象和算法的模板。 容器：是一个与数组类似的单元，可以存储若干个值。STL容器是同质的，即存储的值的类型相同 迭代器：能够用来遍历容器的对象，与能够遍历数组的指针类似，是广义指针 函数对象：类似于函数的对象，可以是类对象或函数指针 算法：完成特定任务（如find，verse等）。 STL不是面对对象的变成，而是一种不同的编程模式——泛型编程（generic programming） 关于更多个STL方法和函数可以看附录G 16.3.1 模板类vector分配器：与string类相似，各种STL容器模板都接受一个可选的模板参数，该参数指定使用哪个分配器对象来管理内存。如果省略了该模板参数的值，则容器类模板将默认使用allocator&lt;T&gt;类，这个类使用new和delete。 123template &lt;class T, class Allocator = allocator&lt;T&gt; &gt;class vector &#123;...&#125; 16.3.2 可对矢量执行的操作每个容器类都定义了一个合适的迭代器，该迭代器的类型是一个名为iterator的typedef，其作用域为整个类。 1vector&lt;double&gt;::iterator pd; // pd an iterator 超尾(past-the-end) ：一种迭代器，指向容器的最后一个元素的后面，就像是C-风格字符串最后一个字符后面的空字符一样，由end()成员函数标识。 16.3.3 对矢量可执行的其他操作对于搜索、排序、随机排序等等很常见的操作，矢量模板类并没有包含！！ 但是 ，STL从更广泛的角度定义了非成员（non-member）函数来执行这些操作，即不是为每个容器类定义find()函数，而是定义了一个适用于所有容器类的非成员函数find()。这种设计理念省去了大量重复的工作。 另一方面，STL有时也会定义一个功能相同的成员函数。这是因为对有些操作来说，类特定算法的效率比同于算法高，比如，vector的成员函数swap()的效率比非成员函数swap()高，但非成员函数可以交换冷儿类型不同的容器的内容。 16.3.4 基于范围的for循环（C++11）第五章的示例： 123double prices[5] = &#123;4.99, 10.99, 6.87, 7.99, 8.48&#125;;for (double x : prices) cout &lt;&lt; x &lt;&lt; std::endl; 在这种for循环中，先声明一个类型与容器内容类型相同的变量，然后写明容器名称，接下来就可以访问，如下面的代码可以写的更加精简： 1234for_each(books.begin(), books.end(), ShowReview); //for_each形式for( auto x:books) ShowReview(x)); // 注意，for_each不能修改容器的容器，而基于范围的for循环可以通过指定一个引用参数来修改内容。例如，假设有如下函数：1void InflateReview(Review &amp;r) &#123;r.rating++;&#125; 可使用如下循环的books的每个元素执行该函数1for(auto &amp;x:books) InflateReview(x); 16.4 泛型编程面向对象编程关注的是编程的数据方面，而泛型编程关注的是算法。它们之间的共同点是抽象和创建可重用代码，但它们的理念决然不同。泛型编程旨在编写独立于数据类型的代码。 16.4.1 为何使用迭代器模板使得算法独立于存储的数据类型，而迭代器使算法独立于使用的容器类型。 例如，在使用find函数时，可以用迭代器来实现不依赖于具体类型的查找。 实际上，作为一种编程风格，最好避免直接使用迭代器，而应尽可能使用STL函数(如for_each()）来处理细节。也可以使用C++11新增的基于范围的for循环。 16.4.2 迭代器类型不同的算头对迭代器要求不同，有的只要求可读，有的要求可随机访问等等。STL定义了5种不迭代器，并根据所需的迭代器类型对算法进行了描述： 输入迭代器 输出迭代器 正向迭代器 双向迭代器 随机访问迭代器 对于不同的算法，需要的迭代器不同，如下面两种算法分别需要输入迭代器和随机访问迭代器 12345template&lt;typename InputIterator, typename T&gt;InputIterator find(InputIterator first, InputIterator last, const T &amp;value);template&lt;typename RandomAccessIterator&gt;void sort(RandomAccessIterator first, RandomAccessIterator last); 对于这5种迭代器，都可以执行解除引用操作（即*运算符），也可进行比较，看其是相等还是不相等（==，！=运算符）。如果两个迭代器相同，则对它们执行解除引用操作得到的值将相同。 输入迭代器 &emsp;&emsp;术语“输入”是从程序的角度出发的，即来自容器的信息被视为输入（从迭代器传到程序中），因此，输入迭代器可被程序用来读取容器中的信息。需要输入迭代器的算法将不会修改容器中的值 &emsp;&emsp;输入迭代器必须能做访问容器中所有的值，这是通过支持++运算符（前缀格式operator++和后缀格式operator++(int)）来实现的。 &emsp;&emsp; 注意： 并不能保证输入迭代器第二次遍历容器时，顺序不变。另外，输入迭代器被递增后，也不能保证其先前的值仍然可以被解除引用。基于输入迭代器的任何算法都应当是单通行（single-pass）的，不依赖于前一次便利时的迭代器值，也不依赖于本次遍历中前面的迭代器值。—— 输入迭代器是单向迭代器，可以递增，但不能倒退 输出迭代器 &emsp;&emsp;同理，“输出”指用于将信息从程序传输给容器的迭代器（从程序输出到迭代器中），输出迭代器智能解除引用让程序修改容器值，而不能读取容器内的值。输出迭代器也是单通行的，只能写不能读。 正向迭代器 &emsp;&emsp; 只是用++运算符遍历容器，每次沿容器向前移动一个元素。与输入和输出迭代器不同的是，它总是按相同的顺序遍历一系列值，另外，将正向迭代器递增后，仍然可以对前面的迭代器值解除引用，并得到对应的值 。这些特征使得正向迭代器是多通行的（可以多次通行容器）。 双向迭代器 &emsp;&emsp;双向迭代器具有正向迭代器的所有特性，且同时支持两种（前缀和后缀）递减运算符。 随机访问迭代器 &emsp;&emsp;有些算法（如排序和二分检索）要求能够直接跳到容器中的任何一个元素（将想数组下标访问一样），因此就有了随机访问迭代器。该迭代器具有双向迭代器的所有特性，同时添加了支持随机访问的操作和用于对元素进行排序的关系运算符。 16.4.3 迭代器层次结构可以看出，迭代器类型形成了一个层次结构。后面的迭代器不仅拥有之前迭代器的所有功能，同时还有自己的功能。 每个容器类都定义了一个类级typedef名称——iterator。（实际上这使用指针实现的，并不是一种新的类型）。 16.4.4 概念、改进和模型STL有若干个用C++语言无法表达的特性，如迭代器种类。正向迭代器是一系列要求，而不是类型。（迭代器通常可以用常规指针实现，所以迭代器本身并不是一种类型）。 STL使用术语“概念（concept）”来描述一系列的要求。 概念可以具有类似继承的关系，就像双向迭代器继承了正向迭代器的功能。然而，不能将C++继承机制用于迭代器，但从概念上看，它确实能够继承，有些STL文献使用属于改进（refinement）来表示这种概念上的继承，因此，双向迭代器是对正向迭代器概念的一种改进。 概念的具体实现被称为模型（model）。因此，指向int的常规指针是一个随机访问迭代器模型，同时也是一个正向迭代器模型。 将指针用作迭代器 &emsp;&emsp;迭代器是广义上的指针，其本身就是一种指针，因此，STL算法可以使用指针来对基于指针的非STL容器进行操作。例如，可将STL算法用于数组。123const int SIZE = 100;double Receipts[SIZE];sort(Receipts,Receipts+SIZE); //用STL的sort算法对数组进行排序 &emsp;&emsp;STL提供了一些预定义迭代器，如ostream_iterator和istream_iterator模板等，都定义在iterator头文件中。 其他有用的迭代器 &emsp;&emsp;头文件iterator还提供了其他一些专用的预定义迭代器类型，它们是reverse_iterator, back_insert_iterator, front_insert_iterator和insert_iterator等。 16.4.5 容器种类 容器概念：概念是具有名称（如容器、序列容器、关联容器等）的通用类别 容器类型：是可用于创建具体容器对象的模板。以前的11个容器类型为：deque, list, queue, priority_queue, stack, vector, map, multimap, set, multiset和bitset。 C++11新增了：forward_list, unordered_map, unordered_multimap, unordered_set和unordered_multiset，且不再将bitset视为容器，而将其视为一种独立的类别。 容器概念 &emsp;&emsp;没有与基本容器概念对应的类型，但概念描述了所有容器类都通用的元素。存储在容器中的类型必须是可复制构造和可赋值的。STL特定操作的时间复杂度有三种，分别是：编译时间、固定时间和线性时间。 C++11新增的容器要求 &emsp;&emsp;下表列出了C++11新增的通用容器要求，其中，复制赋值和移动赋值之间的差别在于，复制操作保留源对象，而移动操作可修改源对象，还可能转让所有权，而不做任何复制。如果源对象是临时的，移动操作的效率将高于常规复制。 表达式 返回类型 说明 复杂度 X u(rv); 调用移动构造函数后，u和值和rv的原始值相同 线性 X u = rv; 作用同上 a = rv; X&amp; 调用移动赋值运算符后，u的值和rv的原始值相同 线性 a.cbegin() const_iterator 返回指向容器第一个元素的const迭代器 固定 a.cend() const_iterator 返回超尾值的const迭代器 固定 序列 16.7.3 使用initializer_list]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的成员初始化列表]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84%E6%88%90%E5%91%98%E5%88%9D%E5%A7%8B%E5%8C%96%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[C++ C++的类对象创建过程C++ 在创建类时需要经过两个阶段：分配空间（Allocation）和初始化（Initialization） 分配空间创建C++类对象的第一步就是为其分配内存空间。对于全局对象，静态对象以及分配在栈区域内的对象，对它们的内存分配是在编译阶段就完成了，而对于分配在堆区域内的对象，它们的分配是在运行是动态进行的。内存空间的分配过程涉及到两个关键的问题：需要分配空间的大小以及是否有足够的内存空间来满足分配。 初始化首先需要区分两个概念：初始化（Initialization）和赋值（Assignment）。初始化早于赋值，它是随着对象的诞生一起进行的。而赋值是在对象诞生以后又给予它一个新的值。 在C++中，提供了类成员的初始化列表，并且初始化列表是先于构造函数体内的代码执行的。 关于成员初始化列表对于以下三种情况，必须使用成员初始化列表 需要初始化的数据成员是对象的情况（包含继承情况下，通过显示调用父类的构造函数对父类数据成员进行初始化） 需要初始化const修饰的类成员 需要初始化引用成员数据 子类初始化父类的私有成员，需要在（并且只能在）参数初始化列表中显示调用父类的构造函数。（这种其实可以并到第一种情况，因为初始化私有成员，就以为着初始化对象） 类对象是默认使用初始化列表的，当没有无参构造函数时，就必须显式使用初始化列表（所以不论如何，都会使用到初始化列表）。 当类成员中含有一个const对象时，或者一个引用时，必须经过成员初始化列表进行初始化，因为const对象或者引用在声明的同时必须初始化，而在构造函数中，做的是对它们的赋值，并不是初始化。 构造函数与初始化列表成员初始化列表只能用于构造函数 在类的实现中，构造函数体内“初始化”的实际上是赋值而不是初始化。也就是说，当代码运行到构造函数内部时，初始化列表已经执行完了，因此相当于是先初始化了一遍，然后又赋值了一遍，重复计算，浪费效率，因此应该优先使用初始化列表。同时，当没有默认的无参构造函数时，必须显式使用初始化列表。 创建派生类对象时，程序首先调用基类构造函数，然后再调用派生类构造函数。基类构造函数负责初始化继承的数据成员；派生类构造函数主要用于初始化新增的数据成员。派生类构造函数总是调用一个基类构造函数。当基类没有默认的构造函数时，就必须显式指明调用哪一个构造函数。 注意：除了虚基类以外，类只能将值传递会相邻的基类，但后者可以使用相同的机制将信息传递给上层相邻的基类，以此类推。 初始化列表的顺序构造函数需要初始化的数据成员，不论是否显式的出现在构造函数的成员初始化列表中，都会在该处完成初始化，并且初始化的顺序和变量声明时的顺序是一致的，与列表中的先后顺序无关]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中类的对象和对象指针之间的区别]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%B1%BB%E7%9A%84%E5%AF%B9%E8%B1%A1%E5%92%8C%E5%AF%B9%E8%B1%A1%E6%8C%87%E9%92%88%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[很关键的一点：定义对象实例时，分配了内存，指针变量则未分配类对象所需内存。 类的指针:他是一个内存地址值,他指向内存中存放的类对象(包括一些成员变量所赋的值).对象,他是利用类的构造函数在内存中分配一块内存(包括一些成员变量所赋的值). 指针变量是间接访问，但可实现多态（通过父类指针可调用子类对象），并且没有调用构造函数。直接声明可直接访问，但不能实现多态，声明即调用了构造函数（已分配了内存）。 类的对象:用的是内存栈,是个局部的临时变量.类的指针:用的是内存堆,是个永久变量,除非你释放它. 1.在类的声明尚未完成的情况下，可以声明指向该类的指针，但是不可声明该类的对象… 例如：含有纯虚成员函数的抽象类。2.父类的指针可以指向子类的对象.. 在应用时: 1.引用成员: 对象用” . “操作符; 指针用” -&gt; “操作符. 2.生命期: 若是成员变量,则是类的析构函数来释放空间;若是函数中的临时变量,则作用域是该函数体内.而指针,则需利用delete 在相应的地方释放分配的内存块. 注意:用new ,一定要delete.. C++的精髓之一就是多态性，只有指针或者引用可以达到多态。对象不行类指针的优点：第一实现多态。第二，在函数调用，传指针参数。不管你的对象或结构参数多么庞大，你用指针，传过去的就是4个字节。如果用对象，参数传递占用的资源就太大了]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的const关键字]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84const%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[const常用形式及代表含义 含义 使用形式 及 作用 const常量 const int Max = 100; int const Max =100 const与int的位置可互换，二者等价 修饰后的变量在程序的任意位置将不能再被修改，就如同常数一样，任何修改该变量的尝试都会导致编译错误（由于常量在定义以后就不能再被修改，所以定义时必须初始化）。 对于类中的const成员变量必须通过初始化列表进行初始化 const引用 const int i = 1024； const int &amp;ref_i = i; int const &amp;ref2_i = i后两句等价int &amp;const ref3_i = i这种方式未定义，会报错：‘const’ qualifiers cannot be applied to ‘int&amp;’ cosnt引用是指向const对象或者普通对象的引用，该引用ref_i可以读取对象i的值，但是，不能修改 i的值，任何对ref_i的赋值都是非法的。 并且 不能用普通引用指向const常量（int &amp;ref4_i = i; // 非法）。（注意，一旦引用被定义，它就不能再指向其它对象，这是引用本身的性质，这也是为什么引用必须进行初始化的原因）。 总结来说就是const引用只是表明：保证不会通过此引用间接的改变被引用的对象！ const指针 1）int age = 39; const int *ptr = &amp;age; 2）const int age = 98; const int *ptr = &amp;age;3）const int age = 32; int *ptr = &amp;age;4）int age = 90; int * const ptr = &amp;age; 对于1），const修饰的是int，表明ptr指向一个const int，但是ptr和age本身都不是const，不能使用ptr来修改age的值，但是age自身可以修改自己的值，同时，ptr也可以转而指向其它变量； 对于2），const修饰的是int，表明ptr指向一个const int，同时age本身就是const，说明既不能通过ptr，也不能通过age来修改变量age的值，但是ptr本身仍然不是const，因此可以转而指向其它变量；对于3），C++禁止将const变量的地址赋给非const指针（除非使用强制类型转换）；对于4），const修饰的是*，表明ptr本身是一个常量指针，这使得ptr自身的值不能改变，也就是只能指向age，不能指向其它变量 const函数参数 void fun(const int * i); void fun(const int &amp; i); 不能在函数体内修改指针或引用指向的值，但是这里指针可以转而指向其他值（其实没多大用，因为指针本身就是值传递，即使改变指向，也不会影响实参的指向，除非用二级指针） const函数返回值 const int fun( int i); 阻止用户修改返回值，返回值必须要相应的赋给一个具有const属性的变量 const成员函数 &lt;类型说明符&gt; &lt;函数名&gt; ( &lt;参数表&gt; ) const; 不会修改类的成员数据，也不能调用其它非const成员函数。 可以利用const限定符实现函数重载。 const对象默认会调用const成员函数 const限定符和static的区别 静态变量的值虽然只能进行一次初始化，但是它的值是可变的。而const的值是不可变的。 const定义的变量在超出其作用域后空间就会被释放，而static定义的静态变量不会释放空间，而是一直存在，知道程序结束 static表示静态，类的静态成员函数、静态成员变量都是和类相关的，而不是和具体的对象相关，即使没有具体对象，也能调用静态成员函数和静态成员变量。而类则是和具体的对象相关的，不同的对象独占一个const变量 static静态成员变量不能在类的内部进行初始化，智能在类的外部进行初始化，并且初始化时不能加static关键字。之后，无需创建对象也能通过类使用该静态变量，同时 由于const变量只是针对于某个类的对象而言的，类可以创建多个不同的对象，每个对象都有自己的const变量，又因为const变量值只能进行一次初始化而不仅再次赋值，因此， const变量也不能在类的内部初始化，而只能在类构造函数的初始化列表中进行 。 如果想要创建整个类的恒定变量，那么应用使用static const来声明（const枚举量也可以） 关于const的其它注意事项将非const指针赋给const指针（两级间接关系）p222 const引用与不可寻址值const引用可以用不同类型的对象初始化（主要能从一种类型转换到另一种类型即可），也可以用字面常量初始化，如下所示： 12345double dval = 3.14159;//下3行仅对const引用才是合法的const int &amp;ir = 1024;const int &amp;ir2 = dval; //隐式类型转换，生成临时变量const double &amp;dr = dval + 1.0; 首先要知道，上面的初始化对于非cosnt引用是不合法的，将导致编译错误！ 原因：引用在内部存放的是一个对象的地址，它是该对象的别名。对于不可寻址的值，如文字常量，以及不同类型的对象，编译器为了实现引用，必须生成一个临时对象，将该对象的值置入临时对象中，引用实际上指向该对象（对该引用的操作就是对该临时对象的操作），但用户不能访问它。因此，C++为了不让用户通过引用修改该临时变量，强制要求必须使用const引用。 const引用与临时变量由于上面提到的原因， C++引用类型在面对会产生临时变量的语句时，必须使用const引用来指向！！切记！！ 1234567891011int i = 100;int *&amp;p_i = &amp;i;//错误int *const &amp;p_i = &amp;i; //正确写法，const修饰int *//&amp;代表p_i是一个引用（别名），*代表这个引用（别名）是一个指向int类型的指针，//而后面的&amp;i代表取i的地址，注意，这里会生成一个存储地址的临时变量，因此，指向该临时变量的引用（别名）必须为const，//也就是说，这个指向int的指针本身必须是const的，因为不能修改临时变量的值const int i = 100;int *&amp;p_i = &amp;i;// 错误，有临时变量生成，引用必须是constint *const &amp;p_i = &amp;i; //错误，由于i本身就是cosnt，因此指针必须是一个指向cosnt int的指针const int *const &amp;p_i = i;//正确 const引用与非const引用在内存中的对比内存地址都是一样的，网上有的写不一样，是错误的！ 1234567891011cosnt int t = 9;const int &amp;k = t;cout&lt;&lt;&amp;k&lt;&lt;endl; // 0012FF74cout&lt;&lt;&amp;t&lt;&lt;endl; // 0012FF74int t = 9;int &amp;k = t;const int &amp;m = t;cout&lt;&lt;&amp;k&lt;&lt;endl; // 0012FF74cout&lt;&lt;&amp;m&lt;&lt;endl; // 0012FF74cout&lt;&lt;&amp;t&lt;&lt;endl; // 0012FF74 不允许非const引用指向需要临时对象的对象或值，即，编译器产生临时变量的时候引用必须为const!!!!切记！！12345678910int iv = 100;int * &amp;pir = &amp;iv;//错误，非const引用对需要临时对象的引用int *const &amp;pir = &amp;iv;//okconst int ival = 1024;int *&amp;pi_ref = &amp;ival; //错误，非const引用是非法的const int *&amp;pi_ref = &amp;ival; //错误，需要临时变量，且引用的是指针，而pi_ref是一个非常量指针const int * const &amp;pi_ref = &amp;ival; //正确//补充const int *p = &amp;ival;const int *&amp;pi_ref = p; //正确 const变量的生存期、作用域和链接性临时变量一般会在语句块的末尾自动释放，但是有两个例外： 将临时对象作为初始化因子，例如string s = string(&quot;hello world&quot;); 将一个常量引用变量绑定到这个临时对象上。 作用域在全局作用域中声明的const变量，只能在当前文件中访问，如果要在其他文件中使用，则必须用extern显式的声明const变量全局变量。（在C中，可以不用extern？） 用const修饰函数参数是否应将void Func(int x) 改写为void Func(const int &amp;x)，以便提高效率？完全没有必要，因为内部数据类型的参数不存在构造、析构的过程，而复制也非常快，“值传递”和“引用传递”的效率几乎相当。问题是如此的缠绵，我只好将“const &amp;”修饰输入参数的用法总结一下。对于非内部数据类型的输入参数，应该将“值传递”的方式改为“const 引用传递”，目的是提高效率。例如将void Func(A a) 改为void Func(const A &amp;a)。 对于内部数据类型的输入参数，不要将“值传递”的方式改为“const 引用传递”。否则既达不到提高效率的目的，又降低了函数的可理解性。例如void Func(int x) 不应该改为void Func(const int &amp;x)。 用const修饰函数的返回值 如果给以“指针传递”方式的函数返回值加const 修饰，那么函数返回值（即指针）的内容不能被修改，该返回值只能被赋给加const 修饰的同类型指针。 如果函数返回值采用“值传递方式”，由于函数会把返回值复制到外部临时的存储单元中，加const 修饰没有任何价值。 const 成员函数(const的作用：说明其不会修改数据成员) 1int GetCount(void) const; // const 成员函数]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的virtual关键字]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84virutal%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[虚函数与运行多态多态：多态按字面的意思就是多种形态。当类之间存在层次结构，并且类之间是通过继承关联时，就会用到多态。C++ 多态意味着调用成员函数时，会根据调用函数的对象的类型来执行不同的函数。 先看最简单的情况，也就是最普通形式的继承，且父类和子类的方法都是一般成员方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Car&#123; public: Car()&#123;cout&lt;&lt;"Car consstructor"&lt;&lt;endl;&#125; ~Car()&#123;cout&lt;&lt;"Car destructor"&lt;&lt;endl;&#125; // 若将成员成员函数声明为const，则该函数不允许修改类的数据成员 void start() const&#123;cout&lt;&lt;"car start"&lt;&lt;endl;&#125; void stop() const&#123;cout&lt;&lt;"cat stop"&lt;&lt;endl;&#125;&#125;;//Benz类，单一继承自Carclass Benz : public Car&#123; public: Benz()&#123;cout&lt;&lt;"Benz constructor"&lt;&lt;endl;&#125; ~Benz()&#123;cout&lt;&lt;"Benz destructor"&lt;&lt;endl;&#125; void start() const&#123;cout&lt;&lt;"Benz start"&lt;&lt;endl;&#125; void stop() const&#123;cout&lt;&lt;"Benz stop"&lt;&lt;endl;&#125;&#125;;// Baoma类，单一继承自Carclass Baoma:public Car&#123; public: Baoma()&#123;cout&lt;&lt;"Baoma constructor"&lt;&lt;endl;&#125; ~Baoma()&#123;cout&lt;&lt;"Baoma destructor"&lt;&lt;endl; &#125; void start() const&#123;cout&lt;&lt;"Baoma constructor"&lt;&lt;endl;&#125; void stop() const&#123;cout&lt;&lt;"Baoma destructor"&lt;&lt;endl;&#125; private: int speed;&#125;;//以上三个类均具有start和stop的同名成员函数//调用成员函数start和stopvoid carFunction(Car *car)&#123; car-&gt;start(); car-&gt;stop();&#125;int main(int argc,char *argv[])&#123; Car *benz = new Benz(); cout&lt;&lt;sizeof(Benz)&lt;&lt;endl; carFunction(benz); Car *baoma = new Baoma(); cout&lt;&lt;sizeof(Baoma)&lt;&lt;endl; carFunction(baoma); delete benz; delete baoma; return 0;&#125; 输出结果如下：123456789101112Car consstructorBenz constructor1 //内部没有成员变量,因此只有一个字节的空间car startcat stopCar consstructorBaoma constructor4 //函数是不占用内存的,baoma中有一个int类型.所以sizeof为4car startcat stopCar destructorCar destructor 首先，为什么Benz类内部明明没有任何变量，还具有一个字节的大小？这是因为C++编译器不允许对象为零长度（试想一个长度为0的对象在内存中怎么存放？怎么获取它的地址？）。为了避免这种情况，C++强制给这种类插入一个缺省成员，长度为1。如果有自定义的变量，那么变量将取代这个缺省成员。 其次，Benz和Baoma都是继承自Car类，根据 里氏替换原则 ，父类能够出现的地方，那么子类也一定能出现。依赖抽象而不去依赖具体,在上述的函数调用过程中,我们传进去的是benz和baoma指针.但是在调用函数的时候,它并没有去调用子类的方法,这也就是一般成员函数的局限性,就是在编译的时候,一般性的函数已经被静态的编译进去,所以在调用的时候不能去选择动态调用. 里氏替换原则：派生类（子类）对象可以在程式中代替其基类（超类）对象 加入vitural关键字修饰的函数,将父类函数变为虚函数,看看变化： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980//和上面几乎一样，都是一般的成员方法，只不过加上了virtual关键字#include&lt;iostream&gt;using namespace::std;class Car&#123; public: Car()&#123; cout&lt;&lt;"Car consstructor"&lt;&lt;endl; &#125; ~Car()&#123; cout&lt;&lt;"Car destructor"&lt;&lt;endl; &#125; virtual void start() &#123; cout&lt;&lt;"car start"&lt;&lt;endl; &#125; virtual void stop() &#123; cout&lt;&lt;"cat stop"&lt;&lt;endl; &#125;&#125;;class Benz : public Car&#123; public: Benz()&#123; cout&lt;&lt;"Benz constructor"&lt;&lt;endl; &#125; ~Benz()&#123; cout&lt;&lt;"Benz destructor"&lt;&lt;endl; &#125; //子类继承父类,如果是虚函数,可以写上vitural也可以不写 virtual void start() &#123; cout&lt;&lt;"Benz start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"Benz stop"&lt;&lt;endl; &#125;&#125;;class Baoma:public Car&#123; public: Baoma()&#123; cout&lt;&lt;"Baoma constructor"&lt;&lt;endl; &#125; ~Baoma()&#123; cout&lt;&lt;"Baoma destructor"&lt;&lt;endl; &#125; void start() &#123; cout&lt;&lt;"Baoma start"&lt;&lt;endl; &#125; void stop() &#123; cout&lt;&lt;"Baoma stop"&lt;&lt;endl; &#125; private: int speed;&#125;;void carFunction(Car *car)&#123; car-&gt;start(); car-&gt;stop();&#125;int main(int argc,char *argv[])&#123; Car *benz = new Benz(); cout&lt;&lt;sizeof(Benz)&lt;&lt;endl; carFunction(benz); Car *baoma = new Baoma(); cout&lt;&lt;sizeof(Baoma)&lt;&lt;endl; carFunction(baoma); delete benz; delete baoma; return 0;&#125; 输出结果如下： 12345678910111213Car consstructorBenz constructor8Benz startBenz stopCar consstructorBaoma constructor16Baoma startBaoma stopCar destructorCar destructor 从上面的输出结果中可以看到,加入了虚函数之后,调用不同指针对象指定函数的时候,这个时候都是去自动调用当前对象类中的具体函数形式,而不是像一般函数的调用一样,只是去调用父类的函数.这就是virtural关键字的作用,因为一般函数调用编译的时候是静态编译的时候就已经决定了,加入了virtural的函数,一个类中函数的调用并不是在编译的时候决定下来的,而是在运行时候被确定的,这也就是虚函数. 虚函数就是由于在由于编写代码的时候并不能确定被调用的是基类的函数还是哪个派生类的函数，所以被 为“虚”函数。 虚函数只能借助于指针或者引用来达到多态的效果， 直接声明的类对象无法达到多态目的。 总结： 虚函数的调用取决于指向或者引用的对象的类型，而不是指针或者引用自身的类型。 注意: C++中的虚函数的作用主要是实现了多态的机制。关于多态，简而言之就是用父类型别的指针指向其子类的实例，然后通过父类的指针调用实际子类的成员函数。 对C++ 了解的人都应该知道虚函数（Virtual Function）是通过一张虚函数表（Virtual Table）来实现的。简称为V-Table。在这个表中，主是要一个类的虚函数的地址表，这张表解决了继承、覆盖的问题，保证其容真实反应实际的函数。这样，在有虚函数的类的实例中这个表被分配在了这个实例的内存中，所以，当我们用父类的指针来操作一个子类的时候，这张虚函数表就显得由为重要了，它就像一个地图一样，指明了实际所应该调用的函数 带有虚函数的对象自身确实插入了一些指针信息，而且这个指针信息并不随着虚函数的增加而增大,这也就是为什么上述增加了虚函数后,出现了size变大的现象 虚函数控制下的运行多态有什么用？假如我们在公司的人事管理系统中定义了一个基类 Employee(员工)，里面包含了升职、加薪等虚函数。 由于Manager(管理人员)和Engineer(工程人员)的加薪和晋升流程是不一样的，因此我们需要实现一些继承类并重写这些函数。 有了上面这些以后，到了一年一度每个人都要加薪的时候，我们只需要一个简单的操作就可以完成，如下所示123456void globalRaiseSalary(Employee *emp[], int n)&#123; for (int i = 0; i &lt; n; i++) emp[i]-&gt;raiseSalary(); // 会根据emp具体指向的对象类型，来选择合适的函数行为 // Polymorphic Call: Calls raiseSalary() // according to the actual object, not according to the type of pointer&#125; 虚函数使得我们可以创建一个统一的基类指针，并且调用不同子类的函数而无需知道子类对象究竟是什么 虚函数表与虚函数表指针C++中虚函数这种多态的性质是通过虚函数指针和一张虚函数表来实现的： vtable（虚函数表）：每一个含有虚函数的类都会维护一个虚函数表，里面按照声明顺序记录了虚函数的地址 vptr（虚函数表指针）：一个指向虚函数表的指针，每个对象都会拥有这样的一个指针 先看看下面这个简单的例子：12345678910111213class A&#123;public: virtual void fun();&#125;;class B&#123;public: void fun();&#125;;sizeof(A) &gt; sizeof(B) // true，因为A比B多了一个虚函数指针 下面再来看看刚刚那个加薪的例子，其多态调用的形式如下图： 通常情况下，编译器在下面两处地方添加额外的代码来维护和使用vptr： 在每个构造函数中。此处添加的代码会设置被创建对象的虚函数表指针指向对应类的虚函数表 在每次进行多态函数调用时。 无论合适调用了多态函数，编译器都会首先查找vptr指向的地址（也就是指向对象对应的类的虚函数表），一旦找到后，就会使用该地址内存储的函数（而不是基类的函数）。 虚函数中的默认参数先看下面的代码12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;class Base&#123;public: virtual void fun ( int x = 0 ) &#123; cout &lt;&lt; "Base::fun(), x = " &lt;&lt; x &lt;&lt; endl; &#125;&#125;;class Derived : public Base&#123;public: // 这里的virtual关键字可以省略，因为只要基类里面被声明为虚函数，那么在子类中默认都是虚的 virtual void fun ( int x )// 或者定义为 virtual void fun ( int x = 10) &#123; cout &lt;&lt; "Derived::fun(), x = " &lt;&lt; x &lt;&lt; endl; &#125;&#125;;int main()&#123; Derived d1; Base *bp = &amp;d1; bp-&gt;fun(); return 0;&#125; 上面的代码输出始终为：1Derived::fun(), x = 0 解释： 首先，参数的默认值是不算做函数签名的，因此，即使基类有默认值，子类没有，这两个函数的函数签名仍然被认为是相同的，所以在调用bp-&gt;fun();，仍然调用了子类的fun函数，但是因为没有给出x的值，所以采用了基类函数给出的默认值0. 当基类给出默认值0，子类给出默认值10时，返回结果仍然是默认值0，这是因为，参数的默认值是静态绑定的，而虚函数是动态绑定的，因此， 默认参数的使用需要看指针或者引用本身的类型，而不是指向对象的类型。-小结：根据上面的分析，在虚函数中最好不要使用默认参数，否则很容易引起误会！ 静态函数可以被声明为虚函数吗静态函数不可以声明为虚函数，同时也不能被const和volatile关键字修饰。如下面的声明都是错误的：123virtual static void fun()&#123;&#125;static void fun() const &#123;&#125; // 函数不能被const修饰，但是返回值可以 原因主要有两个方面： static成员函数不属于任何类对象或类实例，所以即使给此函数加上virtual也是没有意义的 虚函数依靠vptr和vtable来处理，vptr是一个指针，在类的构造函数中创建生成，并且智能用this指针来访问它，静态成员函数没有this指针，所以无法访问vptr。 构造函数可以为虚函数吗构造函数不可以声明为虚函数。同时除了inline之外，构造函数不允许使用其他任何关键字，原因如下： 尽管虚函数表vtable是在编译阶段就已经建立的，但指向虚函数表的指针vptr是在运行阶段实例化对象时才产生的。 如果类含有虚函数，编译器会在构造函数中添加代码来创建vptr。 问题来了，如果构造函数是虚的，那么它需要vptr来访问vtable，可这个时候vptr还没产生。 因此，构造函数不可以为虚函数。 我们之所以使用虚函数，是因为需要在信息不全的情况下进行多态运行。而构造函数是用来初始化实例的，实例的类型必须是明确的。 因此，构造函数没有必要被声明为虚函数。 析构函数可以为虚函数吗析构函数可以声明为虚函数。如果我们需要删除一个指向派生类的基类指针时，应该把析构函数声明为虚函数。事实上，只要一个类有可能会被其他类所继承，就应该声明虚析构函数（哪怕该析构函数不执行任何操作）。原因可以见先秒的代码： 1234567891011121314151617181920212223242526272829#include&lt;iostream&gt;using namespace std;class base &#123; public: base() &#123; cout&lt;&lt;"Constructing base \n"; &#125; // virtual ~base() ~base() &#123; cout&lt;&lt;"Destructing base \n"; &#125; &#125;;class derived: public base &#123; public: derived() &#123; cout&lt;&lt;"Constructing derived \n"; &#125; ~derived() &#123; cout&lt;&lt;"Destructing derived \n"; &#125;&#125;;int main(void)&#123; derived *d = new derived(); base *b = d; delete b; return 0;&#125; 以上代码输出：123Constructing baseConstructing derivedDestructing base 可见，继承类的析构函数没有被调用，delete时只根据指针类型调用了基类的析构函数。 正确的操作是，基类和继承类的析构函数都应该被调用，解决方法是将基类的析构函数声明为虚函数。 虚函数可以为私有函数吗虚函数可以被私有化，但有一些细节需要注意12345678910111213141516171819202122#include&lt;iostream&gt;using namespace std;class Derived;class Base &#123;private: virtual void fun() &#123; cout &lt;&lt; "Base Fun"; &#125;friend int main();&#125;;class Derived: public Base &#123;public: void fun() &#123; cout &lt;&lt; "Derived Fun"; &#125;&#125;;int main()&#123; Base *ptr = new Derived; ptr-&gt;fun(); return 0;&#125; 输出结果为：1Derived fun() 基类指针指向继承类对象，则调用继承类对象的函数 int main()必须声明为Base类的友元，否则编译失败。编译器报错：ptr无法访问私有函数。当然，把基类声明为public，继承类为private，该问题就不存在了。 虚函数可以被内联吗通常类成员函数都会被编译器考虑是否进行内联。但通过基类指针或者引用调用的虚函数必定不能被内联。当然，实体对象调用虚函数或者静态调用时可以被内联，虚析构函数的静态调用也一定会被内联展开。 纯虚函数与抽象类纯虚函数：在基类中只声明不定义的虚函数，同时要求任何派生类都要实现该虚函数。在基类中实现纯虚函数的方法是在函数原型后加“=0”。 抽象类：含有纯虚函数的类为抽象类 纯虚函数的特点以及用途总结如下： 如果不在继承类中实现该函数，则继承类仍为抽象类； 派生类仅仅只是继承纯虚函数的接口，因此使用纯虚函数可以规范接口形式 抽象类无法实例化对象 抽象类可以有构造函数 析构函数被声明为纯虚函数是一种特例，允许其有具体实现。（有些时候，想要使一个类称为抽象类，但刚好有没有任何合适的纯虚函数，最简单的方法就是声明一个纯虚的析构函数）]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的static关键字]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84static%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[首先：在类中声明的静态变量，一定要进行初始化，并且，如果不const static类型的静态变量，则需要在类外初始化，同时初始化的时候一定要带上类名和作用域解析符。 123456789101112131415161718192021class sum&#123; public: static int i ; static int s; sum()&#123;i++; s+=i;&#125;; ~sum()&#123;&#125;; static void set()&#123; //静态函数只能使用静态变量 i = 0; s = 0; &#125;; &#125;;int sum::i =0; // 非const static类型，要在类外初始化int sum::s = 0; // 且必须带上类名sum和作用域解析符class Solution &#123;public: int Sum_Solution(int n) &#123; sum::set(); // 直接用类名调用函数，则该函数必须是静态的 sum a[n]; return sum::s; &#125;&#125;;]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双流手语识别系统：（一）框架设计]]></title>
    <url>%2Fz_post%2F%E9%A1%B9%E7%9B%AE-%E5%8F%8C%E6%B5%81%E6%89%8B%E8%AF%AD%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E2%80%94-%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"></content>
      <categories>
        <category>项目</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Vector数据的内存分配问题]]></title>
    <url>%2Fz_post%2FCpp-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95-Vector%E6%95%B0%E6%8D%AE%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[有问题 待修改首先，要知道，程序所拥有的栈资源是及其有限的（Linux下用ulimit -a或者ulimit -s可查当前栈的大小。 因此在写程序时，绝对不能肆意使用占空间，否则就会报出Segmentation fault。 在用vector实现三维数据时，以下的代码就会产生段错误 123456789101112131415161718#include &lt;vector&gt;using namespace std;int main() &#123; int HEIGHT=2,WIDTH=3,DEPTH=5; // construct array3D[HEIGHT][WIDTH][DEPTH] vector&lt;vector&lt;vector&lt;double&gt; &gt; &gt; array3D; array3D.resize(HEIGHT); for (int i = 0; i &lt; HEIGHT; ++i) &#123; array3D[i].resize(WIDTH); for (int j = 0; j &lt; WIDTH; ++j) array3D[i][j].resize(DEPTH); &#125; return 0;&#125; 以上出现段错误的原因在于申请了过多的vecotr，导致占空间不够用，从而出现段错误，现在来看以下vector在内存中具体是如何存储的，首先看一下以下三种方式的声明： 1234std::vector&lt;T&gt; vec;std::vector&lt;T&gt;* Vec = new std::vector&lt;T&gt;();std::vector&lt;T*&gt; vec; 假设T是一个类型或者一个定义好的类，则以上三种情况的内存分配情况如下： 对于std::vector&lt;T&gt; vec；vec在栈上（stack），而其中的元素T保存在堆上（heap）； 对于std::vector&lt;T&gt;* Vec = new std::vector&lt;T&gt;()；vec和其中的元素T都保存在堆上； 对于std::vector&lt;T*&gt; vec；vec在栈上（stack），而其中的元素T保存在堆上（heap）；和第一种情况类似。 存储在栈上的元素，往往无需手动管理内存空间，通常会自动释放，而在堆上的空间，则需要手动管理。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>踩坑记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gcc/g++的编译链接原理及注意事项]]></title>
    <url>%2Fz_post%2FCpp-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95-%E5%85%B3%E4%BA%8Egcc%E7%9A%84%E7%BC%96%E8%AF%91%E5%92%8C%E9%93%BE%E6%8E%A5%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[LINUX下默认搜索头文件及库文件的路径编译连接多个文件编译在linux下编译，下面有三个文件，分别是1.cpp 和 2.cpp 和myhead.h 文件。 1.cpp 123456789#include &lt;iostream&gt;#include "myhead.h"using namespace std;int main()&#123; print(); cout&lt;&lt;"yes !"&lt;&lt;endl; return 0;&#125; 2.cpp 123456789#include &lt;iostream&gt;#include "myhead.h"using namespace std;void print()&#123; std::cout&lt;&lt;" print "&lt;&lt;std::endl; cout&lt;&lt;&#125; myhead.h 12345#ifndef __myhead_h#define __myhead_hvoid print();#endif 假如他们都在一个目录下面，那么编译流程： 12g++ -c 2.cpp #将2.cpp 编译成2.o 文件g++ 1.cpp -o a.out 2.o #多个文件一起链接 or123g++ -c 2.cppg++ -c 1.cppg++ 1.o 2.o -o test]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>踩坑记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[声明模板类对象，报错“undefined reference to”]]></title>
    <url>%2Fz_post%2FCpp-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95-%E6%A8%A1%E6%9D%BF%E7%B1%BB%E6%8A%A5%E9%94%99undefined_reference_to%2F</url>
    <content type="text"><![CDATA[坑源实现ZeroTensor项目中的Shape3D类时，为了可以处理多种类型的数据（int，double等），需要使用模板类 出现问题和解决办法在实现的时候将模板类的声明和定义写在的不同位置，编译时报错：1undefined reference to XXXX 这是因为模板类并不是普通的类和成员函数！它们只是说明了如何生成类和成员函数定义。因此，不能将模板成员函数放在独立的实现文件中。 由于模板不是函数，因此它们不能单独编译。模板必须与特定的模板实例化请求一起使用。为此，最简单的方法是将所有模板信息放在一个头文件中，并在要使用这些模板的文件中包含该头文件！ 还有另一种解决办法就是在stack.h文件的末尾加上#include stack.cpp，并在stack.cpp文件中去掉对应的包含语句。]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>踩坑记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《CUDA By Example》]]></title>
    <url>%2Fz_post%2FCUDA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CUDAByExample%2F</url>
    <content type="text"><![CDATA[WHY CUDA？ WHY NOW？]]></content>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第十五章]]></title>
    <url>%2Fz_post%2FCpp-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CppPrimerPlusChapter15%2F</url>
    <content type="text"><![CDATA[第十五章 友元、异常和其他15.1 友元类并非只能拥有友元函数，也可以将类作为友元。在这种情况下，友元类的所有方法都可以访问原始类的私有成员和保护成员。哪些函数、成员函数或类为友元是由类定义的，而不能从外部强加友情。因此 ，尽管友元被授予从外部访问类的私有部分的权限，但它们并不与面向对象的编程思想相悖。 15.1.1 友元类关于需要使用友元类的情况，可以想象电视机类和遥控器类之间的关系，首先，它们不是is-a，其次，也不是has-a，但是它们确实存在某个关系，这就是——友元。下面的语句使Remote成为友元类，友元声明可以位于公有、私有或保护部分，其所在的位置无关紧要。由于Remote类中访问了Tv类的成员，因此，编译器必须了解Tv类以后，才能处理Remote类，最简单的方法是首先定义Tv类，另一种方法是使用前向声明（forward delaration），这将稍后介绍。12345class Tv&#123; ... friend class Remote; ...&#125;; 以上代码，在电视机类里面声明遥控器类为友元类以后，遥控器类就可以访问电视机类的私有成员变量，而无需让电视机类修改自身的访问权限，就是说电视机对外界的访问权限是不变的，并没有破坏类的封装行。 15.1.2 友元成员函数可以选择仅让特定的类成员变成另一个类的友元，而不必让整个类成员友元，但是这样做稍微有点麻烦，必须小心排列各种声明和定义的顺序。 123class TV&#123; friend void Remote::set_chanel(TV &amp;t, int c);&#125; 要使编译器能够处理上面的代码，它必须知道Remote的定义，否则，它无法知道Remote是类还是别的什么，也无法确定set_chanel是这个类的方法。而前面又说了，Tv应定义在Remote定义之前，这就导致了循环依赖问题。避开这种问题的方法是使用前向声明（forward declaration）。为此，需要在Remote定义的前面插入下面的语句：1class Tv; 这样，新的排列顺序如下：1234567class Tv;class Remote &#123; ...&#125;;class Tv&#123; ...&#125;; 注意，Tv类与Remote类的定义不可以调换，因为编译器在Tv类的声明者是看到Remote的一个方法被声明为Tv类的友元之前，应该先看到Remote类的声明和set_chanel()方法的声明。 15.1.3 其他友元关系可以通过让类彼此成为对方的友元来实现互相影响对象的功能。即除了Remote是Tv的友元外，Tv还是Remote的友元。需要注意一点的是，对于使用Remote对象的Tv方法，其原型可在Remote类声明之前声明，但必须在Remote类声明之后定义，以便编译器有足够的信息来编译该方法。 15.1.4 共同的友元需要使用友元的另一种情况是，函数需要访问两个类的私有数据。因此，可以将函数左右两个类的友元 15.2 嵌套类（内部类）在C++中，可以将类声明放在另一个类中，在另一个类中声明的类被成为嵌套类（nested class），它通过提供新的类型类作用域来避免名称混乱。包含类的成员函数可以创建和使用被嵌套类的对象，而仅当声明位于公有部分，才能在包含类的外面使用嵌套类，而且必须使用作用域解析符。 对类进行嵌套与包含并不同。包含意味着将类对象作为另一个类的成员，而对类进行嵌套不会创建类成员，而是 定义了一种类型 ，可以在包含类的其他方法内声明该类型的变量，该类型仅在包含嵌套类声明的类中有效。 15.2.1 嵌套类和访问权限 作用域 &emsp;&emsp;如果嵌套类是在另一个类的私有部分声明的，则只有这个类知道它。也就是说，只能通过这个类的成员来使用嵌套类，就像私有变量一样。而这个类的派生类，和外部的程序都无法访问到该嵌套类。 &emsp;&emsp;如果嵌套类是在另一个类的保护部分声明的，则它对于后者及其派生类都是可见的，但是对于外部师姐是不可见的。 &emsp;&emsp;如果嵌套类是在另一个类的公有部分声明的，则允许后者、后者的派生类以及外部世界访问它。并且，由于嵌套类的作用域为包含它的类，因此在外部世界使用它时，必须使用类限定符。 &emsp;&emsp;嵌套结构和枚举的作用域与嵌套类相同。下表总结了嵌套类、结构和枚举的作用域特征 声明位置 包含它的类是否可以使用它 从包含它的类派生的类是否可以使用它 在外部是否可以使用 私有部分 是 否 否 保护部分 是 是 否 公有部分 是 是 是，通过类限定符使用 访问控制 &emsp;&emsp; 类可见后，起决定作用的将是访问控制。对嵌套类访问权的控制规则与对常规类相同。例如，在Queue类声明中声明了Node嵌套类，这并没有赋予Queue类任何对Node类的访问特权，也没有赋予Node类任何对Queue类的访问特权。因此，Queue类对象只能显式的访问Node对象的公有成员。 15.2.2 模板中的嵌套模板类可以正常使用嵌套类，不会带来额外的问题。 15.3 异常程序有时会遇到运行阶段错误，导致程序无法正常的走下去。如，试图打开一个不可用的文件、请求过多的内存、遭遇不能接受的值等等。 C++的异常处理机制是一个相对较新的功能，有些老式编译器可能没有实现，有些编译器可能默认关闭这种特性，需要在选项中开启。比如“零除” 这种异常，很多新编译器通过生成一个表示无穷大的特殊浮点值来处理，cout将其显示为Inf、inf、INF等，有些编译器可能会直接崩溃。 15.3.1 调用abort()abort()函数的原型位于头文件cstdlib（stdlib.h）中，其典型实现是向标准错误流发送消息abnormal program termination（程序异常终止），然后终止程序。它还返回一个随实现而异的值，告诉操作系统（或者父进程），处理失败。abort()是否刷新文件缓冲区（用于存储读写到文件中的数据的内存区域）取决于实现。如果愿意，也可以使用exit()，该函数刷新文件缓冲区，但不显示消息。 15.3.2 返回错误码一种比异常终止更灵活的方法是，使用函数的返回值来指出问题。如果某些函数的任何数值返回都是有效的，那么可以增加一个指针参数或引用参数，来将返回值返回，同时将函数的返回值改成bool类型，来指出是否返回成功。 另一种方法使用一个全局变量。可能问题的函数可以在出现问题时将该全局变量设值为特定的值，而调用程序可以检查该变量。 15.3.3 异常机制C++异常是对程序运行过程中发生的异常情况的一种响应。异常提供了将控制权从程序的一个部分传递到另一个部分的途径。对异常的处理有三个组成部分： 引发异常 使用处理程序捕获异常 使用try块处理异常 throw语句实际上是跳转，即命令程序跳到另一条语句。throw关键字表示引发异常，紧随其后的值（例如字符串或对象）指出了异常的特征。 程序使用异常处理程序（exception handler）来捕获异常，异常处理程序位于要处理问题的程序中，catch关键字表示捕获异常。处理程序以关键字catch开头，随后是位于括号中的类型声明，他指出了异常处理程序要响应的异常类型。 catch关键字和异常类型用作标签，指出当异常被引发时，程序应跳到这个为止执行。异常处理程序也被称为catch块。 try块标识可能引起特定异常的代码块，他后面跟一个或多个catch块。try块是由关键字try只是的，关键字try的后面是一个由花括号括起的代码块，表明需要注意这些代码引发的异常。 在默认情况下，如果函数引发了异常，而没有try块或没有匹配的处理程序时，程序将调用abort()函数。（默认行为可修改）。 15.3.4 将对象用作异常类型通常，引发异常的函数将传递一个对象。这样做的重要优点之一是，可以使用不同的异常类型来区分不同的函数在不同情况下引发的异常。另外，对象可以携带信息，程序员可以根据这些信息来确定引发异常的原因。 根据不同的对象类型，可以跟不同的catch块进行匹配，类型不匹配的catch块将跳过不执行。 15.3.5 异常规范和C++11C++98新增了异常规范（exception specification）的功能，但是在C++11中却被摒弃了。 新增关键字noexcept指出函数不会引发异。 15.3.6 栈解退C++中处理函数的调用和返回时，会让程序将调用函数的指令的地址（返回地址）放到栈中。当被调用的函数执行完毕后，程序将使用该地址来确定从哪里开始继续执行。另外，函数调用将参数放到栈中。在栈中，这些函数参数被视为自动变量。如果被调用的函数创建了新的自动变量，则这些变量也将被添加到栈中。如果被调用的函数调用了另一个函数，则后者的信息将被添加到栈中，以此类推。 现在假设函数由于出现异常（而不是由于返回）而终止，则程序也将释放栈中的内存，但不会在释放栈的第一个返回地址后停止，而是继续释放栈，直到找到一个位于try块中的返回地址。随后，控制权将转到块尾的异常处理程序，而不是函数调用后面的第一条语句。——这个过程被称为栈解退。 栈解退的意义在于：对于普通的函数返回来说，仅仅会调用该函数放在栈中的对象的析构函数，而throw语句则处理try块和throw之间整个函数调用序列放在栈中的对象。所以，如果没有栈解退这种特性，则引发异常后，对于中间函数调用放在栈中的自动类对象，其析构函数将不会被调用。 也就是说：程序进行栈解退以回到能够捕获异常的地方时，将释放栈中的自动存储型变量。如果变量是类对象，将为该对象调用析构函数。 15.3.7 其他异常特性虽然throw-catch机制类似于函数返回机制，但还是有些不同之处： 函数fun()中的返回语句将控制权返回到调用fun()的函数，但throw语句将控制权向上返回到第一个包含能够捕获相应异常的try-catch组合。 引发异常时编译器总是创建一个临时拷贝，即使异常规范和catch块中指定的是引用。 1234567891011121314151617181920class problem&#123;...&#125;;...void super() throw(problem)&#123; ... if( oh_no )&#123; problem oops; throw oops; &#125;&#125;...try&#123; super();&#125;catch(problem &amp;p)&#123; //这里p虽然声明为引用，但是p指向的是oops的副本而不是oops本身，这是件好事，因为函数`super()`执行完毕后，oops将不复存在。//既然如此，为何还要特意声明为引用？因为引用还有另一个重要特征：基类引用可以执行派生类对象。//这有一个很大的用法在于，假设有一个异常类层次结构，并要分别处理不同的异常类型，则使用基类引用将能够捕获任何异常对象；//而使用派生类对象只能捕获它所属类及从这个类派生而来的类的对象。引发的异常对象将被第一个与之匹配的catch块捕获。//这意味着catch块的排列顺序应该与派生顺序相反。也就是要将捕获派生类的catch放前面，捕获基类的catch放后面 //statements&#125; 15.3.8 exception类较新的C++编译器将异常合并到语言中，并在exception头文件（以前为exception.h或except.h定义了exception类，C++可以把它用作其他异常类的基类。 C++库定义了很多基于exceptin的异常类型 stdexcept异常类 &emsp;&emsp;头文件stdexcept定义了其他几个异常类，首先，该文件定义了logic_error和runtime_error类，它们都是以公有方式从exception派生而来的。这两个新类被用作两个派生类系列的基类。 &emsp;&emsp;异常类系列logic_error描述了典型的逻辑错误： domain_error; invalid_argument; length_error; out_of_bounds. &emsp;&emsp;runtime_error异常类系列描述了可能在运行期间发生但难以预计和防范的错误： range_error; overflow_error; underflow_error. &emsp;&emsp;一般，logic_error系列异常表明存在可以通过编程修复的问题，而runtime_error系列异常表明存在无法避免的问题。 &emsp;&emsp;如果上述库类不能满足需求，则应该从logic或runtime异常类中进行派生（而不是从exception），以确保派生出来的异常类可以归入同一个继承层次结构中。 bad_alloc异常和new &emsp;&emsp;对于使用new导致的内存分配问题，C++的最新处理方式是让new引发bad_alloc异常。头文件new包含bad_alloc类的声明，他是从exception类公有派生出来的。但在以前，当无法分配请求的内存量时，new返回一个空指针。 空指针和new &emsp;&emsp;老代码的逻辑是根据new返回的指针是否为空来判断是否失败的，为兼容这种情况，C++标准提供了一种在失败时返回空指针的new，如下所示： 1234567Big* pb;pb = new(std::nothrow) Big[10000];if(pb==0)&#123; cout&lt;&lt;"error"; exit(EXIT_FAILURE);1&#125; 15.3.9 异常、类和继承异常、类和继承以三种方式相互关联： 像C++标准库一样，从一个异常类派生出另一个 在类定义中嵌套异常类声明，从而将异常类组合到类中去 上面的嵌套声明通过继承传给子类 15.3.10 异常何时会迷失方向异常被引发后，在两种情况下会导致问题： 如果异常是在带异常规范的函数中引发的（C++11虽然摈弃了异常规范，但仍有人使用），则必须与规范列表中的某种异常匹配，否则称为意外异常（unexpected exception）。在默认情况下，程序会异常终止。 如果异常不是在函数中引发的（或者函数没有异常规范），则必须捕获该异常，如果没被捕获，则被称为未捕获异常（uncaught exception）。在默认情况下，程序会异常终止。 可以对以上默认情况进行修改： 未捕获异常：未捕获异常不会导致程序理科异常终止。相反，程序将首先调用函数terminate()。在默认情况下，terminate()调用abort()函数。可以使用set_terminate()函数指定terminate()应调用的函数来修改其默认行为：1234567void my_quit()&#123; cout&lt;&lt;"quit"; exit(5); // 退出状态值设为5&#125;...set_terminate(my_quit); 意外异常：通过给函数指定异常规范，可以让函数的用户知道要捕获哪些异常，如下所示：1234567double Argn(double , double ) throw (out_of_bounds);try&#123; x = Argn(a,b);&#125;catch(out_of_bounds &amp; ex)&#123; ...&#125; C++11摒弃它的原因之一是：异常规范机制处理起来比较麻烦。p640 在意外异常发生时，将调用unexpected()函数，这个函数将调用terminate()，后者在默认情况下调用abort()。 C++提供了一个set_unexpected ()函数，但限制更严格。p640 15.3.11 有关异常的注意事项从前面关于如何使用异常的讨论可知，应在设计程序时就加入异常处理功能，而不是以后再添加。 但是这样做会增加代码量，同时异常和动态内存分配并非总能协同工作。 一句话：异常处理很复杂 15.4 RTTIRTTI：运行阶段类型识别（RunTime Type Identification） 这是一项比较新的特性，一些旧的C++编译器不支持，还有一些编译器提供了开关RTTI的设值。 15.4.1 RTTI的用途RTTI旨在为程序在运行阶段确定对象的类型提供一种标准方式。 15.4.2 RTTI的工作原理C++有三个支持RTTI的元素： 如果可能的话，dynamic_cast运算符将使用一个只想基类的指针来生成一个只想派生类的指针；否则，该运算符返回0——空指针 typeid运算符返回一个指出对象的类型的值 type_info结构存储了有关特定类型的信息 RTTI只适用于包含虚函数的类： 只能将RTTI用于包含虚函数的类层次结构，原因在于只有对于这种类层次结构，才应该将派生类对象的地址赋给基类指针。 dynamic_cast运算符 &emsp;&emsp; 该运算符是最常用的RTTI组件， 它不能回答“指针指向的是哪类对象”这样的问题， 但能够回答“是否可以安全地将对象的地址赋给特定类型的指针”这样的问题。 &emsp;&emsp; 与知道“是哪类对象”相比，知道“类型转换是否安全”更通用，也更有用。主要是因为，通常项知道类型的原因在于：知道类型后，就可以知道调用特定的方法是否安全。 而要调用方法，类型并不一定要完全匹配，而可以是定义了方法的虚拟版本的基类类型。 &emsp;&emsp; 用法：ym1Superb* pm = dynamic_cast&lt;Superb *&gt;(pg); &emsp;&emsp; 通常，如果指向的对象(*pt)的类型为Type或从Type直接间接派生而来的类型，则下面的表达式将指针pt转换为Type类型的指针，并作为结果赋给ps，否则ps结果为0，即空指针：1ps = dynamic_cast&lt;Type *&gt;(pt) &emsp;&emsp; 也可以将dynamic_cast用于引用，其用法稍微有点不同：没有与空指针对应的引用值，因此无法使用特殊的引用值来指针失败。当请求不正确时，dynamic_cast将引发类型为bad_cast的异常，这种异常是从exception类派生而来的，在头文件typeinfo中定义，可以像下面这样使用：1234567#include &lt;typeinfo&gt;...try&#123; Superb &amp; rs = dynamic_cast&lt;Superb&amp;&gt;(rg);&#125;catch(bad_cast&amp;)&#123; ...&#125; typeid运算符和type_info类 &emsp;&emsp;typeid运算符使得能够确定两个对象是否为同种类型。它与sizeof有些相像，可以接受两种参数： 类名 结果为对象的表达式 &emsp;&emsp;typeid运算符返回一个对type_info对象的引用，其中，type_info是头文件typeinfo中定义的一个类。type_info类重载了==和!=运算符，可以进行类型间的比较。下面的代码判断pg指向的是否是一个Magnificent对象：1typeid(Magnificent) == typeid(* pg); //只会判断指针的类型，当基类指针指向子类时，得到的也是基类的类型 &emsp;&emsp;如果pg是一个空指针，程序将引发bad_typeid异常。该异常类型是从exception类派生而来的，是在头文件typeinfo中声明的。 误用RTTI的例子 如果在扩展的if else语句系列使用了typeid，则应高了是否应该是否虚函数和dynamic_cast。 15.5 类型转换运算符C语言中的类型转换运算符太过松散，因此，在C++中，提供了更严格的限制允许的类型转换，并添加4个类型转换运算符，使转换过程更规范： dynamic_cast const_cast static_cast reinterpret_cast const_cast 运算符用于执行只有一种用途的类型转换，即改变值为const或volatile，其语法与dynamic_cast运算符相同。1const_cast &lt;type-name&gt; (expression) 如果类型的其他方面也被修改，则上述类型转换将出错。也就是说，除了const或volatile特征可以不同外，type-name和expression的类型必须相同。 提供该运算符的原因是，有时候可能需要这样一个值，它在大多数时候是常量，而有时有事可以修改的。此时就可以声明为const，并在需要的时候使用const_cast。 static_cast运算符的语法与其他类型转换运算符相同：1static_cast &lt;type-name&gt; (expression) 仅当type-name可被隐式转换成expression所属的类型或expression可被隐式转换为type-name所属的类型时，上述转换才是合法的，否则将出错。 reinterpret_cast运算符用于天生危险的类型转换。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[轻量级深度学习框架ZeroTensor：（一）框架设计]]></title>
    <url>%2Fz_post%2F%E9%A1%B9%E7%9B%AE-ZeroTensor-%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"></content>
      <categories>
        <category>项目</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[FocalLoss]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-FocalLoss%2F</url>
    <content type="text"><![CDATA[ICCV 2017的best student paper，应该好好读一哈（嘿嘿 本文作者：Tsung-Yi Lin，Priya Goyal ，Ross Girshick，Kaiming He，Piotr Dollár 摘要首先，Lin等人回顾了一下目前目标检测的发展概况，先进的目标检测算法目前大概分成两种，一种是one-stage的，一种是two-stage的。one-stage的代表作YOLO以一种简单统一的网络成功实现了实时检测的目的，但是它的准确率并不是best。相反的，two-stage的代表作RCNN系列则是在准确率方面完胜其他模型，但是它的检测速度真的是慢的有的可怜（相比于YOLO）。 于是，Lin他们就开始研究造成这种现象的原因，接着他们就发现原来是在训练的时候，后景数据相比于前景数据较少的缘故。为了解决这个问题，Lin等人对标准的交叉熵损失函数进行修改，降低那些已经分类很好的样例对loss的影响比重，称之为Focal Loss，也就是会特别关注某一些loss的意思。 最后，Lin等人实现了一个使用Focal Loss的简单的检测系统，最终在速度上几乎赶上了YOLO，并且在准确性了超过了现有的所有检测算法。源码可以在facebook的Detectron上取得：https://github.com/facebookresearch/Detectron . 介绍首先，作者介绍了以下two-stage方法的简单流程以及相关的论文，然后又介绍了以下YOLO和SSD等one-stage方法的概况，然后，作者就指出这one-stage方法精确度低的主要原因是源于训练集数据分布的不平衡导致的。由此，作者就引出了自己的Focal Loss损失函数，指出Focal Loss函数在面对具有较高confidence的样例时，其影响因子会接近于0,直观上来说，就说Focal Loss更关注那些hard examples。另外，作者还提出，Focal Loss的形式不是唯一的，很多其他的实现方法也能达到相似的结果。（其实我觉得这说明损失函数这一块还有很多工作可以往下研究） 为了证明Focal Loss的有效性，作者实现了一个one-stage检测模型，命名为RetinaNet（Retina是视网膜的意思），基于ResNet-101-FPN实现，还用到了feature pramid和anchor boxes等思想。 相关工作传统检测系统主要是基于sliding-window paradigm的一类方法：HOG， DPMs等等。虽然滑动窗口类的方法在目标检测领域处于一线地位，但是随着deep learning的出现和研究，滑动窗口方法渐渐失去光芒。 Two-stage Detectorstwo-stage方法的先驱是Selective Search work，它会首先提取出一个稀疏的候选框集合（稀疏是指只有很少一部分包含物体），然后对这些候选框进行分类，看是否包含物体，或包含哪种物体。 之后，RCNN的诞生标志着深度学习技术成功引入目标检测领域，利用cnn网络对特征的高度抽象和提取，rcnn在物体检测的准确率上大幅度提高，后期的RCNN系列又不断的提出新的方法来提升准确率和速度，到Faster RCNN时，提出了RPN网络，将候选框选取阶段和分类阶段都放在了统一个网络，使之可以进行端到端训练。后续还有更多的关于这一系列的工作继续被人们研究着。 One-stage DetectorsOverFeat算是首个现代的基于深度学习的one-stage检测方法，而最近的SSD和YOLO更是激起了人名对one-stage方法的研究热情，但是one-stage方法最令人诟病的地方就在于它们较低的准确率。 为此，本文的工作就是想要知道是否one-stage检测算法可以在精确度上匹敌two-stage检测算法，同时还要保持一定的检测速度。 于是，作者提出了Focal Loss，一种新的损失函数，利用这个损失函数，可以在保持现在模型大框架不变的基础上，达到最好的检测水平！ 样本类别不均衡 Class Imbalance不管是传统的one-stage检测方法如boosted detectors， DMPs，还是最近的方法SSD，都会在训练阶段面临 $10^4\sim 10^5$ 个候选区域，这其中会包含大量的背景区域，也就是负样本，这种不平衡会造成两个问题： 在训练时，在大多数位置都是负样本，这样只会贡献更多无用的信号 大量的负样本会导致模型在一定程度上的退化 对于此问题，常用的解决方案是在训练阶段设计更复杂的样本抽取策略，但是这样速度就会受影响。而本文提出的Focal Loss，不仅解决了样本不均的问题，而且不需要增加额外的抽取策略，可以更快训练 Robust Estimation有很多工作乐于设计健壮的损失函数，具体可以看看原文的参考文献，这里就不说了（主要因为没有什么好讨论的地方，作者也只是提了一下） Focal Loss为了便于理解，从交叉熵（CE）的二分类问题出发： CE(p,y) = \begin{cases} -log(p)& \text {if y=1} \\ -log(1-p) & \text{otherwise}\end{cases}当二分类问题中的样本分布不均时，数量多的样本的损失值对最终函数的影响会淹没数量少的样本产生的影响。多分类问题也是如此。 为了便于表示，对上面的公式进行改写： $CE(p,y) = CE(p_t) = -log(p_t)$，于是有： p_t = \begin{cases} p & \text{if y = 1} \\ 1-p & \text{otherwise} \end{cases}Balanced Cross Entropy一个常用的解决办法就是引入一个权重因子 $\alpha \in [0,1]$，然后分别令 $\alpha$ 和 $1 - \alpha$作为两个类别的权重，$\alpha$ 的取值可以是根据类别出现的频率决定，也可以作为超参数，利用交叉验证来选取较好的值。我们使用这种方法作为baseline来与Focal loss进行比较： CE(p_t) = -\alpha log(p_t)Focal Loss Definition本文的实验结果表明，类别分布不均会对交叉熵损失函数带来很大的影响。那些很容易被分类的负样本（背景等）贡献了损失函数及其梯度中的大部分影响力。尽管baseline方法的 $\alpha$ 因子可以平衡正负样本之间的比例，但它仍然不能把握好简单样本和困难样本的比例（应该困难样本多一些，简单样本少一些，这样有利于模型的健壮性）。于是，作者就提出了Focal Loss，主要引入了一个“调制因子” $(1-p_t)^\gamma$ ，其中 $\gamma \ge 0$ ，具体的形式化表示如下： FL(p_t) = -(1-p_t)^\gamma log(p_t)直观上来讲，这个“调制因子”可以降低easy example对loss的contribution。同时，还应注意到，Focal Loss的形式不是唯一固定的，作者还在使用了其他不同形式的因子，比如结合了 $\alpha$ 因子： FL(p_t) = -\alpha_t(1-p_t)^\gamma log(p_t)后文的大部分实验都使用的是上面这个形式的Focal Loss。 Class Imbalance and Model Initialization二值分类模型在初始的时候，对两个类别的预测概率是均等的，在这种初始化条件下，如果某一个类别出现的次数过多，就会对损失函数产生较大的影响。为了解决这个问题，作者特意提出了“先入为主”的概念，也就是使得模型在开始的时候，对稀有类别（如前景类别）的预测概率的初始值设置的低一些，如0.01 。 经过实验表明，这样的方法可以提升模型训练的稳定性。 Class Imbalance and Two-stage DetectorsTwo-stage Detector 并没有使用类似 $\alpha$ 因此的方法来解决样本不均的问题。相反的，它们通过两个机制来降低这个问题带来的影响：（1）two-stage模式和（2）biased minibatch取样。首先，two-stage模式会在第一阶段就将近乎无限物体位置可能性降低到一到两千个，更重要的是，这一到两千个可能位置并不是随机选取的，它们移除了大量的易分类负样本（背景框）。第二，这些方法还设计了biased minibatch的取样策略，比如，保证正样本和负样本的比例为1：3进行训练（这其实相当于起到了 $\alpha$ 因子的作用。 RetinaNet DetectorRetinaNet是一个单一的、统一的网络，它由一个backbone网络和两个task-specific子网络组成。backbone网络是现成的，主要负责计算卷积特征图谱。第一个子网络负责物体分类任务，第二个子网络负责bounding box回归任务，它们都是在backbone网络输出的卷积图谱上进行计算的。 Feature Pyramid Network Backbone： 采用了FPN作为backbone网络。 Anchors: 和FPN一样，对P3到P7使用了不同大小的anchors Classification Subnet： 该子网络是一个较小的FCN，连接在FPN的每一层。 值得注意的一点是，该子网络并不与Box Regression Subnet共享参数，二者是互相独立的。 Box Regresion Subnet： 与分类子网络并行，该子网络也是一个FCN网络，连接在FPN的每一层上。目标是让anchor通过位移回归到gt box附近。 Inference and TrainingInference： RetinaNet是有基于FPN和backbone和两个基于FCN的子网络组成的一个统一的单一网络，因此，在inference阶段，只需要简单的通过前向传播经过整个网络即可。为了提高速度，本文在每个FPN层级上，只会处理最多1000个box prediction。 Focal Loss： 使用了上文提到的Focal Loss。取 $\gamma=2$ 。在训练阶段，本文强调将focal loss应用到所有100k个anchors上，主要目的是为了与RPN和SSD等模型作对比。 从实验结果上看，当 $\gamma$ 的值取得较大时，$\alpha$ 的值就应该取消一些（for$\gamma=2$ , $\alpha = 0.25$ works best)。 Initialization： 本文分别实现了ResNet-50-FPN和ResNet-101-FPN。 对其中初始值可参见原文。 Optimization： 使用了SGD优化方法，在8个GPU上训练，每个minibatch有16张图片（一个GPU包含2张图片）。 损失函数为focal loss和标准smooth L1损失函数之和。 实验在COCO数据集上进行了实验 Training Dense Detection对于所有实验均使用深度为50和101的ResNets配合FPN来组成backbone。同时对所有的消融实验，图片的分辨率都为600。 Network Initialiation： Balanced Cross Entropy： Focal Loss：]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YOLOv3]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-YOLOv3%2F</url>
    <content type="text"><![CDATA[摘要作者对YOLOv2进行了一些改进，使之在保持实时检测的同时，准确率又有所提升了。 介绍作者说他这一年（18年）基本没干啥，就是打打电话，玩玩推特，偶尔还帮别人干点活。。 然后因为只对YOLO做了一些改进，但是并没什么特别的地方，因此就写了这一篇技术报告,而没有选择发表成论文形式。 The Deal作者说了，他们大部分的工作都是从别人那里吸取好的点子，同时训练了一个新的分类器网络（比别人的好，恩。。） Bounding Box Prediction和YOLO9000一样，在预测bounding box时使用了dimension clusters和anchor boxes。 YOLOv3在预测每个bouding box的objectness score时，使用的是logistic regression。 与faster rcnn不同的是，我们的系统只会给每个gt object指派一个bounding box。如果没有指派的话，就说明没有对象的box坐标，只有objectness。 Class Prediction每个box使用了多标签分类，我们不选择softmax是因为发现它很难取得好的效果，因此，改用一个单独的logistic classifiers。在训练阶段，使用binary cross-entropy loss来进行类别预测。 Predictions Across ScalesYOLOv3在三种不同的scales下进行预测。 Feature Extractor作者使用了一个新的网络模型来提取特征，主要是在Darknet-19中引入了residual network stuff，最终模型的卷积层数达到53层，也就是Darknet-53。 Training仍然使用不带hard negative mining的图片训练。同时使用了multi-scale training，data augmentation，batch normalization，以及其他的一些标准程序。 How We Do根据不同的评价标准，YOLO的性能差异较大，总的来说主要是因为YOLO虽然能标出物体的大致位置，但是画出的框并不是“完美”，使得在IOU要求高的评价标准上，YOLO的得分很低。 另外， 之前的YOLO在检测小物体上往往有很多瓶颈，而目前的YOLO已经在慢慢克服这方面的缺陷 Things We Tried That Didn’t WorkAnchor box $x,y$ offset predictions Linear $x,y$ predictions instread of logistic Focal loss Dual IOU thresholds and truth assignment What This All means最后，作者说了为什么要选择其他的评价标准。 对于人类来说，很难直接区分出IOU0.3和IOU0.5之间的差别，那么我们要求计算机这样做是否合理呢（我认为是合理的。。。） 最后作者说出了对计算机视觉未来发展的一些“愿景”。（作者反对隐私泄漏和军事用途）]]></content>
  </entry>
  <entry>
    <title><![CDATA[YOLO9000]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-YOLO9000%2F</url>
    <content type="text"><![CDATA[摘要本文提出了一个新的，实时目标检测模型，YOLO9000。首先，作者使用了不同的提升技巧来优化YOLO模型，同时，利用多尺度的训练方法，YOLO可以方便的在speed和accuracy之间进行tradeoff。在67FPS时，YOLOv2可以在VOC2007上活得76.8的mAP，在40FPS时，YOLOv2可以或者78.6mAP，超过了Faster RCNN和SSD的性能表现。尽管只有200个类里面的44个类的数据，YOLO9000仍然可以在ImageNet上获得19.7的mAP，对于不在COCO里面的156个类，YOLO可以获得16.0的mAP。9000的含义是说YOLO-v2可以运行在超过9000个不同的物体类别，同时保持实时检测。 介绍目前关于分类任务的数据集数量远远超过检测任务的数据集大小，而短期内，检测任务的数据集数量无法快速增长。对此，本文提出了一个新的方法来利用现有的分类任务的数据集，进而扩充当前目标检测系统的检测范围。 同时，本文还提出了一个联合训练方法，使得我们可以同时在检测数据集和分类数据集上训练检测器。（检测数据集提升定位能力，分类数据集提升类别容量和系统健壮性） 本文分两步：首先将YOLO升级到YOLOv2,然后利用本文提出的数据集联合方法来进行联合训练。 BetterYOLO的主要缺点在于定位错误和较低的召回率。 本文在优化这些缺点时，并不是选择扩大网络的规模，而是将整个网络简化，使表征信息更容易学习。根据之前的工作，我们采用了很多方法来提升YOLO的性能。 Batch Normalization：在所有的卷积层之上加上BN，可以提升2%的mAP，并且可以去掉dropout层而不产生过拟合。 高分辨率分类器 High Resolution Classifier：之前的YOLO是利用ImageNet的224大小的图像预训练的，然后在检测时，会将224的图像放大到448尺寸。在YOLOv2,首先在448的ImageNet图像上进行finetune 10 epochs。这给了一定时间让网络适应更大的尺寸大小，然后再在该网络进行物体检测的finetune。 这可以提升4%mAP。 Convolutional With Anchor Boxes：YOLO使用叠在卷积层之上的全连接层的特征提取器来直接预测bounding box的坐标。 相比于YOLO，Faster RCNN使用了精心挑选的方式来获得预测的boundign box，它在anchor box的基础上进行预测，并且其预测层是卷积层。为此，本文移除了YOLO的全连接层，改用anchor box来预测bouding box。 首先，移除了一个pool层，从而使网络卷积层的输出有更高的分辨率。另外，还将网络的输入图像的分辨率降到416,这么做的原因是作者希望在特征图谱上得到奇数个locations，这样一来，就由一个center cell。YOLO的结构可以使416的图像降到13×13的大小。 在使用anchor box时，我们将类别预测问题从位置标定问题中分离出来，然后为每个anchor box预测类别和是否有物体。和YOLO一样，预测是否有物体时会预测gt和proposed box的IOU，类别预测时会计算给定有物体的条件下给出属于每个class的条件概率。 原来的YOLO会对每张图片产生98个box，而使用anchor box后，每张图片会产生上千个box。 不用anchor box时，本文的模型可以达到69.5的mAP和81%的recall。而是用了anchor box后，可以到大69.2的mAP和88%的recall。虽然mAP变低了，但是recall的提升说明本模型还有很大的提升空间。 Dimension Cluster：在使用anchor box时，主要遇到了两个问题。 第一：anchor box的维度是手动标定的。 anchor值的选择会对最终结果有一定影响。为了解决这个问题，我们不采用手动标定的方法，而是对训练集的boudning boxes用k-means clustering来自动找到较好的anchor值。如果使用基于欧式距离的标准k-means，那么更大的box就会产生更多的error。为了不让box的大小对最终的anchor值有影响，我们使用下面的式子作为距离度量： d(\text{box},\text{centroid}) = 1 - IOU(\text{box}, \text{centroid})最终在模型复杂度和高召回率的权衡下，本文选择 $k=5$ 。 直接位置预测 Direct location prediction使用anchor box的第二问题就是：模型不稳定，尤其是在早起迭代阶段。稳定性差的主要来源是box的坐标 $(x,y)$ ，在RPN网络中，网络会预测 $t_x$ 和 $t_y$ ，于是 $(x,y)$ 的值可以通过下面的公式计算得到： x = (t_x*w_a) - x_ay = (t_y*h_a) - y_a本文不使用上面的方法，而是使用YOLO中的方法，预测相对于grid cell位置的相对坐标，这将gt限制在了0到1之间。这样的参数设置使得参数更容易学习，网络更加稳定。 Fine-Grained Features精细化的13×13的特征图谱对于标定大物体来说已经足够了，同时，由于特征更加细粒度，使得它在标定更小的物体时有一定提升。 Faster RCNN和SSD都在不同的特征图谱上执行，因此，它们得到的是一个区间的图像分辨率大小。 本文采用一个更简单的测率，直接添加一个passthrough层，使得从更早的26×26的层中得到特征。 这个passthrough层将高分辨率的特征和低分辨率的特征连接起来，通过将相邻特征堆叠到不同的channes？ 这将26×26×512的特征图谱变成了一个13×13×2048的特征图谱。 Multi-Scale Training为了使模型更加健壮，使用了不同尺度的图片来训练模型。在训练时，每经过一段迭代次数后，都会改变接受输入图片的size。由于本文的模型输出的尺寸会变成原来1/32,因此选择以下尺寸：{320,352,…,608}。 这样一来，一个网络可以在不同的分辨率下进行目标检测，可以取得更好的效果。 Faster大多数目标检测网络使用了VGG16作为基础网络，但是VGG16需要30.69billion浮点运算，十分复杂。 而本文使用基于GoogleNet的自定义网络，只需要8.52billion浮点运算。（但是精确性低于VGGnet） Darknet最终网络起名为Darknet-19。 具有19个卷积层和5个最大池化层。 Training for classification将网络在标准Imagenet 1000上进行训练。 SDG的初始学习率为0.1, 递减指数为0.4,权重递减为0.0005,momentum为0.9。 在训练时，使用了标准的数据增广方法：random crops，ratations，hue，saturation，exposure shifts等。 Training for detection将上面训练好的网络的最后一层卷积层移除，然后加上三个具有1024个filter的3×3卷积层，并在其中跟一个1×1的卷积层，使输出是我们需要的结果。 比如，对于VOC，需要有5个box，每个box有5个coordinates和20个class，所以需要125个filetes。 同时使用了passthrough层，以便模型可以使用fine grain features。 Stronger本文提出了一种可以联合训练分类数据和检测数据的机制。本文的方法使用检测数据的图像标签来学习物体位置信息，使用分类数据的标签来扩充可以检测的物体的类别。 在训练阶段，我们了检测数据和分类数据混合。当网络模型看到一个带有检测标签的图片时，就会对YOLOv2的整个损失函数进行BP求导，当看到分类图片时，则只会对分类部分的损失函数进行BP求导。 上面的方法具有一些难点：]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YOLO]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-YOLO%2F</url>
    <content type="text"><![CDATA[摘要YOLO将目标检测问题看作是一个回归问题，进而从整张图像中直接直接得到bounding boxes和对应的class probabilities。 1. 介绍之前的工作都是将检测任务看成是一个分类问题，如RCNN，通过区域提取，分类，区域修正，去重等等一系列工作得到检测结果，这样的模型十分复杂而且很难优化，因为区域提取和分类任务必须单独训练，麻烦且难以调试。 本文将目标检测问题看成是一个回归问题，直接从图片像素中得到bounding box坐标和class probabilities。 YOLO具有三大优点： Fast。 由于不用按照复杂的pipeline进行运作，YOLO只需要一个卷积网络就可以同时预测出多个物体，因此十分快 YOLO在进行推理时，可以看到整幅图片，因此，可以隐式地对物体的周围像素进行分析。这使得YOLO不容易在背景中错误识别。反观Fast RCNN，经常会将背景中的非物体检测出来。 YOLO的泛化性更好，可以学到更一般的特征。在自然图像上训练后，YOLO在艺术图像上可以取得相比于RCNN更好的检测效果。 2. 一体化检测YOLO使用整幅图像的特征图谱进行预测，同时预测所有物体的所有bounding box。这样的设计思想，可以使得YOLO进行端到端的训练，并且能够进行实时检测。 系统将整张图片划分成 $S \times S$ 大小的网格。 如果某个物体落入了网格中的某一格，那么这个格子就负责检测该物体。 每个格子会预测B个bounding boxes和B个confidence scores。这些confidence scores反映了模型对这个box里面是否有物体，并且有多大的把握确定。 将confidence定义为 $Pr(Object)\times IOU{pred}^{truth}$ 。 $IOU{pred}^{truth}$ 代表真实框和预测框之间的IOU值。 每一个bounding box包含5个预测值：x，y，w，h，和confidence。 每一个grid cell预测C个conditional class probabilities，记为 $Pr(Class_i|Object)$ 。 C与B的个数之间没有直接关系。 在测试阶段，我们将conditional class probabilities和individual box confidence predictions相乘： Pr(Class_i|Object)\times Pr(Object)\times IOU_{pred}^{truth} = Pr(Class_i)\times IOU_{pred}^{truth}由此可以得到针对每个box的特定class的confidence scores。这些scores代表着特定calss出现在box里面的概率，以及预测出来的box在多大程度上适应这个object。 最终预测的tensor维度： $S\times S\times (B\times 5+ C)$ 。 2.1 网络设计YOLO：收到GoogleNet的启发，公有24层卷积层和2层全连接层 但是没有使用Inception模块，而是使用了 $3\times 3$ 的卷积层和一个 $1 \times 1$ 的reduction layers（减少depth） fast YOLO：9个卷积层和2个全连接层。 2.2 训练首先在ImageNet上进行了预训练。 预训练时，使用前20个卷积层，加上一个平均池化层，和一个全连接层。 使用了Darknet framework。 Ren et al证明在预训练的网络上添加卷积层和全连接层可以提升性能。因此，本文添加了4个卷积层和2个全连接层，都赋予随机初始值。 模型的输入图像像素为448 。 最后一层同时预测class probabities和bounding box coordinates。 我们将box的宽和高都归一化到占图片宽高值的比例，因此coordinates的值在0到1之间。coordiantes的x和y归一化到对特定cell的相对位移，所以它们的值也在0到1之间。 本文最后一层使用线性激活函数，其他层均使用leaky rectified linear 激活函数，如下所示： \phi(x) = \begin{cases} x & \text{if } x>0 \\ 0.1x& \text{otherwise} \end{cases}本文的优化函数为平方和误差。 由于它对localization error的权重和对classification的权重是一样的，因此该函数并不能够很好的匹配我们的目标。为了解决问题，提升了bounding box coordinate predictions的loss，同时降低了confidence predictions的loss。 作者使用了 $\lambda{coord} = 5$和 $\lambda{noobj} =5$ 来实现这一目标。 同时为了更好的针对小目标，本文对bounding box的宽和高都使用了平方跟。 YOLO对每个grid cell都会预测出多个bounding boxes，而在训练阶段，我们只需要一个bouding box 来对每个物体负责。选取的原则是与GT有最高的IOU值。 在训练阶段，本文优化下面的联合目标损失函数： \lambda_{coord} \sum_{i=0}^{S^2} \sum_{j=0}^B{\mathbb I}_{ij}^{obj}[(x_i-\hat x_x)^2 + (y_i - \hat y_i)^2] \ + \lambda_{coord}\sum_{i=0}^{S^2} \sum_{j=0}^B \mathbb I_{ij}^{obj} [(\sqrt w_i - \sqrt{\hat w_i})^2 +(\sqrt h_i - \sqrt{\hat h_i})^2] + \sum_{i=0}^{S^2}\sum_{j=0}^B \mathbb I_{ij}^{obj} (C_i - \hat C_i)^2 \ + \sum_{i=0}^{S^2} \mathbb I_i^{obj} \sum_{c\in \text{classes}} (p_i(c) - \hat p_i(c))^2batch size为64，a momentum of 0.9 and a decay of 0.0005。 2.3 推理阶段平均每张图片会得到98个bounding boxes。 虽然采用了非极大值抑制，但是提升的效果并不高，不如RCNN和DPM那么明显。 2.4 YOLO的局限性难以检测小物体和堆积在一起的物体，比如鸟群。 另外，YOLO对于不同大小的物体，其采取的损失函数是一样的，因此，在面对大物体时，细微的差别可能不会引起IOU的大幅变化，但是在面对小物体时，就会产生较大波动。YOLO的错误来源主要是由于定位错误。 3 和其他检测系统的比较Deformable parts models： DPM使用了滑动窗口的方法来做目标检测。它的检测是由分离的好几段过程完成的。 相比来说，作者的模型统一了所有这些过程，并且取得了更快更好的效果（基本来说就是把DPM吊打了。。。，不过毕竟DPM是2010年的产品，不吊打说不过去了。。） RCNN： RCNN没有使用滑动窗口的方法来获取bounding box，而是使用了Selective Search（之后也不用SS方法了，提出了RPN，继承到模型内部了）。同理，RCNN也是一种多阶段的方法，先画框，再检测，分两步走。YOLO在一定程度了也借鉴了RCNN及其变体的思想，但是YOLO是基于grid cell进行proposes bounding box的，所以最后只生成了98个框，而RCNN的框多大2000个，所以YOLO在速度上肯定是远超RCNN了，另外精度上也比RCNN高（不过RCNN只是region based检测方法的雏形，所以并不说明YOLO比RCNN整个系列都好）。 Other Fast Detectors： RCNN其他系列来了，作为后出生的Fast RCNN和Faster RCNN，当然视为自家的兄弟出了口气，在精度上爆了YOLO，但是速度还是不及YOLO（YOLO是真的快，真正意义上的实时监测系统） Deep MultiBox 这篇文章我也没看，14年出来的，貌似也没有引起大的轰动 OverFeat 13年的一篇文章，肯定是干不过YOLO了 MultiGrasp 这是Joseph自己的工作，在YOLO之间发的，解决的任务是检测一张的图片中某个包含物体的区域，比YOLO要解决的任务简单的多，没什么好说的 实验 Experiments首先是在VOC2007上做了实验，然后专门针对YOLO和Fast RCNN进行比较，虽然整体mAP没有Fast高，但是在背景上的假正例比Fast少。接着，还给出2012VOC的实验结果。最后，还做了一个从自然图像训练，然后检测艺术作品的实验，提出YOLO可以学到更一般化的特征。 4.1 Comparison to Other Real-Time Systems]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法总结]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[1. 快排快排的两种写法，Partition内部使用&lt;和&lt;=的区别 12345678910111213141516171819void quickSort(vector&lt;int&gt;&amp; input, int low, int high)&#123; int mid = Partition(input, low, high); if(mid&lt;high) quickSort(input, mid+1, high); if(mid&gt;low) quickSort(input, low, mid-1);&#125;int Partition(vector&lt;int&gt;&amp; input, int low, int high)&#123; int p = input[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; p&lt;=input[high]) high--; input[low] = input[high]; while(low&lt;high &amp;&amp; p&gt;=input[low]) low++; input[high] = input[low]; &#125; input[low] = p; return low;&#125; 这里Partition用的是&lt;=，那么在high位元素和p相等时，并不会执行交换，而是会high—。 下面的Partition用的是&lt;,那么在high位元素和p相等时，二者会进行交换，又因为二者是相等的，所以后面必须再加上low++，目的是为了不让二者再次比较。 而上面的Partition因为没有low++，因此会多一些比较，可以加上去减少比较次数，也不可以不加，代码显得更简洁。 总结：前者比较次数多了一些，后者交换次数多了一些。123456789101112131415161718192021222324252627282930313233343536373839void quick_sort1(int s[], int l, int r)&#123; if (l &lt; r) &#123; int i = AdjustArray(s, l, r);//先成挖坑填数法调整s[] quick_sort1(s, l, i - 1); // 递归调用 quick_sort1(s, i + 1, r); &#125;&#125;int AdjustArray(int s[], int l, int r) //返回调整后基准数的位置&#123; int i = l, j = r; int x = s[l]; //s[l]即s[i]就是第一个坑 while (i &lt; j) &#123; // 从右向左找小于x的数来填s[i] while(i &lt; j &amp;&amp; s[j] &gt;= x) j--; if(i &lt; j) &#123; s[i] = s[j]; //将s[j]填到s[i]中，s[j]就形成了一个新的坑 i++; &#125; // 从左向右找大于或等于x的数来填s[j] while(i &lt; j &amp;&amp; s[i] &lt; x) i++; if(i &lt; j) &#123; s[j] = s[i]; //将s[i]填到s[j]中，s[i]就形成了一个新的坑 j--; &#125; &#125; //退出时，i等于j。将x填到这个坑中。 s[i] = x; return i;&#125; 2. 归并排序核心思想是将两个有序数列进行合并，使其成为一个新的有序数列（时间复杂度为 $O(n)$ ）。通过递归的方式实现。 在合并时，由两种选择，一种是不使用额外空间的插入合并，这样会增加时间开销。另一种是使用额外空间的合并，这样不增加时间开销，但是需要额外空间。（当然，如果使用的是链表，则没有这种情况，可以既不增加时间，也不增加空间开销） 123456789101112131415161718192021222324252627282930313233343536void mergesort(vector&lt;int&gt;&amp; a,int first, int last)&#123; if(first&lt;last)&#123; mid = (last-first)/2; mergesort(a, first, mid); mergesort(a, mid+1, last); mergeArray(a, first,mid,mid+1,last); &#125;&#125;void mergeArray(vector&lt;int&gt;&amp; a, int first1,int last1,int first2,int last2)&#123; vector&lt;int&gt; temp; int i = first1; int j = first2; while(i&lt;=last1 &amp;&amp; j&lt;=last2)&#123; if(a.at(i) &lt; a.at(j))&#123; temp.push_back(a.at(i)); i++; &#125; else&#123; temp.push_back(a.at(j)); j++; &#125; &#125; while(i&lt;=last1)&#123; temp.push_back(a.at(i)); i++; &#125; while(j&lt;=last2)&#123; temp.push_back(a.at(j)); j++; &#125; for(int i = 0; i&lt;temp.size(); i++) a.at(first1+i) = temp.at(i);&#125; 3. 堆排序堆简介堆排序与快速排序，归并排序一样都是时间复杂度为 $O(NlogN)$ 的几种常见排序方法 堆（二叉堆）可以视为一棵完全的二叉树，完全二叉树的一个“优秀”的性质是，除了最底层之外，每一层都是满的，这使得堆可以利用数组来表示（普通的一般的二叉树通常用链表作为基本容器表示），每一个结点对应数组中的一个元素。 如下图,是一个堆和数组的相互关系: 因此,对于给定的某个节点的下标i, 可以很容易计算出这个节点的父节点, 子节点的下标 Parent(i) = floor((i-1)/2)，i 的父节点下标 Left(i) = 2i + 1，i 的左子节点下标 Right(i) = 2(i + 1)，i 的右子节点下标 堆一般分为两种,大顶堆和小顶堆, 前者每个节点的值都大于它的子节点,后者反之 大顶堆: 小顶堆: 堆排序原理堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。在堆中定义以下几种操作： 最大堆调整（Max-Heapify）：将堆作调整，使得子节点永远小于父节点 创建最大堆（Build-Max-Heap）：将堆所有数据重新排序，使其成为最大堆 堆排序（Heap-Sort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 基于上面的三种操作,可以进行堆的插入和删除: 插入: 将新元素放置在数组末尾,然后进行堆调整 删除: 移除堆顶,然后将数组末尾元素置于堆顶,然后进行堆调整(删除主要用于排序) 最大堆调整（MAX‐HEAPIFY）的作用是保持最大堆的性质，是创建最大堆的核心子程序，作用过程如图所示： 代码实现: 1234567891011121314151617181920212223242526272829303132333435363738394041// 递归实现void max_heapify(vector&lt;int&gt; &amp;vec, int index, int heap_size)&#123; int imax = index //mark max index int ileft = index*2+1; // left child int iright = index*2+2; // right child if (ileft &lt; heap_size &amp;&amp; vec[imax] &lt; vec[ileft])&#123; imax = ileft; &#125; if(iright &lt; heap_size &amp;&amp; vec[imax] &lt; vec[iright])&#123; imax = iright; &#125; if( imax != index)&#123; std::swap(vec[imax], vec[index]); max_heapify(vec, imax); //由于变换了当前节点,因此子树的堆结构可能被破坏,递归调整, 这里imax的坐标是左右子节点的下标之一(因为进行了交换) &#125; // 堆是自下而上进行调整的,所以在调整当前节点符合堆要求之前,子树已经符合堆要求, 除非进行了节点交换,否则子树的堆结构不会被破坏, 无需进行额外处理&#125;//非递归实现void max_heapify(vector&lt;int&gt; &amp;vec, int index, int heap_size)&#123; while(true)&#123; int imax = index; int ileft = 2*index+1; int iright = 2*index+2; if(ileft &lt; heap_size &amp;&amp; vec[imax] &lt; vec[ileft])&#123; imax = ileft; &#125; if(iright &lt; heap_size &amp;&amp; vec[imax] &lt; vec[iright])&#123; imax = iright; &#125; if( imax != index )&#123; std::(vec[imax], vec[index]); index = imax; //产生了交换, 可能破坏了左右子树的堆结构, 令index为左右子树之一的下标, 继续调整 &#125;else&#123; break; //如果没有交换，说明当前结构的堆结构已经完成，直接跳出 &#125; &#125;&#125; 创建最大堆（Build-Max-Heap）的作用是将一个数组改造成一个最大堆，接受数组和堆大小两个参数，Build-Max-Heap 将自下而上的调用 Max-Heapify 来改造数组，建立最大堆。因为 Max-Heapify 能够保证下标 i 的结点之后结点都满足最大堆的性质，所以自下而上的调用 Max-Heapify 能够在改造过程中保持这一性质。如果最大堆的数量元素是 n，那么 Build-Max-Heap 从 Parent(n) 开始，往上依次调用 Max-Heapify。 代码实现: 123456789//创建堆void build_maxheap(vector&lt;int&gt; &amp;vec)&#123; int lasti_parent = std::floor((vec.size()-1)/2); for( int i = lasti_parent ; i&gt;=0 ; i--)&#123; max_heapify(vec, i , vec.size()) //从下到上对每个节点进行堆调整，无需从叶子节点开始 //堆的size需要传整个size过去,因为下标从针对整个堆而言的 &#125;&#125; 创建好堆以后,就可以通过移除堆顶来进行排序,每次将堆顶元素和数组末尾元素进行交换(这样可以不借助额外空间完成排序)，然后对数组的前n-1个元素重新进行堆调整构成新的大顶堆, 重复此过程知道堆中只剩下一个元素, 如下图所示: 12345678//代码实现void heap_sort(vector&lt;int&gt; &amp;vec)&#123; build_maxheap(vec); for(int i = vec.size()-1 ; i &gt; 0)&#123; //重复n-1次 std::swap(vec[0] , vec[i]) // Heapify(vec, 0, i); //堆的大小变为i, 所以必须要设置一个变量来标识堆的size,而不是用vec.size() &#125;&#125; 堆排序复杂度分析]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Grasp_detection]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-Grasp_detection%2F</url>
    <content type="text"></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++常用助记]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E5%B8%B8%E7%94%A8%E5%8A%A9%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[闲杂123Array &lt; Stack&lt;int&gt; &gt; array_stack;//在C++98中，要求至少用一个空白符将两个&gt;符号分开，以免与运算符&gt;&gt;混淆，C++11不要求这样做 花括号与分号在结构体与类定义大括号后面需要分号；其余可要可不要if else、try catch等组合语句如果在中间加了分号会将一个语句块分成两个 最简单的将int转换成string的方法方法一：C风格的itoa123int a = 10;char* intStr = itoa(a);string str = string(intStr); 方法二：1234int a = 10;stringstream ss;ss &lt;&lt; a;string str = ss.str(); 方法三：C++风格的std::to_string12345#include &lt;string&gt;std::string s = std::to_string(42);auto s = std::to_string(42); cmath123456789#include &lt;cmath&gt;or#include &lt;math.h&gt;ceil(),floor() 向上、向下取整，不在命名std里面。ceil(5/2); // 2ceil(5.0/2); // 3floor(5.0/2); // 2: std::find返回范围 [first, last) 中满足特定判别标准的首个元素迭代器，查找失败则返回end迭代器 std::sort1234567891011// 自定义函数必须写在最外吗，否则无法通过bool mysort(int a, int b)&#123; return a&gt;b; &#125;int main()&#123; std::vector&lt;int&gt; v = &#123;2,3,5,787,8,5&#125;; std::sort(v.begin(), v.end(), mysort); for(auto iter = v.begin(); iter!= v.end(); iter++)&#123; std::cout&lt;&lt;* iter&lt;&lt;std::endl; &#125;&#125; 1234//lamda 表达式std::sort(s.begin(), s.end(), [](int a, int b) &#123; return b &lt; a; &#125;); vector常用操作截取vector中的一部分作为一个新的vector12 清空：clear() 在最后添加元素：push_back() 初始化123vector&lt;string&gt; v3(5, "hello"); // 创建有5个值为“hello”的string类对象的容器std::vector&lt;int&gt; v = &#123;7, 5, 16, 8&#125;; 判断某元素是否存在123vector&lt;string&gt; vStr;int nRet = std::count(vStr.begin(), vStr.end(), "abc");//返回向量中，“abc”元素的个数 at：访问指定字符，有边界检查 str.at(1) front：访问首字符 (C++11) str.front() back：访问最后的字符（C++11）Cpp string类常用操作截取子串s.substr(pos, n) 截取s中从pos开始（包括0）的n个字符的子串，并返回 s.substr(pos) 截取s中从从pos开始（包括0）到末尾的所有字符的子串，并返回 替换子串s.replace(pos, n, s1) 用s1替换s中从pos开始（包括0）的n个字符的子串 查找子串s.find(s1) 查找s中第一次出现s1的位置，并返回（包括0） s.rfind(s1) 查找s中最后次出现s1的位置，并返回（包括0） s.find_first_of(s1) 查找在s1中任意一个字符在s中第一次出现的位置，并返回（包括0） s.find_last_of(s1) 查找在s1中任意一个字符在s中最后一次出现的位置，并返回（包括0） s.fin_first_not_of(s1) 查找s中第一个不属于s1中的字符的位置，并返回（包括0） s.fin_last_not_of(s1) 查找s中最后一个不属于s1中的字符的位置，并返回（包括0） 判断字符串string里面是否含有某个字符串利用string::size_type string::find(string &amp;);函数 1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; string a="abcdefghigklmn"; string b="def"; string c="123"; string::size_type idx; idx=a.find(b);//在a中查找b. if(idx == string::npos )//不存在。 cout &lt;&lt; "not found\n"; else//存在。 cout &lt;&lt;"found\n"; idx=a.find(c);//在a中查找c。 if(idx == string::npos )//不存在。 cout &lt;&lt; "not found\n"; else//存在。 cout &lt;&lt;"found\n"; return 0;&#125; c++字符串比较大小的两种方法 compare函数的使用： 123456789#include &lt;iostream&gt;using namespace std;int main()&#123; string str1="hello"; cout&lt;&lt;str1.compare("helloo")&lt;&lt;endl;//返回-1； cout&lt;&lt;str1.compare("hello")&lt;&lt;endl;//返回0 ； cout&lt;&lt;str1.compare("hell")&lt;&lt;endl;//返回1；&#125; 使用strcmp(aa1.c_str(),bb2.c_str()) 1234567891011121314#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int main()&#123; char* str1="hello"; char* str2="hell"; char *str3="helloo"; char *str4="hello"; //原型extern int strcmp(const char *s1,const char *s2); cout&lt;&lt;strcmp(str1,str2)&lt;&lt;endl;//返回1； cout&lt;&lt;strcmp(str1,str3)&lt;&lt;endl;//返回-1； cout&lt;&lt;strcmp(str1,str4)&lt;&lt;endl;//返回0.&#125; 统计字符串中某个字符出现了多少次使用算法库里面的count函数，使用方法是count（begin，end，‘a’），其中begin指的是起始地址，end指的是结束地址，第三个参数指的是需要查找的字符 123456789101112#include &lt;iostream&gt;#include &lt;algotirhm&gt;#include &lt;string&gt;using namespace std;int main()&#123; string temp = "aaabcdaaa!!!"; int num = count(temp.begin(),temp.end(),'a'); cout &lt;&lt;"在字符串" &lt;&lt; temp &lt;&lt; "中，" &lt;&lt;"字母a出现的次数是" &lt;&lt; num &lt;&lt; endl; return 0 ；&#125; 元素访问at：访问指定字符，有边界检查 str.at(1) front：访问首字符 (C++11) str.front() back：访问最后的字符（C++11）Cpp c_str：返回不可修改的C字符数组版本（带’\0’） str.c_str() 交换string的值成员函数： string::swap(string&amp; str) 主要用于交换两个string的值，用法如下： 1234567891011121314151617181920212223242526// swap strings#include &lt;iostream&gt;#include &lt;string&gt;main ()&#123; std::string buyer ("money"); std::string seller ("goods"); std::cout &lt;&lt; "Before the swap, buyer has " &lt;&lt; buyer; std::cout &lt;&lt; " and seller has " &lt;&lt; seller &lt;&lt; '\n'; seller.swap (buyer); std::cout &lt;&lt; " After the swap, buyer has " &lt;&lt; buyer; std::cout &lt;&lt; " and seller has " &lt;&lt; seller &lt;&lt; '\n'; return 0;&#125;/*output:Before the swap, buyer has money and seller has goods After the swap, buyer has goods and seller has money*/ 非成员函数std::swap()可以将string内部的两个元素进行交互。同时，也可以对两个string进行交换 12345678910111213141516171819#include &lt;iostream&gt;#include &lt;string&gt;int main()&#123; std::string str1 = "abc"; std::swap(str1.at(0), str1.at(1)); std::cout&lt;&lt;str1&lt;&lt;std::endl; std::string str2 = "def"; std::swap(str1, str2); std::cout&lt;&lt;str1&lt;&lt;std::endl; return 0;&#125;/*output:bacdef*/]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《CUDA C Programming Guide》]]></title>
    <url>%2Fz_post%2FCUDA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CUDACProgrammingGuide-md%2F</url>
    <content type="text"><![CDATA[第一章 介绍GPU在进行浮点数运算时超高的精确度和速度，其原因在于GPU很擅长解决计算密集型和高并行计算。 多核CPU和GPU的一个挑战在于怎么编写并行的程序来利用这些多核。 CUDA并行变成模式就是希望用一个较低的学习曲线来解决这个问题。 三个关键的抽象：线程组等级、共享内存、障碍同步 第二章 编程模型2.1 Kernelskernel程序用__global__定义。并且用一种新的执行配置语法&lt;&lt;&lt;...&gt;&gt;&gt;来决定CUDA的线程数量。每一个线程都会在给定的“线程ID”下执行kernel，线程ID可以通过kernel内部的threadIdx变量来获取。 下面的代码显示了向量加法。 总共启动了N个线程，每个都执行一个对应位相加运算。 123456789101112//Kernel definition__global__ void VecAdd(float* A, float* B, float* C)&#123; int i = threadIdx.x; C[i] = A[i] + B[i];&#125;int main()&#123; ... // Kernel invocation with N threads VecAdd&lt;&lt;&lt;1,N&gt;&gt;&gt;(A,B,C);&#125; 2.2 线程结构（Thread Hierarchy）为了方便，threadIdx包含三个组成向量，因此，线程可以使用一维，二维或者三维的thread index，由此，可以表示一维，二维或者三维的线程块（“thread block”）。 线程的索引和它的线程ID是直接关联的。对于一维线程块来说，它们是一样的。对于二维线程块来说，索引为 $(x，y)$ 的线程，其线程ID为：$(x+yD_x)$ 。对于三维线程块来说，索引为 $(x,y,z)$ 的线程，其线程ID为： $(x+ yD_x +zD_xD_y)$ 。 下面的代码显示了矩阵加法。 123456789101112131415//Kernel definition__global__ void MatAdd(float A[N][N], float B[N][N], float C[C][C])&#123; int i = threadIdx.x; int j =threadIndx.y; C[i][j] = A[i][j] + B[i][j];&#125;int main()&#123; ... //Kernel invocation with one block of N*N*1 threads int numBlocks = 1; dim3 threadsPerBlock(N,N); //&lt;&lt;&lt;&gt;&gt;&gt;语法可以接受int类型或者dim3类型的数据 MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A,B,C);&#125; thread block的索引可以通过blockIdx变量获得，thread block的维度的size可以通过blockDim变量获得。 扩展上面的MatAdd()代码，使其可以处理多blocks，代码如下： 123456789101112131415161718//Kernel definition__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N])&#123; int i = blockIdx.x * blockDim.x + threadIdx.x; int j = blockIdx.y * blockDim.y + threadInx.y; if(i&lt;N &amp;&amp; j&lt;N)&#123; C[i][j] = A[i][j] + B[i][j]; &#125;&#125;int main()&#123; ... //Kernel invocation dim3 threadsPerBlock(16, 16); dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y); MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C); ...&#125; 线程块必须独立执行，因此它们必须能够在任意的顺序下并行执行。 CUDA使用__syncthreads()来协调共享内存和各个线程之间的执行。 2.3 内存结构（Memory Hierarchy）由两种额外的只读内存空间可以被所有线程访问到：常量内存空间（constant memory spaces）和纹理内存空间（texture memory spaces）。 2.4 异构编程CUDA编程模型假设所有线程都是在物理上单个的设备上运行的，每个设备都当做是主机的从处理程序。比如，kernel在GPU上执行，而剩下的C程序在CPU上执行。 CUDA编程模型还假设主机和设备都DRAM中各自维护自己的内存，对应这“主机内存（host memory）”和“设备内存（divice memory）”。因此，程序通过调用CUDA运行时来管理主机和设备的内存。 2.5 计算能力（Compute Capability）计算能力用设备的版本号标识，有时也称为“SM version”。有major revision number“X”和minor revision number“Y”组成，记为X.Y。 第三章 编程接口（Programming Interface）CUDA提供了诸多扩展语法来并行变成（如kernel），任何包含这些扩展语法的源文件都需要需要nvcc编译器来编译。 3.1 Compilation with NVCCKernels can be written using the CUDA instruction set architecture, called PTX, whichis described in the PTX reference manual. 3.1.1 编译工作流3.1.1.1 离线编译 Offline Compilationnvcc编译器可以编译包含host code和device code的混合代码。nvcc首先会将device code从host code中分离出来，然后，会进行以下两步： 编译device code到assembly form（PTX code）或者binary form（cubin objec） 修改host code，将&lt;&lt;&lt;...&gt;&gt;&gt;语法替换成必要的CUDA C运行时函数。 被修改的host code要么输出成C code，要么把直接输出成object code。 3.1.1.2 即时编译 Just-in-Time Compilation二进制兼容性 Binary CompatibilityBinary code is architecture-specific。通过-code=sm_35的形式来指定特定的architecture。注意，编译好的二进制代码是向上兼容的，也就是如果二进制代码设定的计算能力版本号为 $X.y$ ，那么该代码就只能运行在 $X.z$上，其中 $z\ge y$ 。 3.1.3 PTX 兼容性一些PTX指令仅仅支持在高计算机能力版本的GPU中使用。 指针某些计算能力版本的PTX code总是可以转换成binary code，进而都更高计算能力的版本中使用。 其他有些版本，则不能直接使用。 3.1.4 应用兼容性为了满足bianry兼容性和PTX兼容性，推荐使用即时编译。 通过-gencode、-arch和-code编译选项来指定计算能力版本号及其兼容性。 3.1.5 C/C++ 兼容性CUDA源文件的前端遵循C++语法规则。host code可以完美支持C++语言发。但是，device code支持C++语法中的一个子集，详细可以参见C/C++ Language Support。 3.1.6 64-Bit Compatibility64位的nvcc会将device code编译成64位模式（即，指针占64位）。此时host code必须在32位模式下执行。 32位device、host同理 -m64 选项可以切换nvcc的位数。 3.2 CUDA C Runtime运行时使用cudart库实现。 或者使用cudart.lib、libcudart.a进行静态链接，或者使用cudart.dll、cudart.so进行动态链接。 正如前面异构编程提到的。CUDA编程模型将系统看走是由device和host组成的一个整体，二者管理各自的内存。 3.2.1 初始化没有专门的初始化函数在初始化阶段，runtime为系统中的每一个device创建上下文。 3.2.2 设备内存 Device MemoryKernels操控device memory之外的代码。所以runtime会提供allocate，deallocate和copy等函数来复制device memory，同时在host和device内存之间传输数据。 Divice memory可以申请linear memory或者CUDA arrays。 CUDA arrays是不透明的内存形式，专门用于优化texture fetching。 Linear memory存在于40位的地址空间中，可以使用cudaMalloc()函数申请，用cudaFree()函数释放，同时，可以用cudaMemcpy()函数来将数据在host和device之间交换。 cudaMallocPitch()和cudaMalloc3D()推荐用来申请2D和3D数组。cudaMemcpy2D。 cudaGetSymbolAddress()用来检索指向内存的地址。 cudaGetSymbolSize()可以得到申请内存的大小。 3.2.3 共享内存 Shared MemoryShared Memory在Thread Hierarchy上要比global memory更快。 矩阵乘法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// Matrices are stored in row-major order:// M(row, col) = *(M.elements + row * M.width + col)typedef struct &#123;int width;int height;float* elements;&#125; Matrix;// Thread block size#define BLOCK_SIZE 16// Forward declaration of the matrix multiplication kernel__global__ void MatMulKernel(const Matrix, const Matrix, Matrix);// Matrix multiplication - Host code// Matrix dimensions are assumed to be multiples of BLOCK_SIZEvoid MatMul(const Matrix A, const Matrix B, Matrix C)&#123;// Load A and B to device memoryMatrix d_A;d_A.width = A.width; d_A.height = A.height;size_t size = A.width * A.height * sizeof(float);cudaMalloc(&amp;d_A.elements, size);cudaMemcpy(d_A.elements, A.elements, size,cudaMemcpyHostToDevice);Matrix d_B;d_B.width = B.width; d_B.height = B.height;size = B.width * B.height * sizeof(float);cudaMalloc(&amp;d_B.elements, size);cudaMemcpy(d_B.elements, B.elements, size,cudaMemcpyHostToDevice);// Allocate C in device memoryMatrix d_C;d_C.width = C.width; d_C.height = C.height;size = C.width * C.height * sizeof(float);cudaMalloc(&amp;d_C.elements, size);// Invoke kerneldim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);dim3 dimGrid(B.width / dimBlock.x, A.height / dimBlock.y);MatMulKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_A, d_B, d_C);// Read C from device memorycudaMemcpy(C.elements, Cd.elements, size,cudaMemcpyDeviceToHost);&#125;// Free device memorycudaFree(d_A.elements);cudaFree(d_B.elements);cudaFree(d_C.elements);// Matrix multiplication kernel called by MatMul()__global__ void MatMulKernel(Matrix A, Matrix B, Matrix C)&#123;// Each thread computes one element of C// by accumulating results into Cvaluefloat Cvalue = 0;int row = blockIdx.y * blockDim.y + threadIdx.y;int col = blockIdx.x * blockDim.x + threadIdx.x;for (int e = 0; e &lt; A.width; ++e)Cvalue += A.elements[row * A.width + e]* B.elements[e * B.width + col];C.elements[row * C.width + col] = Cvalue;&#125; 3.2.4 Page-Locked Host Memoryplhm有诸多好处，如： 可以使copy更快 可以直接映射到地址空间，消除copy到device memory的需求 在fron-side bus上， plhm的bandwidth更高。 但是，plhm是稀缺资源，因此，在申请时一定要注意不能过度使用。 3.2.4.1 移动内存 Portable Memory一块page-locked内存可以备用在与任意一个设备的连接上。但是默认情况下，使用page-locked内存的好处仅仅会在当前block所申请的设备（或者那些共享了内存的设备）上显现。 为了使这些好处对于所有设备来说都是可行的，block需要将flag cudaHostAllocPortable传递到cudaHostAlloc中去，或者将flag cudaHostRegisterPortable传递到cudaHostRegister中去。 3.2.4.2 Write-Combining Memory该内存通过释放L1和L2的缓存资源，使得更多缓存资源可以给后面的应用使用。 从host中读取write-combining 内存比较慢，所以常常只用于写。 3.2.4.3 Mapped Memory使用cduaHostAllocMapped或者cudaHostRegisterMapped可以使一块page-locked host内存映射到设备的地址空间中。 因此，这样的内存块往往有两个地址，分别是host地址和device地址。 直接kernel中访问host内存有以下几点优势： 无需在device中申请内存块，也无需在device和host中来还传输数据 在执行kernel时，无需使用“流”来overlap数据的传输 3.2.5 异步并发执行 Asynchronous Concurrent ExecutionCUDA将下列操作当作一个独立的任务，它们可以互相并发执行： 在host上计算 在device上计算 将host上的内存传输到device上 将device上的内存传输到host上 3.2.5.1 在Host和Device之间并发执行通过异步调用，许多device操作都可以排成队列，进而利用CUDA driver来执行。这减轻了host线程管理device的负担，使得它可以执行其他任务。下列device操作相对于host来说是异步的。 启动Kernel 将内存拷贝到一个单一的deivce内存中 将内存从host拷贝到device中小于64将内存从host拷贝到device中小于64KB的内存块中 用带有Async后缀的函数来进行内存拷贝 内存设定函数的调用（Memory set function calls） 3.2.5.2 Concurrent Kernel Execution计算能力告诉2.x的版本可以并发启动多个kernels。 可以通过concurrentKernel设备属性来查看是否支持并发启动。 3.2.5.3 Overlap of Data Tranfer and Kernel Execution有一些设备可以从GPU利用kernel执行来进行异步的内存拷贝，应用需要想设备询问是否具有这种功能，可以通过检查asyncEngineCoune设备属性来查看，如果大于0就是支持的。 3.2.5.4 并发数据传输 Concurrent Data Transfers一些计算能力在2.x以上的设备可以在进行数据传输是进行overlap，应用可以通过asyncEngineCount来检查设备是否支持该功能 3.2.5.5 流 Streams应用通过“流”来管理并发的操作。一个“流”代表这一串由“命令”组成的序列 3.2.5.5.1 创建和销毁：Creation and Destruction下面的代码创建了两个流，同时在page-locked内存中申请了flaot类型的hosrtPtr 123456cudaStream_t stream[2];for (int i = 0; i &lt; 2; ++i)cudaStreamCreate(&amp;stream[i]);float* hostPtr;cudaMallocHost(&amp;hostPtr, 2 * size); 这两条流都经过下面的代码定义，执行一个从host到device的内存拷贝操作，一个kernel启动操作，以及一个从device到host的的内存拷贝操作。 123456789for (int i = 0; i &lt; 2; ++i) &#123;cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,size, cudaMemcpyHostToDevice, stream[i]);MyKernel &lt;&lt;&lt;100, 512, 0, stream[i]&gt;&gt;&gt;(outputDevPtr + i * size, inputDevPtr + i * size, size);cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,size, cudaMemcpyDeviceToHost, stream[i]);&#125; 通过cudaStreamDestroy()可以释放流： 1234for (int i =0;i&lt;2;i++)&#123; cudaStreamDestroy(stream[i]);&#125; 3.2.5.5.2 默认流 Default Stream对于使用--default-stream per-thread编译选项的代码来说，默认流是一条常规的流，并且每个主线程都有它自己的默认流 对于使用--default-stream legacy编译选项的代码来说，默认流是一条特殊的流，被称为NULL stream ，并且每一个设备都具有一条单一的NULL stream供所有的host线程使用。它的特殊性源自于它会隐式的进行同步操作。 3.2.5.5.3 显式同步以下几种方式可以对流进行显式同步操作： cudaDeviceSynchronize() cudaStreamSynchronize() cudaStreamWaitEvent() cudaStreamQuery() 为了避免不必要的速率降低，以上所有的同步函数通常用于timing purpoese或者用于孤立一个拷贝或启动的失败。 3.2.5.5.4 隐式同步从两个不同流传过来的指令中的其中一条出现了问题，那么就无法并发运行。 同步操作越晚执行越好。 3.2.5.5.5 Overlapping 行为对于两个流里面的操作，如一个是从host拷贝内存到device，另一个是从device拷贝内存到host，则这两条指令直接存在Overlap。 3.2.5.5.6 回调函数Callbacks运行时提供了可以在流中的任何位置插入回调函数的指令：cudaStreamAddCallback()。 3.2.5.5.7 流优先级 Stream Priorities相对优先级使用cudaStreamCreateWithPriority() 获取优先级范围[highest priority,lowest priority]使用cudaDeviceGetStramPriorityRange。 下面的代码包含了获取当前设备的优先级范围： 1234567// get the range of stream priorities for this deviceint priority_high, priority_low;cudaDeviceGetStreamPriorityRange(&amp;priority_low, &amp;priority_high);// create streams with highest and lowest available prioritiescudaStream_t st_high, st_low;cudaStreamCreateWithPriority(&amp;st_high, cudaStreamNonBlocking, priority_high);cudaStreamCreateWithPriority(&amp;st_low, cudaStreamNonBlocking, priority_low); 3.2.5.6 事件 Eventsruntime 同时还提供了密切监视device进程的方法，主要是通过appliocation来异步记录事件完成时的事件点。 3.2.5.6.1 创建和销毁下面的代码创建了2个事件：123cudaEvent_t event1, event2;cudaEventCreate(&amp;event1);cudaEventCreate(&amp;event2); 下面的代码销毁了2个事件：12cudaEventDestroy(event1);cudaEventDestroy(event2); 3.2.5.6.2 运行时间下面的代码可以用来监视事件的运行时间（从start到end）1234567891011121314cudaEventRecord(start, 0);for (int i = 0; i &lt; 2; ++i) &#123;cudaMemcpyAsync(inputDev + i * size, inputHost + i * size,size, cudaMemcpyHostToDevice, stream[i]);MyKernel&lt;&lt;&lt;100, 512, 0, stream[i]&gt;&gt;&gt;(outputDev + i * size, inputDev + i * size, size);cudaMemcpyAsync(outputHost + i * size, outputDev + i * size,size, cudaMemcpyDeviceToHost, stream[i]);&#125;cudaEventRecord(stop, 0);cudaEventSynchronize(stop);float elapsedTime;cudaEventElapsedTime(&amp;elapsedTime, start, stop); 3.2.5.7 同步调用可以使用cudaSetDeviceFlags()配合一些特定的flags？？ 3.2.6 Multi-Device System3.2.6.1 Device Enumeration一个host系统可以有多个devices，下面的代码展示了如何枚举这些设备，并查询它们的属性，决定可启用CUDA的设备数量。 123456789int deviceCount;cudaGetDeviceCount(&amp; deviceCount);int device;for( device = 0; device&lt;deviceCount; device++)&#123; cudaDeviceProp deviceProp; cudaGetDeviceProperties(&amp;deviceProp, device); printf("Device %d has compute capability %d.%d. \n"), device, deviceProp.major, deviceProp.minor);&#125; 3.2.6.2 Device Selectionhost线程可以在任何时候使用cudaSetDevice()来设置device。device的内存申请和kernel启动都会在当前设置的device上进行，如果没有调用该函数，则当前的设备默认为0. 下面的代码展示了如何设置当前的device，以及申请内存和执行kernel 123456789size_t size = 1024 * sizeof(float);cudaSetDevice(0);float* p0;cudaMalloc(&amp;p0, size);// Allocate memory on device 0MyKernel&lt;&lt;&lt;1000, 128&gt;&gt;&gt;(p0);// Launch kernel on device 0cudaSetDevice(1);// Set device 1 as currentfloat* p1;cudaMalloc(&amp;p1,size);// Allocate memory on device 1MyKernel&lt;&lt;&lt;1000,128&gt;&gt;&gt;(p1);// Launch kernel on device 1 3.2.6.3 Stream and Event Behavior如果stream没有绑定到当前的device，那么kernel launch就会失败 即使stream没有绑定到当前的device，memory copy也会成功 如果input event和input stream 绑定到了不同的diveces上面，那么cudaEventRecord() will fail 如果两个input events绑定到了不同的devices上面，那么cudaEventElapsedTime() will fail 即使input event绑定到了不同于当前device的device上面，cudaEventSynchronize()和cudaEventQuery()仍然will succeed]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C++中关于*、&、*&以及&*的解析.md]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E5%85%B3%E4%BA%8E%E6%8C%87%E9%92%88%EF%BC%8C%E6%8C%87%E9%92%88%E5%BC%95%E7%94%A8%E7%9A%84%E8%A7%A3%E6%9E%90-md%2F</url>
    <content type="text"><![CDATA[由一道牛客网《剑指offer》的编程题引发的思考，题目如下： 二叉搜索树与双向链表：输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的节点，只能调整树中结点指针的指向。 按照递归的解题思路，有如下解答： 12345678910111213141516171819202122232425262728293031323334/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: TreeNode* Convert(TreeNode* pRootOfTree) &#123; if(pRootOfTree==nullptr) return nullptr; TreeNode* prenode = nullptr; recurve(pRootOfTree,prenode); while(pRootOfTree-&gt;left!=nullptr) pRootOfTree = pRootOfTree-&gt;left; return pRootOfTree; &#125; void recurve(TreeNode* root, TreeNode*&amp; prenode)&#123; if(root-&gt;left!=nullptr) recurve(root-&gt;left,prenode); root-&gt;left = prenode; if(prenode!=nullptr) prenode-&gt;right = root; prenode = root; if(root-&gt;right!=nullptr) recurve(root-&gt;right,prenode); &#125;&#125;; 代码中23行使用了TreeNode*&amp; prenode，这里，如果缺少了&amp;，则结果会出错！ 以下，对C++中*、&amp;、*&amp;以及&amp;* 四种形式展开讨论。 * 代表指针&amp; 代表引用、别名指针和引用的区别之一： 参数传递时，不管是传值还是传指针，函数都会产生一个临时副本变量，但在传引用时，不会生成临时变量。 *&amp; 首先是一个指针，然后前面的&amp;代表是这个指针的引用。 指针的引用其实就是指针的一个别名，和指针具有相同的地址。&amp;* 首先是一个变量的引用，然后是指向这个引用的指针，但是，因为引用不是对象，没有实际的地址，因此 不能定义指向引用的指针 。问题：向函数中传递指针和传递指针的引用的区别 如果传递的是指针，那么会先复制该指针，在函数内部使用的是复制后的指针，这个指针与原来的指针虽然指向相同的地址，但是如果在函数内部将复制后的指针指向了另外的地址，那么不会影响原来的指针。 但是对于传递指针的引用，如果将传递进来的指针指向了新的地址，那么原始的指针也会指向新的地址，这也是为什么在该题中，必须使用指针的引用，而不能使用指针的原因。就是因为在这段代码中，要对指针指向的值进行更改，而在递归的函数中，又需要保证prenode指向的值保持统一，因此，必须使用指针的引用来使在不同层的递归函数中，prenode指向的值都是一样的。 在传递指针的引用时，还有另外一个问题，那就是如果由于原始的指针不再指向原始对象了，所以如果没有其他指针指向该原始对象的话，就会造成内存泄漏。同理，如果在函数内释放了指针的引用，那么在函数外部就不能在使用原来的指针了，因为原来的内存已经被释放了。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中NULL和nullptr之间的区别.md]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%ADNULL%E3%80%81null%E5%92%8Cnullptr%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB-md%2F</url>
    <content type="text"><![CDATA[首先，C++中没有null，只有NULL和nullptr。 NULL引渡自C语言，一般由宏定义实现，而nullptr则是C++11的新增关键字。在C语言中，NULL被定义为(void*)0,而在C++语言中，NULL则被定义为整数0，编译器一般对其实际定义如下：12345#ifdef __cplusplus#define NULL 0#else#define NULL ((void *)0)#endif 出现C++和C定义不一致的原因是，在C++中不允许(void*)类型进行隐式转换，例如：12345char* a =&quot; Hello&quot;;void foo(void* p)&#123;&#125;foo(a); 以上这种调用方式在C++中是不允许的，在C++中指针必须有明确的类型定义。如上需使用foo((char*)a)才可以;但是将NULL定义为0带来的另一个问题是无法与整数的零区分。因为C++中允许有函数重载，所以可以试想如下函数定义情况： 123void func(int data);void func(char* data); 那么在传入NULL参数时，编译器将无法确定到底使用哪个函数定义，造成编译时错误。nullptr在C++11被引入用于解决这一问题，nullptr可以明确区分整型和指针类型，能够根据环境自动转换成相应的指针类型，但不会被转换为任何整型，所以不会造成参数传递错误。nullptr的一种实现方式如下： 1234567const class nullptr_t&#123;public: template&lt;class T&gt; inline operator T*() const&#123; return 0; &#125; template&lt;class C, class T&gt; inline operator T C::*() const &#123; return 0; &#125;private: void operator&amp;() const;&#125; nullptr = &#123;&#125;; 以上通过模板类和运算符重载的方式来对不同类型的指针进行实例化从而解决了(void*)指针带来参数类型不明的问题，另外由于nullptr是明确的指针类型，所以不会与整形变量相混淆。但nullptr仍然存在一定问题，例如： 123void fun(char* p);void fun(int* p); 在这种情况下存在对不同指针类型的函数重载，此时如果传入nullptr指针则仍然存在无法区分应实际调用哪个函数，这种情况下必须显示的指明参数类型。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Video-based Sign Language Recognition without Temporal Segmentation]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-Video_based_Sign_Language_Recognition%2F</url>
    <content type="text"><![CDATA[摘要世界上具有上百万的聋哑患者使用手语进行交流，因此，实现从手语到自然语言的翻译是一件非常有意义的事情。目前，手语识别（SLR）问题主要由两量子问题组成：逐个单词进行识别的独立SLR、对整个句子进行翻译的连续SLR。 介绍——Introduction在SLR问题中的一个关键挑战在于表示肢体运动、手势和面部表情的关系描述器的设计。目前主要有两类：手工设计特征 和 基于CNN和特征提取方法。 本文欲计划涉及一个双流的3D-CNN模型，用于对视频特征进行提取。 时域分割问题在连续SLR中是一个十分困难的问题。 普遍的解决思路是将连续的SLR解析成独立的单词进行识别，这样就需要解决时域分割问题。 由于需要翻译的动作十分多样，因此很难进行检测，同时，时域分割作为一个预处理步骤，会将分割误差传递给后续步骤。并且，对每个动作打标签也是一项很耗时的任务。 受到基于LSTM的视频描述工作的启发，我们利用一个等级式的注意力网络（Hierarchical Attention Network HAN）规避了时域分割问题。HAN是在考虑结构信息和注意力机制之后，对LSTM的一个扩展。大体思路是将整个视频流送入的HAN中，然后一个单词一个单词的将句子输出。 但是，HAN仅仅是通过前一个单词，来预测后一个单词的最大可能性，忽略了video和句子之间的关系。最终结果是，它可能会出现鲁棒性问题。为了改善这个问题，本文引入隐式共建模型来挖掘视频和句子之间的关系。 一句话总结，本文主要的贡献点有以下三个： 一个新的双流3D CNN，用于生成全局和局部的视频特征表征 一个新的LS-HAN框架，可以规避连续SLR中的时域分割问题 对提出的LS-HAN框架中的相关性损失函数和分辨损失函数进行联合优化 编辑了目前最大的针对连续SLR问题的现代汉语手语识别数据集 相关工作连续SLR大多数现有的SLR研究都是针对独立SLR的。更具挑战性的问题是连续SLR的研究。大多数现有的连续SLR方法都将句子级别的识别分为以下三个阶段：视频时域分割，独立单词识别，基于语言模型的句子融合。例如，DTW-HMM提出了一个基于粗粒度时域分割的阈值矩阵。2017年提出了一个新的基于HMM的语言模型。最近，transitional movements吸引了很多的关注，因为它们可以当作时域分割的基础。 尽管采用时域分割很普遍，但是时域分割问题本质上是很难解决的：即使是transitional movements在面对手势时，依然显得很脆弱和混乱。 视频描述生成图像描述生成是一个相关的研究领域，它通过描述视频序列中的场景/物体/动作来生成一段简单的话。一个流行的方法是序列到序列，视频到文本的方法，它将两个LSTM置于CNN之上。还有其他更多关于LSTM的扩展。 抛开图像描述生成和手语翻译在目标和技术手段上的一些相似之处，二者依然是两个完全不同的任务。 基于潜在空间的学习潜在空间模型是一个用来在不同模态的语义鸿沟之间建立联系的流行的工具。 手语视频特征表示手语视频主要由身体的上半部分决定，尤其是手势动作。识别手势动作的主要挑战是会出现大量的变形和趋向。 收到目前深度学习技术在目标检测任务上的进展，我们提出了一个双流的3D CNN模型，用于生成视频特征的表征。这个3DCNN模型会同时接受整个视频帧和剪裁后的手势图像，并且独立的送到两个流中去，最终会通过一个融合机制，将它们融合在一起。因此，这个模型可以对整体信息和局部信息都进行编码。 手势检测和跟踪我们首先用fasterrcnn预训练了VOC2007数据，然后，从CSL中选取了400帧进行finetune。之后，所有的视频都逐帧处理。 另外，还是用了compressive tracking 双流3D CNN本文基于 C3D（Tran et al 2015） 设计了一个3D CNN双流模型。模型的输入是一个视频截图（间隔16帧）。 顶端流用于提取全局的手部位置和动作。底端流关注的是局部的，细节的视频帧信息。左手和右手作为不同的通道连接在一起。最后的两层全连接层会作为融合层将顶端流和底端流连接起来。 每一个流都包含着和C3D网络相同的结构。 双流CNN模型首先会对独立的SLR数据集进行训练。在测试阶段，会使用从视频中截断的图来进行测试。 LS-HAN Model视频句子 隐式空间如图2所示，我们模型框架的输入是视频和对应标注好的数据。视频用global-local特征表示，句子中的每一个单词都用one hot向量表示。 用V表示视频，S表示句子，。 隐式空间的目标是建立连接语义鸿沟的空间。 将视频截图和句子映射到同一个隐式空间中。 Dynamic Time Warping（DTW）算法：衡量 $f_v 和 f_s$之间的相关性。 Recognition with HAN首先最近sequence to sequence模型的启发，识别问题可以看作是在给定video的情况下，求句子的log条件分布率的估计。（LSTM）。 首先，输入帧序列通过隐式空间进行编码，然后，对句子的每个单词进行解码。扩展HAN中的编码器使其能够反应等级式结构，同时引入注意力机制。 模型包含两个编码器和一个解码器。每一个编码器都是一个带有注意力机制的 bidirectional LSTM，而解码器一个单独的LSTM。 clip编码器将视频截图编码，使其和单词对其。本文才经验上选取了3种对齐机制：（实验证明3比较好，因为本文选择3） 将clips分成两个子序列 每两个clips分出一个子序列 均分出7个子序列（因为在训练集中的句子平均含有7个单词）。 Learning and Recognition of LS-HAN Model实验数据总共有两个开源数据，一个是CSL，另一个是德国手语数据集RWTH-PHONEIX-Weather。 CSL包含25k个标注的视频实例，总共超过100小时，共50位手语者。17K用于训练，2K用于验证，6K用于测试。 RWTH-PHONEIX-Weather包含7K天气预测的句子，共9位手语者。 所有的视频均为25帧每秒，分辨率为210×260 。 实验设置227×227. fc6 4096.等等 评价标准]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第十四章]]></title>
    <url>%2Fz_post%2FCpp-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CppPrimerPlusChapter14%2F</url>
    <content type="text"><![CDATA[第十四章 C++中的代码重用除了公有继承之外，还有其他促进代码重用的方法： 包含/组合/层次话：在类中使用另一个类的对象做成员 私有或保护继承：用于实现has-a关系，即新的类将包含另一个类的对象 14.1 包含对象成员的类string类 valarray类：这是一个模板类 14.2 私有继承另一种实现has-a关系的途径——私有继承。 使用私有继承，基类的公有成员和保护成员都将成为派生类的私有成员。这意味着基类方法将不会成为派生对象公有接口的一部分，但可以在派生类的成员函数中使用它们。 “包含”是将对象作为一个命名的成员添加到类中，而“私有继承”将对象作为一个未被命名的继承对象添加到类中。 初始化基类组件，对于继承类，需要使用成员初始化列表语法，使用类名而不是成员名称来标识构造函数。 访问基类的方法：可以通过将私有的成员函数包含在一个公有函数中来访问该私有方法。 访问基类对象：通过this指针和强制类型转换来创建对应的对象或引用 访问基类的友元函数：用类名显式的限定函数名不适合友元函数，这是因为友元不属于类。然而，可以通过显式的转换为基类来调用正确的函数。 14.2.2 使用包含还是私有继承。通常，应使用包含来建立has-a关系。如果新类需要访问原有类的保护成员，或需要重新定义虚函数，则应使用私有继承。 14.2.3 保护继承保护继承是私有继承的变体。使用保护继承时，基类的公有成员和保护成员都将成为派生类的保护成员。 当从派生类派生出另一个类时，私有继承和保护继承之间的区别在于： 使用私有继承时，第三代类将不能使用基类的接口，这是因为继承的公有方法在派生类中将变成私有方法。使用保护继承时，基类的公有方法在第二代中将变成受保护的，因此第三代派生类可以使用它们。 各种继承方式: 特征 公有继承 保护继承 私有继承 公有成员变成 派生类的公有成员 派生类的保护成员 派生类的私有成员 保护成员变成 派生类的保护成员 派生类的保护成员 派生类的私有成员 私有成员变成 只能通过基类接口访问 只能通过基类接口访问 只能通过基类接口访问 能否隐式向上转换 能 能（但只能在派生类中） 否 隐式向上转换（implicit upcasting）：意味着无需进行显式类型转换，就可以将基类指针或引用指向派生类对象。 14.2.4 使用using重新定义访问权限使用保护派生或私有派生时，基类的公有成员将成为保护成员或私有成员。假设要设即为的方法在派生类外面可用，方法之一是定义一个使用该基类方法的派生类方法。 另一种方法是，将函数调用包装在另一个函数调用中，即使用一个using声明来指出派生类可以使用特定的基类成员，即使采用的是私有派生。例如，假设希望通过Student类能够使用valarray的方法min()和max()，可以如下书写：12345class Student: private std::string, private std::valarray&lt;double&gt;&#123; public: using std::valarray&lt;double&gt;::min; using std::valarray&lt;double&gt;::max;&#125; 注意：using声明只使用成员名——没有圆括号、函数特征表和返回类型。 有一种老式的不带using声明的方法，它看起来就像是不包含关键字using的using声明，但是这种方法已被摒弃，即将体制使用。 14.3 多重继承MI描述的是有多个直接基类的类，与单继承一样，公有MI表示的也是is-a关系。例如，可以从Waiter类和Singer类派生出SingingWaiter类。 私有MI和保护MI可以表示has-a关系。 MI可能会带来很多新问题，其中最重要的问题是： 从两个不同的基类继承同名方法; 从两个或更多相关基类那里继承同一个类的多个实例。 14.3.1 有多少个Work如果多个类来自于同一个基类，而当前类又继承这多个类，那么，就会有多个最原始的基类副本，者造成了二义性。 为了解决以上问题，C++引入了一种新技术——虚基类（virtual base calss），使MI成为可能。 虚基类：虚基类使得从多个类（它们的基类相同）派生出的对象之只继承一个基类对象。 新的构造函数规则：使用虚基类时，需要对类构造函数采用一种新的方法。对于非虚基类，唯一可以出现在初始化列表中的构造函数是即时基类构造函数。但这些构造函数可能需要将信息传递给其基类。（详细请看p558） 14.3.2 哪个方法因为多重继承，有时会继承多个同名方法，因此，需要指出使用哪一个方法。 可以使用作用域解析运算符来指定使用的方法：12SingingWaiter newhire("Elise", 2005, 6, soprano);newhire.Singer::Show(); 然而，更好的方法是在SingingWaiter中重新定义Show()，并指出要使用哪个Show()。如下所示： 123void SingingWaiter::Show()&#123; Singer::Show;&#125; 对于多继承，使用模块化的方式而不是递增方式来在派生类的同名函数中使用基类函数，即提供一个只显示Work组件的方法和一个只显示Waiter组件 或 Singer组件的方法。然后，在SingingWaiter::Show()方法中将组件组合起来。详细见p559。 总结： 在祖先相同时，使用MI必须引入虚基类，并修改构造函数初始化列表的规则。 下面介绍一些有关MI的问题。 混合使用虚基类和非虚基类 当类通过多条虚途径和非虚途径继承某个特定的基类时，该类将包含一个表示所有的虚途径的基类子对象和分别表示各条非虚途径的多个基类子对象。 虚基类和支配 派生类中的名称优先于直接或间接祖先类中的相同名称。 如果无法用优先规则判断出使用哪个名称，则会导致二义性。 14.4 类模板C++的类模板为生成通用的类声明提供了一种更好的方法（C++最初不支持模板，单模板被引入后，就一直在演化，因此有的编译器可能不支持这里的所有特性）。模板提供参数化（parameterized）类型，即能够将类型名作为参数传递给接收方来建立类或函数。 C++库提供了多个模板类，如vector、array、valarray等等。 14.4.1 定义类模板模板类以下面这样的代码开头：1234567template &lt;class T&gt;class Stack&#123;private: ...public: ...&#125;; 这里使用class并不意味着Type必须是一个类，而只是表明Type是一个通用的类型说明符，在使用模板时，将使用时间的类型替换它。较新的C++实现推荐使用关键字typename来代替class。 当模板被调用时，Type将被具体的类型值（如int或string）取代。 同样，可以使用模板成员函数替换原有类的类方法，每个函数头都将以相同的模板声明打头（如果在类声明中定义了方法，即内联定义，则可以省略模板前缀和类限定符：1234template &lt;typename T&gt;bool Stack&lt;T&gt;::push(const T&amp; item)&#123; ...&#125; 注意： 模板声明本身并不是类和成员函数，它们属于C++编译器指令，说明了如何生成对应的类和成员函数定义。而模板的具体实现则被称为实例化（instantiation）或具体化（specialization）。 不能将模板成员函数放在独立的实现文件中（以前，C++标准确实提供了关键字export，让您能够将模板成员函数放在独立的实现文件中，但支持该关键字的编译器不多，C++11不再这样使用export，而是将其保留用于其他用途）。 由于模板不是函数，它们不能单独编译，模板必须与特定的模板实例化请求一起使用。为此，最简单的方法是就所有模板信息放在一个头文件中，并在要使用这些模板的文件中包含该头文件。 14.4.2 使用模板类可以用所需的具体类型替换泛型名，就可以声明一个类型为模板类的对象： 12Stack&lt;int&gt; kernels;Stack&lt;string&gt; colonels; 注意，必须显式的提供所需的类型，这与常规的函数模板是不同的，因为编译器可以根据函数的参数类型来确定要生成哪种函数。 14.4.3 深入探讨模板类关于使用指针在作为Stack的类型，比如用字符指针替换string来作为T类型。这样会带来一些问题。 char* s：单纯的char* s并没有给s分配合适的空间，这会使s的值存在某些不合适的内存单元中 char s[40]：这虽然分配了空间，但是s的大小固定，且s本身是数组名，虽然代表地址，但是无法进行运算，有些操作会引起冲突。 char* po = new char[40]：这次分配了空间，po也成为了变量，但仍有问题，具体看p573。 但是并不是说不能使用指针作为T，只是在使用时，需要多家注意，考虑谨慎。 14.4.4 数组模板示例和非类型参数使用非类型参数来说模板达到某些目的 12345678910template &lt;typename T, int n&gt;class ArrayTP&#123;private: ...public: ...&#125;;ArrayTP&lt;double,12&gt; one;ArrayTP&lt;double,13&gt; two; 表达式参数方法的主要缺点是，每组数组的大小都将生成自己的模板，而利用构造函数的方法只会生成一个类声明，并将数组大小信息传递给类的构造函数，详细见p578。 14.4.5 模板多功能性可以将常规类的技术用于模板类，模板类可以用作基类，也可用作组件类，还可用作其他模板的类型参数。 递归使用模板 使用多个类型参数 12345678910template &lt;typename T1, typename T2&gt;class Pair&#123;private: T1 a; T2 b;public: T1&amp; first(); T2&amp; second(); ...&#125;; 默认模板参数 可以为类型参数提供默认值：1template &lt;class T1, class T2 = int&gt; class Topo&#123;...&#125;; 14.4.6 模板的具体化模板以泛型的方式描述类，而具体化是使用具体的类型生成类声明。 隐式实例化（implicit instantiation） &emsp;&emsp;声明一个或多个对象，指出所需的类型，编译器使用通用模板提供的处方生成具体的类定义： 1ArrayTP&lt;int, 100&gt; stuff; &emsp;&emsp;编译器在需要对象之前，不会生成类的隐式实例化，如下面的代码，第二条语句才会使编译器生成类定义，并根据定义创建一个对象12ArrayTP&lt;double, 30&gt; *pt;pt = new ArrayTP&lt;double, 30&gt;; 显式实例化（explicit instantiation） &emsp;&emsp;当使用关键字template并指出所需类型来声明类时，编译器将生成类声明的显式实例化。在这种情况下，孙然没有创建或提及类对象，编译器也将生成类声明（包括方法定义）。和隐式实例化一样，也将根据通用模板来生成具体化。（这里没搞懂）1template class ArrayTP&lt;string, 100&gt;; 显式具体化（explicit specialization） &emsp;&emsp;显式具体化是特定类型（用于替换模板中的泛型）的定义。有时候，可能需要在为特殊类型实例化时，对模板进行修改，使其行为不同。在这种情况下，可以创建显式具体化。（这块也没看懂） &emsp;&emsp;另外，假设模板是用&gt;运算符来对值进行比较，对于数字，管用。如果T表示一个type，则只要定义了T::operator&gt;()方法，这也管用。但如果T是由const char*表示的字符串，这将不管用。实际上，模板倒是可以正常工作，但字符串将按地址（按照字母顺序）排序。这要求类定义使用strcmp()，而不是&gt;来对值进行比较。 部分具体化（partial specialization） &emsp;&emsp;C++允许部分具体化，即部分限制模板的通用性。例如，可以给类型参数之一指定具体类型，下面的代码将T2具体化为int，但T1保持不变：1234//general templatetemplate &lt;class T1, class T2&gt; class Pair &#123;...&#125;;//specialization with T2 set to inttemplate &lt;class T1&gt; class Pair&lt;T1, int&gt; &#123;...&#125;; 14.4.7 成员模板模板可用作结构、类或模板类的成员。要完全实现STL的设计，必须使用这项特性。 14.4.8 将模板作为参数模板除了可以包含类型参数（typename T）和非类型参数（int n）之外，还可以包含本身就是模板的参数，如下所示：123template &lt;template &lt;typename T&gt; class Thing&gt; class Crab//其中，template&lt;typename T&gt;class是类型，Thin是参数 14.4.9 模板类和友元模板类声明也可以有友元。模板的友元分三类： 非模板友元 1234567template &lt;class T&gt;class HasFriend&#123;public: friend void counts(); //(1) friend void report(HasFriend &amp;); //(2) 错误 friend void report(HasFriend&lt;T&gt; &amp;); //(3) 正确&#125; &emsp;&emsp;上述代码中的（1）式在模板中将一个常规函数声明为友元，该声明使counts()函数成为模板所有实例化的友元，counts()函数不是通过对象调用的（它是友元，不是成员函数），也没有对象参数。它通过以下几种方式访问HasFriend对象：访问全局对象;使用全局指针访问非全局对象;创建自己的对象;访问独立于对象的模板类的静态数据成员。如果要为友元函数提供模板类参数，则不能通过（2）式来达到目的，原因是不存在HasFriend这样的对象，而只有特定的具体化，如HasFriend&lt;short&gt;，这里short可以用T表示，因为参数传递时就会指明T的类型，因此，要提供模板类参数，必须指明具体化。 约束（bound）模板友元，即友元的类型取决于类被实例化时的类型1234567891011//（1）template &lt;typename T&gt; void counts();template &lt;typename T&gt; void reprot(T&amp;);//（2）template &lt;typename T&gt;class HasFriendT&#123; ... friend void counts&lt;TT&gt;(); friend void report&lt;&gt;(HasFriendT&lt;TT&gt; &amp;);&#125;; &emsp;&emsp;使友元本身成为模板，使累得每一个具体化都获得与友元匹配的具体化，包含三步：首先，在类定义之前声明每个模板函数，如（1）所示，然后，在函数中再次将模板声明为友元，声明中的&lt;&gt;指出这是模板具体化，对于report()，&lt;&gt;可以为空，因为可以从函数参数推断出如下模板类型参数：HasFriendT&lt;TT&gt;，也可以写完整：report&lt;HasFriendT&lt;TT&gt; &gt; (HasFriendT&lt;TT&gt; &amp;)。但counts函数没有参数，因此必须使用模板参数语法&lt;TT&gt;来指明具体化。最后一步是友元提供模板定义。 非约束（unbound）模板友元，即友元的所有具体化都是类的每一个具体化的方式 12345template &lt;typename T&gt;class ManyFriend&#123; ... template &lt;typename C, typename D&gt; friend void show2(C&amp;, D&amp;);&#125;; &emsp;&emsp;对于非约束友元，友元模板类型参数与模板类类型参数是不同的，如上代码所示。 14.4.10 模板别名（C++11）可以使用typedef为模板具体化指定别名：1234567//define three typedef aliasestypedef std::array&lt;double,12&gt; arrd;typedef std::array&lt;int, 12&gt; arri;typedef std:array&lt;std::string,12&gt; arrst;arrd gollons;arri days;arrst months; C++11提供了一种新的可以简化上述任务的方法——使用模板提供一系列别名，如下所示：123456template&lt;typename T&gt; using arrtype = std::array&lt;T,12&gt;;//这将arrtype定义为一个模板别名，可以使用它来指定类型，如下所示arrtype&lt;double&gt; gallons;arrtype&lt;int&gt; days;arrtype&lt;std::string&gt; months;//总之， arrtype&lt;T&gt; 就表示类型 std::array&lt;T,12&gt;]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深入应用C++11——代码优化与工程级应用》]]></title>
    <url>%2Fz_post%2FCpp-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%B7%B1%E5%85%A5%E5%BA%94%E7%94%A8Cpp11%2F</url>
    <content type="text"><![CDATA[第一章 使用C++11让程序更简洁、更现代1.1 类型推导C++11引入了auto和decltype关键字实现类型推导。 1.1.1 auto类型推导1、auto关键词的新意义auto 可用于隐式类型定义。 不同于Python等动态类型语言（运行时才确定数据类型），隐式类型定义的类型推导发生在编译器。（C++是静态类型语言） 使用auto声明的变量必须立刻初始化，以让编译器推断出它的实际类型，并在 编译 时将auto占位符替换为真正的类型。 2、auto的推导规则 当不声明为指针或引用时，auto的推导结果会将初始化表达式的引用和cv限定符抛弃 当声明为指针或引用时，auto的推导结果将保持初始化表达式的cv属性。 3、auto的限制 auto不能用于函数参数 auto不能用于非静态成员变量 auto无法定义数组 auto无法推导出模板参数 4、什么时候用auto 当类型的名称很长时，可以用auto简化代码 当不确定变量应用被定义成什么类型时，如泛型函数的参数类型。 注意： auto虽然好用，但是不应该过度使用，否则，会严重降低代码的可读性和可维护性。 1.1.2 decltype1、获知表达式的类型 decltype关键字用于在编译时推导出一个表达式的类型，其语法格式为decltype(exp)，该关键字并不会真正计算表达式的值。 2、decltype的推导规则 当exp是标识符、类访问表达式时，decltype(exp)和exp的类型一致 当exp是函数调用时，decltype(exp)和返回值的类型一致 其他情况，若exp是一个左值，则decltype(exp)是exp类型的左值 引用 ，否则和exp类型一致。 3、decltype的实际应用 decltype的应用多出现在泛型编程中。 decltype也经常用在通过变量表达式抽取变量类型上。 1.1.3 返回类型后置语法——auto和decltype的结合使用]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的左值、右值、右值引用解析]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84%E5%B7%A6%E5%80%BC_%E5%8F%B3%E5%80%BC_%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[左值、右值C++11对C++98中的右值进行了扩充。在C++11中右值又分为纯右值（prvalue，Pure Rvalue）和将亡值（xvalue，eXpiring Value）。 在C++11中可以取地址的的就是左值，反之，不能取地址的、没有名字的就是右值（将亡值或纯右值）。举个例子，int a = b+c, a 就是左值，其有变量名为a，通过&amp;a可以获取该变量的地址；表达式b+c、函数int func()的返回值是右值，在其被赋值给某一变量前，我们不能通过变量名找到它，＆(b+c)这样的操作则不会通过编译。 纯右值的概念等同于我们在C++98标准中右值的概念，指的是临时变量和不跟对象关联的字面量值； 左值与右值的根本区别在于是否允许取地址&amp;运算符获得对应的内存地址 将亡值则是C++11新增的跟右值引用相关的表达式，这样表达式通常是将要被移动的对象（移为他用），比如返回右值引用T&amp;&amp;的函数返回值、std::move的返回值，或者转换为T&amp;&amp;的类型转换函数的返回值。右值引用本身就是一个xvalue。 不能根据在等号左边还是右边来判断左值和右值左值出现在等号右边的情况：12int a = 2;int c = a; 右值出现在等号左边的情况（不能作为赋值的对象，赋值没有意义）：1((i&gt;0) ? i : j) = 1; 右值、将亡值在理解C++11的右值前，先看看C++98中右值的概念：C++98中右值是纯右值，纯右值指的是临时变量值、不跟对象关联的字面量值。临时变量指的是非引用返回的函数返回值、表达式等，例如函数int func()的返回值，表达式a+b；不跟对象关联的字面量值，例如true，2，”C”等。 将亡值可以理解为通过“盗取”其他变量内存空间的方式获取到的值。在确保其他变量不再被使用、或即将被销毁时，通过“盗取”的方式可以避免内存空间的释放和分配，能够延长变量值的生命期。 左值引用、右值引用左值引用就是对一个左值进行引用的类型。右值引用（C++11新特性）就是对一个右值进行引用的类型，事实上，由于右值通常不具有名字，我们也只能通过引用的方式找到它的存在。 右值引用和左值引用都是属于引用类型。无论是声明一个左值引用还是右值引用，都必须立即进行初始化。而其原因可以理解为是引用类型本身自己并不拥有所绑定对象的内存，只是该对象的一个别名。左值引用是具名变量值的别名，而右值引用则是不具名（匿名）变量的别名。 左值引用通常也不能绑定到右值，但 常量左值引用 是个“万能”的引用类型。它可以接受非常量左值、常量左值、右值对其进行初始化。不过常量左值所引用的右值在它的“余生”中只能是只读的。相对地，非常量左值只能接受非常量左值对其进行初始化。 1234567int &amp;a = 2; # 左值引用绑定到右值，编译失败int b = 2; # 非常量左值const int &amp;c = b; # 常量左值引用绑定到非常量左值，编译通过const int d = 2; # 常量左值const int &amp;e = d; # 常量左值引用绑定到常量左值，编译通过const int &amp;&amp;b =2; # 常量左值引用绑定到右值，编程通过 右值引用本质上也是一种引用，只是它必须且只能绑定在右值上。由于右值引用只能绑定在右值上，而右值要么是字面常量，要么是临时对象，所以： 右值引用的对象，是临时的，即将被销毁 右值引用的对象，不会在其他地方使用 这两个特性意味着：接受和使用右值引用的代码，可以自由的接管所引用对象的资源，而无需担心对其他代码逻辑造成数据破坏 右值值引用通常不能绑定到任何的左值，要想绑定一个左值到右值引用，通常需要std::move()将左值强制转换为右值，例如： 123456int a=2;int b=1;int &amp;&amp;r1 = 3; //编译通过，右值引用可以绑定到字面常量上int &amp;&amp;r2 = a+b; //编译通过，右值引用可以绑定到临时变量上int &amp;&amp;r3 = a; # 编译失败int &amp;&amp;r4 = std::move(a); # 编译通过 右值引用本身是左值右值引用本身是左值，通过下面的代码，我们发现，可以通过右值引用的名字得到他的地址，因此，右值引用本身就是左值：12int&amp;&amp; r1 = 2;std::cout&lt;&lt;&amp;r1; //编译通过，输出r1的地址 下表列出了在C++11中各种引用类型可以引用的值的类型。值得注意的是，只要能够绑定右值的引用类型，都能够延长右值的生命期。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译型语言、解释型语言、静态类型语言、动态类型语言的概念与区别]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E7%BC%96%E8%AF%91%E5%9E%8B%E8%AF%AD%E8%A8%80%E3%80%81%E8%A7%A3%E9%87%8A%E5%9E%8B%E8%AF%AD%E8%A8%80%E3%80%81%E9%9D%99%E6%80%81%E7%B1%BB%E5%9E%8B%E8%AF%AD%E8%A8%80%E3%80%81%E5%8A%A8%E6%80%81%E7%B1%BB%E5%9E%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[编译型语言和解释型语言1、编译型语言需通过编译器（compiler）将源代码编译成机器码，之后才能执行的语言。一般需经过编译（compile）、链接（linker）这两个步骤。编译是把源代码编译成机器码，链接是把各个模块的机器码和依赖库串连起来生成可执行文件。 优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。 缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。 代表语言：C、C++、Pascal、Object-C以及最近很火的苹果新语言swift 2、解释型语言解释性语言的程序不需要编译，相比编译型语言省了道工序，解释性语言在运行程序的时候才逐行翻译。 优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。 缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。 代表语言：JavaScript、Python、Erlang、PHP、Perl、Ruby 3、混合型语言既然编译型和解释型各有缺点就会有人想到把两种类型整合起来，取其精华去其糟粕。就出现了半编译型语言。比如C#,C#在编译的时候不是直接编译成机器码而是中间码，.NET平台提供了中间语言运行库运行中间码，中间语言运行库类似于Java虚拟机。.net在编译成IL代码后，保存在dll中，首次运行时由JIT在编译成机器码缓存在内存中，下次直接执行（博友回复指出）。 Java先生成字节码再在Java虚拟机中解释执行。 严格来说混合型语言属于解释型语言。C#更接近编译型语言。 动态语言和静态语言1、动态语言是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。通俗点说就是在运行时代码可以根据某些条件改变自身结构。 主要动态语言：Object-C、C#、JavaScript、PHP、Python、Erlang。 2、静态语言与动态语言相对应的，运行时结构不可变的语言就是静态语言。如Java、C、C++。 3、注意：很多人认为解释型语言都是动态语言，这个观点是错的！Java是解释型语言但是不是动态语言，Java不能在运行的时候改变自己结构。反之成立吗？动态语言都是解释型语言。也是错的！Object-C是编译型语言，但是他是动态语言。得益于特有的run time机制（准确说run time不是语法特性是运行时环境，这里不展开）OC代码是可以在运行的时候插入、替换方法的。 C#也是动态语言，通过C#的反射机制可以动态的插入一段代码执行。 动态类型语言和静态类型语言1、动态类型语言很多网上资料把动态类型语言和动态语言混为一谈，简直是误人子弟。动态类型语言和动态语言是完全不同的两个概念。动态类型语言是指在运行期间才去做数据类型检查的语言，说的是数据类型，动态语言说的是运行时改变结构，说的是代码结构。 动态类型语言的数据类型不是在编译阶段决定的，而是把类型绑定延后到了运行阶段。（Python只有到了运行时才能确定某一个变量的具体类型） 主要语言：Python、Ruby、Erlang、JavaScript、swift、PHP、Perl。 2、静态类型语言 静态语言的数据类型是在编译其间确定的或者说运行之前确定的，是在编译阶段就完成的，编写代码的时候要明确确定变量的数据类型。 主要语言：C、C++、C#、Java、Object-C。 3、注意：相当一部分程序员，认为解释型语言都是动态类型语言，编译型语言都是静态类型语言。这个也是错的。swift是编译型语言但是它也是动态类型语言。C#和Java是解释型语言也是静态类型语言。 强类型语言和弱类型语言1、强类型语言：强类型语言，一旦一个变量被指定了某个数据类型，如果不经过强制类型转换，那么它就永远是这个数据类型。你不能把一个整形变量当成一个字符串来处理。 主要语言：Java、C#、Python、Object-C、Ruby 2、弱类型语言：数据类型可以被忽略，一个变量可以赋不同数据类型的值。一旦给一个整型变量a赋一个字符串值，那么a就变成字符类型。 主要语言：JavaScript、PHP、C、C++（C和C++有争议，但是确实可以给一个字符变量赋整形值，可能初衷是强类型，形态上接近弱类型） 3、注意：一个语言是不是强类型语言和是不是动态类型语言也没有必然联系。Python是动态类型语言，是强类型语言。JavaScript是动态类型语言，是弱类型语言。Java是静态类型语言，是强类型语言。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98-%E5%89%91%E6%8C%87offer%2F</url>
    <content type="text"><![CDATA[1. 二维数组中的查找题目描述在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数 2. 替换空格3.从尾到头打印链表4.重建二叉树5.用两个栈实现队列6.旋转数组的最小数字7.斐波那契数列8.跳台阶9.变态跳台阶10.矩形覆盖11.二进制中1的个数12.数值的整数次方13.调整数组顺序使奇数位于偶数前面14.链表中倒数第k个节点15.反转链表16.合并两个排序的链表17.树的子结构18.二叉树的镜像19.顺时针打印矩阵20.包含min函数的栈21.栈的压入、弹出序列22.从上往下打印二叉树23.二叉搜索树的后序遍历序列24.二叉树中和为某一值的路径25.复杂链表的复制题目描述输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空） 注意链表的复制不同于其他复制，在进行链表复制时，必须创建新的节点，同时，不能通过newnode-&gt;next = oldnode-next对新节点进行赋值，这是因为这样赋值会使新链表指向旧链表的节点，造成混乱。 正确解题思路： 先对原链表中的每一个节点进行复制，将复制的节点插入到原节点之后，比如原链表是A-&gt;B-&gt;C，则复制后应该变成A-&gt;A1-&gt;B-&gt;B1-&gt;C-&gt;C1。 再按照原始链表中随机指针的指向，对新节点的随机指针进行赋值。 将链表拆分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/*struct RandomListNode &#123; int label; struct RandomListNode *next, *random; RandomListNode(int x) : label(x), next(NULL), random(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: RandomListNode* Clone(RandomListNode* pHead) &#123; if(pHead==NULL) return NULL; //少考虑这种情况会发生段错误 RandomListNode* curnode = pHead; //C++允许在声明结构变量时省略关键字struct，但是C不允许 while(curnode!=NULL)&#123; RandomListNode* clonenode = new RandomListNode(curnode-&gt;label); clonenode-&gt;next = curnode-&gt;next; curnode-&gt;next = clonenode; curnode = clonenode-&gt;next; &#125; curnode = pHead; while(curnode!=NULL)&#123; if(curnode-&gt;random!=NULL)&#123; //少考虑这种情况会不满足个别用例 curnode-&gt;next-&gt;random = curnode-&gt;random-&gt;next; curnode = curnode-&gt;next-&gt;next; &#125; else&#123; curnode-&gt;next-&gt;random = NULL; curnode = curnode-&gt;next-&gt;next; &#125; &#125; curnode = pHead; RandomListNode* newhead = pHead-&gt;next; RandomListNode* newcur = pHead-&gt;next; while(curnode!=NULL)&#123; if(newcur-&gt;next == NULL)&#123; curnode-&gt;next = NULL; break; &#125; curnode-&gt;next = newcur-&gt;next; newcur-&gt;next = newcur-&gt;next-&gt;next; curnode = curnode-&gt;next; newcur = newcur-&gt;next; &#125; return newhead; &#125;&#125;; 26.二叉搜索树与双向链表题目描述输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的节点，只能调整树中结点指针的指向。 解法一：自己的思路后序遍历，递归实现，首先将左子树全部变成有序的，然后将右子树全部变成有序的。由于在返回时，返回的是左右子树的根节点，因此，在将当前根节点与左右子树拼接时，需要移动到左子树的最后一个元素上（最大），与当前根节点的left拼接。对于右子树，要移动到右子树的第一个元素上（最小），与当前根节点的right拼接。 这里有一个需要注意的地方，以下两种声明方式，指针一定要初始化之后才能使用，会使代码结果表现不同，前者超时，后者通过 12TreeNode* pre=nullptr,* next=nullptr;TreeNode* pre,* next; 123456789101112131415161718192021222324252627282930313233343536373839404142/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: TreeNode* Convert(TreeNode* pRootOfTree) &#123; if(pRootOfTree==nullptr) return nullptr; TreeNode* node = recurve(pRootOfTree); while(node-&gt;left!=nullptr) node = node-&gt;left; return node; &#125; TreeNode* recurve(TreeNode* pRootOfTree)&#123; TreeNode* pre=nullptr,* next=nullptr; // 这里，如果没有指定nullptr，则程序会超时！！！ if(nullptr!=pRootOfTree-&gt;left) pre = recurve(pRootOfTree-&gt;left); if(nullptr!=pRootOfTree-&gt;right) next = recurve(pRootOfTree-&gt;right); if(pre!=nullptr)&#123; while(pre-&gt;right!=nullptr) pre=pre-&gt;right; pRootOfTree-&gt;left = pre; pre-&gt;right = pRootOfTree; &#125; if(next!=nullptr)&#123; while(next-&gt;left!=nullptr) next = next-&gt;left; pRootOfTree-&gt;right = next; next-&gt;left = pRootOfTree; &#125; return pRootOfTree; &#125;&#125;; 解法二：中序遍历，递归实现由于对搜索二叉树来说，中序遍历的结果就是有序的，因此，只需要通过维护一个prenode指针来标记当前节点的上一个节点即可完成双向有序链表。 注意，这里有一个非常关键的点，那就是TreeNode*&amp; prenode，如果少了&amp;引用标识，则结果错误！具体原因看文章关于*&amp;和*的联系和区别。12345678910111213141516171819202122232425262728293031323334/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: TreeNode* Convert(TreeNode* pRootOfTree) &#123; if(pRootOfTree==nullptr) return nullptr; TreeNode* prenode = nullptr; recurve(pRootOfTree,prenode); while(pRootOfTree-&gt;left!=nullptr) pRootOfTree = pRootOfTree-&gt;left; return pRootOfTree; &#125; void recurve(TreeNode* root, TreeNode*&amp; prenode)&#123; if(root-&gt;left!=nullptr) recurve(root-&gt;left,prenode); root-&gt;left = prenode; if(prenode!=nullptr) prenode-&gt;right = root; prenode = root; if(root-&gt;right!=nullptr) recurve(root-&gt;right,prenode); &#125;&#125;; 解法三：中序遍历，非递归实现基于中序遍历的非递归方法，思路与解法二一致。 但是这里有个疑问，为什么使用下面的代码会发生段错误。123while(pRootOfTree-&gt;left!=nullptr) pRootOfTree = pRootOfTree-&gt;left;return pRootOfTree; 以下代码额外设置了一个指针指向第一个节点，以避免使用上面代码带来的段错误。 123456789101112131415161718192021222324252627282930313233343536373839/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: stack&lt;TreeNode*&gt; S_node; TreeNode* Convert(TreeNode* pRootOfTree) &#123; TreeNode* P = pRootOfTree; TreeNode* node = pRootOfTree; TreeNode* pre = nullptr; while(P!=nullptr||!S_node.empty())&#123; while(P!=nullptr)&#123; S_node.push(P); P = P-&gt;left; &#125; if(!S_node.empty())&#123; P = S_node.top(); P-&gt;left = pre; if(pre!=nullptr)&#123; pre-&gt;right = P; &#125;else node = P; pre = P; S_node.pop(); P = P-&gt;right; &#125; &#125; //while(pRootOfTree-&gt;left!=nullptr)&#123; // pRootOfTree = pRootOfTree-&gt;left; return node; &#125;&#125;; 27.字符串的排列题目描述输入一个字符串，按字典序打印出该字符串中字符的所有排列。例如输入字符串abc，则打印出由字符a，b，c所能排列出来的所有字符串abc，acb，bac，cab和cab。 思路（没想到）：将一个字符串看成两个部分，前一部分为首位字母，剩下的是后一部分。通过将首位字母与后一部分的所有字符交换（包括跟自己交换），可以得到第一个位置的所有可能情况。然后，再将剩下的部分看作是一个新的字符串，同样将剩余部分分成两部分，其中，第一部分是剩余部分的首位。如此，可以按照递归进行处理。 123456789101112131415161718192021222324252627282930class Solution &#123;public: //bool my_sort(string s1, string s2)&#123; return s1&lt;s2;&#125;; vector&lt;string&gt; Permutation(string str) &#123; vector&lt;string&gt; v_string; if(str=="") return v_string; PermutationHelp(v_string, 0, str); std::sort(v_string.begin(), v_string.end()); return v_string; &#125; void PermutationHelp(vector&lt;string&gt;&amp; v_string, int pos, string str)&#123; /* if(pos == 0 )&#123; v_string.push_back(str); PermutationHelp(v_string, pos+1, str); &#125; * / //这里i=pos而不是pos+1的原因是：如果用pos+1,会导致丟解，即自己与自己交换的那种情况没有继续向下递归 for(int i=pos; i&lt;str.length(); i++)&#123; std::swap(str.at(pos), str.at(i)); if(std::count(v_string.begin(), v_string.end(), str) == 0) v_string.push_back(str); PermutationHelp(v_string, pos+1, str); //std::swap(str.at(pos), str.at(i)); //注释本行的原因是因为，这里，由于，我们只需要将后面的n-1中字符依次置换到首位，因此，无须在置换后进行还原再置换，直接进行置换即可 &#125; &#125;&#125;; 28.数组中出现次数超过一半的数字题目描述：数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出2。如果不存在则输出0。 思路一：如果数组是有序的，那么，出现次数超过数组长度一半的数字一定位于数组的中间位置，如果中间位置的数字出现次数小于数组长度的一半，那么就不存在。该方法需要进行排序，所以算法时间复杂度为 $nlog(n)$ 。1234567891011121314class Solution &#123;public: int MoreThanHalfNum_Solution(vector&lt;int&gt; numbers) &#123; //bool mysort(int a, int b) &#123;return a&lt;b;&#125; vector&lt;int&gt; counts; std::sort(numbers.begin(), numbers.end()); int n = std::count(numbers.begin(), numbers.end(), numbers.at((int)numbers.size()/2)); if (n &gt; numbers.size()/2) return numbers.at((int)numbers.size()/2); else return 0; &#125;&#125;; 思路二：根据快排的思想，由于该数字一定在数组的中间位置，那么可以借助Partition来实现，随机选一个数字进行Partition，如果返回的mid索引最终停在N/2处，那么该索引对应的数字就有可能是答案，此时，只需统计该数字的出现次数即可。 该方法的时间复杂度是 $O(n)$ ，因为只会执行一边的Partition，并不会执行另一边。 需要注意，具体在代码中看 12345678910111213141516171819202122232425262728293031323334353637383940414243bool mysort(int a, int b) &#123;return a&lt;b;&#125;class Solution &#123;public: int MoreThanHalfNum_Solution(vector&lt;int&gt; numbers) &#123; int low = 0 ; int high = numbers.size()-1; int mid = Partition(numbers, low, high); while(mid != numbers.size()/2)&#123; if(mid &lt; numbers.size()/2)&#123; low = mid + 1; mid = Partition(numbers, low, high); &#125;else&#123; high = mid - 1; mid = Partition(numbers,low, high); &#125; &#125; if(std::count(numbers.begin(), numbers.end(), numbers.at(mid)) &gt; numbers.size()/2) return numbers.at(mid); else return 0; &#125; int Partition(vector&lt;int&gt;&amp; numbers, int low, int high)&#123; int p = numbers.at(low); int mid = low; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; p &lt; numbers.at(high)) high--; //这里如果p用的是&lt;,则需要下面的low++逻辑，否则，会陷入死循环，如果用的是&lt;=，则在返回时，会返回首个元素的坐标 numbers.at(low) = numbers.at(high); if(low!=high) low++; while(low&lt;high &amp;&amp; p &gt; numbers.at(low)) low++; numbers.at(high) = numbers.at(low); if(low!=high) high--; &#125; numbers.at(low) = p; if(low == high) return mid; else return low; &#125;&#125;; 思路三： 如果数组中存在这样一个数，那么这个数的出现次数一定大于其他所有数的出现次数总和，因此，设置两个变量，一个number用来存储数组中的第一个数，另一个num置为1,如果下一个数与number数相同，则num加一，否则减1,如果num被减为0,那么number转而存储下一个数，同时将num置为1。 这样，如果存在这个数，最终这个数一定为number，且num大于1。 1234567891011121314151617181920class Solution &#123;public: int MoreThanHalfNum_Solution(vector&lt;int&gt; numbers) &#123; int number = numbers.at(0); int num = 1; for(vector&lt;int&gt;::iterator iter = numbers.begin()+1; iter != numbers.end(); iter++)&#123; if(num == 0)&#123; //这里与下面的区别之一是，一定要放在for训练内部的前面 number = *(iter-1); //区别之二这里如果使用iter-1,则无须在最后做count检查 num = 1; &#125; if(number == *iter) num++; else num--; &#125; if(num &gt;= 1) return number; //这里，num只需要&gt;=1 即可，仔细想一想这是为什么，为啥用了iter-1,就不用检查count。 else return 0; &#125;&#125;; 1234567891011121314151617181920class Solution &#123;public: int MoreThanHalfNum_Solution(vector&lt;int&gt; numbers) &#123; int number = numbers.at(0); int num = 1; for(vector&lt;int&gt;::iterator iter = numbers.begin(); iter != numbers.end(); iter++)&#123; if(number == *iter) num++; else num--; if(num == 0)&#123; number = *iter; num = 1; &#125; &#125; if(count(numbers.begin(), numbers.end(), number) &gt; numbers.size()/2) return number; //由于上面用的是iter，所以最终的num为1的数，只是有可能是我们要得数字，因此，需要进行检查。 else return 0; &#125;&#125;; 29.最小的K个数题目描述：输入n个整数，找出最小的K个数，例如输入4,5,1,6,2,7,3,8，则输出1,2,3,4。 一定要考虑边界情况： 数组为空 k大于数组size k小于0 思路一：最直接的想法，就是先对数组排序，然后输出前k个数。复杂度为 $nlog(n) + n$ 。 快排12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k) &#123; vector&lt;int&gt; k_input; if(k &gt; input.size() || input.size()&lt;=0) return k_input; int low = 0; int high = input.size()-1; quickSort(input, low, high); //vector&lt;int&gt; k_input(&amp;input.at(0), &amp;input.at(k-1)); for(int i=0; i&lt;k; i++) k_input.push_back(input.at(i)); return k_input; &#125; void quickSort(vector&lt;int&gt;&amp; input, int low, int high)&#123; int mid = Partition(input, low, high); if(mid&lt;high) quickSort(input, mid+1, high); if(mid&gt;low) quickSort(input, low, mid-1); &#125; int Partition(vector&lt;int&gt;&amp; input, int low, int high)&#123; int p = input[low]; while(low&lt;high)&#123; while(low&lt;high &amp;&amp; p&lt;=input[high]) high--; input[low] = input[high]; while(low&lt;high &amp;&amp; p&gt;=input[low]) low++; input[high] = input[low]; &#125; input[low] = p; return low; &#125;&#125;; 思路二：遍历整个数组，将当前元素与k_input数组进行比较，按照顺序插入，并且超出k的部分删除，最终直接返回k_input。时间复杂度 $O(nk)$ 。（该思想与冒泡排序思想类似）。12345678910111213141516171819202122class Solution &#123;public: vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k) &#123; vector&lt;int&gt; k_input; if(k&gt;input.size() || input.size()&lt;=0) return k_input; k_input.push_back(input.at(0)); for(auto iter = input.begin()+1; iter!=input.end(); iter++)&#123; for(int i =0 ;i&lt;k; i++)&#123; if(i == k_input.size())&#123; k_input.push_back(*iter); break; &#125;else if(*iter &lt; k_input.at(i))&#123; k_input.insert(k_input.begin()+i, *iter); break; &#125; &#125; if(k_input.size() &gt; k) k_input.pop_back(); &#125; return k_input; &#125;&#125;; 30.连续子数组的最大和题目描述HZ偶尔会拿些专业问题来忽悠那些非计算机专业的同学。今天测试组开完会后,他又发话了:在古老的一维模式识别中,常常需要计算连续子向量的最大和,当向量全为正数的时候,问题很好解决。但是,如果向量中包含负数,是否应该包含某个负数,并期望旁边的正数会弥补它呢？例如:{6,-3,-2,7,-15,1,2,2},连续子向量的最大和为8(从第0个开始,到第3个为止)。给一个数组，返回它的最大连续子序列的和，你会不会被他忽悠住？(子向量的长度至少是1) 解法一：穷举遍历，时间复杂度 $O(n^2)$ 。 1234567891011121314151617class Solution &#123;public: int FindGreatestSumOfSubArray(vector&lt;int&gt; array) &#123; int max=array.at(0); for(auto iter=array.begin(); iter!=array.end(); iter++)&#123; //if(*iter &gt; 0)&#123; int temp = 0; for(auto it = iter; it!=array.end(); it++)&#123; temp += *it; if(temp &gt; max) max = temp; //&#125; &#125; &#125; return max; &#125;&#125;; 解法二：$O(n)$ 的方法，根据数组性质，设置两个变量，一个记录当前的最大值，一个记录当前的子序列之和。首先，如果当前子序列之和为负，那么就是说，从当前位置开始的子序列，比从之前位置开始的子序列大，那么就可以不考虑从之前位置开始的子序列，之前累计的和也被抛弃。 12345678910111213141516171819class Solution &#123;public: int FindGreatestSumOfSubArray(vector&lt;int&gt; array) &#123; int max = array.at(0); int s = array.at(0); for(auto iter = array.begin()+1; iter!=array.end(); iter++)&#123; if(s&lt;0)&#123; s = * iter; &#125;else&#123; s += * iter; &#125; if( max &lt; s)&#123; max = s; &#125; &#125; return max; &#125;&#125;; 解法三：动态规划。与解法二的思路异曲同工，核心思想可有下述公式表示。 $f(i)代表以第i个数字结尾的子数组的连续最大和$ f(x)= \begin{cases} pData[i]& {i=0 或者f(i-1)\le 0} \\ f(i-1)+pData[i]& {i\ne 0 并且 f(i-1) > 0} \end{cases}上面的形式是递归的，通常情况下都用递归的方式来分析动态规划问题，但最终都会基于循环去编码。 上述公式对应的非递归形式就是思路二的代码。 递归写法：1234567891011121314151617181920class Solution &#123;public: int FindGreatestSumOfSubArray(vector&lt;int&gt; array) &#123; int max = array.at(0); f(array, array.size()-1, max); return max; &#125; int f(vector&lt;int&gt;&amp; array, int i, int&amp; max)&#123; if(i==0) return array.at(0); int f1 = f(array, i-1, max); if(f1&lt;0) f1 = array.at(i); else&#123; f1 = f1+ array.at(i); &#125; if(f1&gt; max) max =f1; return f1; &#125;&#125;; 31.整数中1出现的次数（从1到整数n中1出现的次数）题目描述求出1~13的整数中1出现的次数,并算出100~1300的整数中1出现的次数？为此他特别数了一下1~13中包含1的数字有1、10、11、12、13因此共出现6次,但是对于后面问题他就没辙了。ACMer希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数（从1 到 n 中1出现的次数）。 解法一：直接借助C++函数，先将int转换成string，然后count计算string里面‘1’的个数。（这种方法可能面试不会满意，可以提一下，不过肯定有其他方法） 12345678910111213class Solution &#123;public: int NumberOf1Between1AndN_Solution(int n) &#123; int count_1 = 0 ; for(int i = 1; i&lt;=n; i++)&#123; string str = std::to_string(i); count_1 += std::count(str.begin(), str.end(), '1'); &#125; return count_1; &#125;&#125;; 解法二：对每个数字进行除和求余的运算，得到每个数字中1的个数，然后将个数相加。 该方法的复杂度为 $O(nlogn)$ ，该种思想过于直接，时间复杂度较高，属于次等方案。（注意：这里的log底数按理说是10 ，但说大O记法是不考虑常数的，所以直接表示成log就可以） 123456789101112131415161718192021222324class Solution &#123;public: int NumberOf1Between1AndN_Solution(int n) &#123; int count =0 ; for(int i =1 ;i&lt;=n;i++)&#123; int i1 = has1(i); if(i1) count+=i1; &#125; return count; &#125; int has1(int num)&#123; int count=0; while(num)&#123; if(num%10 == 1) count++; num /= 10; &#125; return count; &#125;&#125;; 解法三：设定整数点（如1、10、100等等）作为位置点i（对应n的各位、十位、百位等等），分别对每个数位上为1的情况有多少种进行分析 根据设定的整数位置，对n进行分割，分为两部分，高位n/i，低位n%i 当i表示百位，且百位对应的数&gt;=2时,如n=31456,i=100，则a=314,b=56，此时百位为1的情况有a/10+1=32（最高两位0~31，百位为1,共32种），每一种都包含100个连续的点，即共有(a%10+1) * 100种情况百位为1 当i表示百位，且百位对应的数为1时，如n=31156， i=100，则a=311,b=56，此时百位对应的就是1，则共有a%10(最高两位0-30)种情况是包含100个连续点，当最高两位为31（即a=311），本次只对应部分情况00~56，共b+1种，所有点加起来共有（a%10*100）+(b+1)种情况可以是百位为1 当i表示百位，且百位对应的数为0,如n=31056,i=100，则a=310,b=56，此时百位为1的情况有a/10=31种（最高两位0~30） 综合以上三种情况，当百位对应0或&gt;=2时，有(a+8)/10次包含所有100个点，当百位为1时，有(a%10==1)种，另外需要增加部分情况b+1种 之所以补8，是因为当百位为0，则a/10==(a+8)/10，当百位&gt;=2，补8会产生进位位，效果等同于(a/10+1) 123456789101112131415class Solution &#123;public: int NumberOf1Between1AndN_Solution(int n) &#123; int count = 0; for(int i =1; i&lt;=n; i*=10)&#123; int a = n/i; int b = n%i; count+=(a+8)/10*i+(int)(a%10==1)*(b+1); &#125; return count; &#125;&#125;; 解法四：剑指offer的递归方法，没看懂，感觉好像有错误？ 32.把数组排成最小的数题目描述：输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。 难点： 找出一个新的排序规则，同时要证明这个排序规则是有效的 看到将两个int整数拼接在一起，就应该想到大数问题 解法一：主要考虑如何制定一个合理的判断规则： 比较两个字符串s1, s2大小的时候，先将它们拼接起来，比较s1+s2,和s2+s1那个大，如果s1+s2大，那说明s2应该放前面，所以按这个规则，s2就应该排在s1前面。 基于上面的规则，首先将vector&lt;int&gt;转换成对应的vector&lt;string&gt;，然后直接利用快排进行排序，最后将排好序的字符串向量拼接输出。 时间复杂度为主要在排序，因此为 $O(nlogn)$ 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Solution &#123;public: string PrintMinNumber(vector&lt;int&gt; numbers) &#123; if(numbers.size() == 0) return ""; vector&lt;string&gt; str_numbers; for(auto it=numbers.begin(); it!=numbers.end(); it++)&#123; str_numbers.push_back(std::to_string(*it)); &#125; int low =0; int high = numbers.size()-1; quickSort(str_numbers, low, high); string s=""; for(auto it = str_numbers.begin(); it != str_numbers.end(); it++)&#123; s+=*it; &#125; return s; &#125; void quickSort(vector&lt;string&gt;&amp; str_numbers, int low , int high)&#123; int mid = Partition(str_numbers, low, high); if(mid&lt;high) quickSort(str_numbers,mid+1, high); if(mid&gt;low) quickSort(str_numbers, low, mid-1); &#125; int Partition(vector&lt;string&gt;&amp; str_numbers, int low, int high)&#123; string p = str_numbers.at(low); while(low&lt;high)&#123; string s1= p + str_numbers.at(high); string s2= str_numbers.at(high) + p; while(low&lt;high &amp;&amp; s1.compare(s2) &lt;=0)&#123; high--; s1 = p + str_numbers.at(high); s2 = str_numbers.at(high) + p; &#125; str_numbers.at(low) = str_numbers.at(high); if(high&gt;low) low++; s1 = p + str_numbers.at(low); s2 = str_numbers.at(low) + p; while(low&lt;high &amp;&amp; s1.compare(s2) &gt;=0)&#123; low++; s1 = p + str_numbers.at(low); s2 = str_numbers.at(low) + p; &#125; str_numbers.at(high) = str_numbers.at(low); if(high&gt;low) high--; &#125; str_numbers.at(low) = p; return low; &#125;&#125;; 33.丑数题目描述：把只包含质因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含质因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数 解法一：最简单的方法，就是对所有整数进行判断，该方法很容易超时 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int GetUglyNumber_Solution(int index) &#123; int i = 0; int num = 1; int ugly=0; while(i&lt;index)&#123; if(IsUgly(num))&#123; i++; ugly = num; &#125; num++; &#125; num--; return num; &#125; bool IsUgly(int num)&#123; while(num%2==0) num /=2 ; while(num%3==0) num /= 3; while(num%5==0) num /= 5; if(num == 1) return true; else return false; &#125;&#125;; 解法二：用空间换时间，用一个数组将之前的丑数都存起来，然后，在判断下一个丑数时，不用对逐个整数判断，而只是与丑数和2,3,5的乘积进行判断 12345678910111213141516171819202122232425262728293031323334// 使用指针时，一定要千万注意，指针会改变指向地址的值，使得其他指向该地址的指针，其指向的值也跟着变！class Solution &#123;public: int GetUglyNumber_Solution(int index) &#123; int* UglyArray = new int[index]; UglyArray[0] = 1; for(int i = 1 ;i &lt; index; i++)&#123; int *Ugly2 = UglyArray; int *Ugly3 = UglyArray; int *Ugly5 = UglyArray; while(*Ugly2 * 2 &lt;= UglyArray[i-1]) Ugly2++; while(*Ugly3 * 3 &lt;= UglyArray[i-1]) Ugly3++; while(*Ugly5 * 5&lt;= UglyArray[i-1]) Ugly5++; UglyArray[i] = Min(*Ugly2 *2, *Ugly3 *3, *Ugly5 *5); &#125; int num = UglyArray[index-1]; delete[] UglyArray; return num; &#125; int Min(const int&amp; a, const int&amp; b,const int&amp; c)&#123; int x = a&lt;b? a:b; return x&lt;c? x:c; &#125;&#125;; 34.第一次只出现一次的字符题目描述在一个字符串(0&lt;=字符串长度&lt;=10000，全部由字母组成)中找到第一个只出现一次的字符,并返回它的位置, 如果没有则返回 -1（需要区分大小写） 解法一（自想）每遇到一个字符，判断其是否是第一次出现，则将它存在一个vector once里面，如果不是，则判断该字符是否在另一个vector more里面，如果没在，则该once中的该字符转移到mul里面，接着判断下一个字符。最终，输出once里面的首个元素。 该方法时间复杂度为 $O(n^2)$，并不令人满意。 123456789101112131415161718192021222324252627282930class Solution &#123;public: int FirstNotRepeatingChar(string str) &#123; vector&lt;int&gt; once_char; vector&lt;char&gt; mul_char; for(int i = 0; i&lt; str.length();i++)&#123; bool isfirst = true; for(auto it = once_char.begin(); it!=once_char.end(); it++)&#123; if(str[*it] == str[i])&#123; isfirst = false; once_char.erase(it); mul_char.push_back(str[i]); break; &#125; &#125; if(isfirst)&#123; auto mul_it = find(mul_char.begin(), mul_char.end(), str[i]); if(mul_it != mul_char.end()) isfirst = false; &#125; if(isfirst)&#123; once_char.push_back(i); &#125; &#125; if(once_char.empty()) return -1; return once_char.front(); &#125;&#125;; 解法二：牛客借助哈希表，时间复杂度为 $O(n)$。哈希表的构造可以用256大小的数组实现，字符对应的int值可作为哈希表的索引，表内的内容存储了该字符出现的次数。总共需要遍历两次字符串，第一次更新数组内字符出现的次数，第二次找到首个出现次数为1的字符。空间复杂度为 $O(1)$ （256是常数） 123456789101112131415161718class Solution &#123;public: int FirstNotRepeatingChar(string str) &#123; int hash_map[256]; for(int i =0;i&lt;256;i++) hash_map[i] = 0; //若少了初始化数组，则通不过，经过验证，数组默认内部不是0,而是随机数？ //有一种更标准初始化为0的方法，无需显式while循环：int hash_map[256]= &#123;0&#125;; for(int i = 0; i&lt;str.length(); i++)&#123; hash_map[int(str[i])]++; &#125; for(int i = 0; i&lt;str.length(); i++)&#123; if(hash_map[int(str[i])] == 1) return i; &#125; return -1; &#125;&#125;; 35.数组中的逆序对题目描述在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007输入描述: 题目保证输入的数组中没有的相同的数字 数据范围： 对于%50的数据,size&lt;=10^4 对于%75的数据,size&lt;=10^5 对于%100的数据,size&lt;=2*10^5 注意：仔细思考，这道题的P的数量会非常大，对于长度为n的数组，其P值最大可为 $\frac{n(n-1)}{2}$ 个。根据体重给出的数据，n最大可为 $2\times 10^5$ ，因此，P最大为 $\frac{2\times 10^5\times(2\times10^5 -1)}{2} \approx 2\times 10^{10}$,因此，使用int类型的数据时，有可能超过限制。所以，要使用long！ 解法一（自） 暴力求解，时间复杂度 $O(n^2)$ ，这样做肯定不行 解法二（剑指）这里需要注意的几点： 初始化是，将data数据复制到temp中，然后在递归时，将data和temp数组交换传递，可以不用在数组融合时，将temp中的数据复制到data中， 减少计算次数 数组融合时使用的while循环，条件均为 $&lt;=$ 或 $&gt;=$。 每次得到P的一部分时，都进行取余数，可保证P的值不会过大。（但还是要用long型整数） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Solution &#123;public: int InversePairs(vector&lt;int&gt; data) &#123; if (data.size() == 0) return 0; vector&lt;int&gt; temp= data; //int P=0; long P = mergeSort(data,temp, 0, data.size()-1); return P%1000000007; &#125; long mergeSort(vector&lt;int&gt;&amp; data,vector&lt;int&gt;&amp; temp, int first, int last)&#123; int mid = (last - first)/2; mid += first; long inv1=0,inv2=0,inv=0; if(first&lt; last)&#123; //这里，首先temp和data相同，因此对于mergeSort来说，可以顺序颠倒 //此时相当于把temp当前真实数组，而data当作了缓存空间 //经过mergeSort后，data里面数据就是分别排好序的 //所以传向mergeArray时，要把data放前面，把temp放后面 inv1 = mergeSort(temp, data, first, mid); inv2 = mergeSort(temp, data, mid+1, last); inv = mergeArray(data, temp, first, mid, mid+1, last); &#125; return (inv1+inv2+inv)%1000000007; &#125; long mergeArray(vector&lt;int&gt;&amp; data, vector&lt;int&gt;&amp; temp, int first1,int last1,int first2,int last2)&#123; long int inv = 0; int t = last2; int i = last1; int j = last2; while(i&gt;=first1 &amp;&amp; j&gt;=first2)&#123; if(data.at(i) &gt; data.at(j))&#123; temp.at(t) = data.at(i); inv += j-first2+1;; i--; t--; &#125;else&#123; temp.at(t) = data.at(j); j--; t--; &#125; &#125; while(i&gt;=first1)&#123; temp.at(t) = data.at(i); t--; i--; &#125; while(j&gt;=first2)&#123; temp.at(t) = data.at(j); j--; t--; &#125; return inv%1000000007; &#125;&#125;; 36.两个链表的第一个公共节点题目描述输入两个链表，找出它们的第一个公共结点。 解法一：分析公共子节点的特点，首先，是单向链表，因此，从第一个公共子节点开始，后面的都是一样的，所以最好是能从链表的最后一项还是比较。但由于是单向链表，因此只能从头访问，从能访问最后的节点。 就像是先进先出一样 因此，考虑用两个辅助栈来帮助实现～ 1234567891011121314151617181920212223242526272829303132333435/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* FindFirstCommonNode( ListNode* pHead1, ListNode* pHead2) &#123; stack&lt;ListNode*&gt; s1; stack&lt;ListNode*&gt; s2; for(ListNode* cur = pHead1; cur!=nullptr; cur = cur-&gt;next)&#123; s1.push(cur); &#125; for(ListNode* cur = pHead2; cur!=nullptr; cur = cur-&gt;next)&#123; s2.push(cur); &#125; ListNode* firstCN = nullptr; while(!s1.empty() &amp;&amp; !s2.empty())&#123; if(s1.top() == s2.top())&#123; firstCN = s1.top(); s1.pop(); s2.pop(); &#125;else break; &#125; return firstCN; &#125;&#125;; 37.数字在排序数组中出现的次数题目描述统计一个数字在排序数组中出现的次数。 解法一（自想）先利用二分查找找到该数字的下标，然后统计该数字左右两边的相等数的个数，虽然二分查找的时间复杂度为$O(logn)$，但是在对该数左右两边查看相等数个数时，时间复杂度为 $O(n)$，因此，最终的时间复杂度应为 $O(n)$ 。 （这样的复杂度不会让面试官满意） 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int GetNumberOfK(vector&lt;int&gt; data ,int k) &#123; int count = 0; if(data.size() == 0) return count; int index = binarySearch(data, k, 0, data.size()-1); if(index == -1) return count; else&#123; int i = index-1; while(index&lt;data.size() &amp;&amp; data.at(index) == k)&#123; index++; count++; &#125; while(i&gt;=0 &amp;&amp; data.at(i) == k)&#123; i--; count++; &#125; &#125; return count; &#125; int binarySearch(vector&lt;int&gt;&amp; data, int num, int first, int last)&#123; if(first == last)&#123; if(data.at(first) == num) return first; else return -1; &#125; int mid = (first+last)/2; if(data.at(mid) == num) return mid; else if(data.at(mid) &gt; num) return binarySearch(data, num ,first, mid); else return binarySearch(data, num, mid+1, last); &#125;&#125;; 解法二：牛客分析上面的方法，时间复杂度高的主要原因来自于最后的顺序检索。设想一下，如果知道目标数字出现的第一个位置和最后一个位置，是否就不用再进行顺序检索了？ 于是，可以将二分查找算法改成分别查找目标数字的首次出现位置和末次出现位置。也就是说，如果mid上的数字等于num，同时mid-1（mid&gt;0）上的数字不等于num，则mid为首次出现位置，否则，首次出现位置就应该还在前半段，同理，末次出现位置也是相似的道理。 结合以上讨论，将二分查找分成两个函数，分别找首次和末次位置，这样时间复杂度就是 $O(logn)$，无需进行顺序查找。 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123;public: int GetNumberOfK(vector&lt;int&gt; data ,int k) &#123; int count = 0; if(data.size() == 0) return count; int index1 = binarySearchFirst(data, k, 0, data.size()-1); int index2 = binarySearchLast(data, k, 0, data.size()-1); if(index1 == -1 || index2 == -1) return 0; else return index2-index1+1; &#125; int binarySearchFirst(vector&lt;int&gt;&amp; data, int num, int first, int last)&#123; if(first &gt; last) return -1; int mid = (first+last)/2; if(data.at(mid) == num)&#123; if(mid == 0 || data.at(mid-1) != num) return mid; else return binarySearchFirst(data, num ,first, mid-1); &#125; else if(data.at(mid) &gt; num) return binarySearchFirst(data, num ,first, mid-1); else return binarySearchFirst(data, num, mid+1, last); &#125; int binarySearchLast(vector&lt;int&gt;&amp; data, int num, int first, int last)&#123; if(first &gt; last) return -1; int mid = (first+last)/2; if(data.at(mid) == num)&#123; if(mid==last || data.at(mid+1)!=num) return mid; else return binarySearchLast(data, num, mid+1, last); &#125; else if(data.at(mid) &gt; num) return binarySearchLast(data, num ,first, mid-1); else return binarySearchLast(data, num, mid+1, last); &#125;&#125;; 38.二叉树的深度题目描述输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。 解法一（自想）利用BFS广度优先遍历（错了，树没有广度遍历，这个应该叫层次遍历），结合一个专门存储当前节点所处深度的队列实现，最终的树深度，就应该等于广度优先遍层次遍历历最后一个访问节点所处的深度。（因为这肯定是最后一层，也就是最深的一层） 123456789101112131415161718192021222324252627282930313233343536373839/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: int TreeDepth(TreeNode* pRoot) &#123; queue&lt;TreeNode*&gt; BFSqueue; queue&lt;int&gt; depth; if(pRoot!=nullptr)&#123; depth.push(1); BFSqueue.push(pRoot); &#125; int tree_depth = 0; while(!BFSqueue.empty())&#123; TreeNode* curNode = BFSqueue.front(); int cur_depth = depth.front(); depth.pop(); BFSqueue.pop(); if(curNode-&gt;left!=nullptr)&#123; BFSqueue.push(curNode-&gt;left); depth.push(cur_depth+1); &#125; if(curNode-&gt;right!=nullptr)&#123; BFSqueue.push(curNode-&gt;right); depth.push(cur_depth+1); &#125; tree_depth = cur_depth; &#125; return tree_depth; &#125;&#125;; 解法二：牛客二叉树中的某个节点的深度，就是其左子树深度和右子树深度较大者+1 ， 二叉树的深度就是根节点的深度，所以，利用递归的思想实现。（代码简洁，但是复杂复杂度好像和广度优先一样，都是n？ 是这样吗？） 123456789101112class Solution &#123;public: int TreeDepth(TreeNode* pRoot) &#123; if(pRoot==nullptr) return 0 ; int depth1 = 1, depth2 = 1; if(pRoot-&gt;left!=nullptr) depth1 = TreeDepth(pRoot-&gt;left)+1; if(pRoot-&gt;right!=nullptr) depth2 = TreeDepth(pRoot-&gt;right)+1; return depth1&gt;depth2 ? depth1 : depth2; &#125;&#125;; 39.平衡二叉树题目描述输入一棵二叉树，判断该二叉树是否是平衡二叉树。 解法一（自想）将题目看作是求左右子树的深度，如果深度差超过1,那么就不是二叉树，返回一个特殊的标识（-1），这种方法属于一边遍历，一边判断，只需要遍历每个节点一次，通过递归实现。时间复杂度为 $O(logn)$ 有一种“不太好”的方法是每遇到一个节点，就单独求一次这个节点对应的树的深度，这种做法要遍历一个节点很多次，是一种典型的不令人满意的做法 12345678910111213141516171819class Solution &#123;public: bool IsBalanced_Solution(TreeNode* pRoot) &#123; int tdepth = treeDepth(pRoot); if(tdepth!=-1) return true; else return false; &#125; int treeDepth(TreeNode* root)&#123; if(root == nullptr) return 0; int leftdepth = treeDepth(root-&gt;left); if(leftdepth == -1) return -1; int rightdepth = treeDepth(root-&gt;right); if(rightdepth == -1) return -1; if(abs(leftdepth-rightdepth) &gt; 1) return -1; return max(leftdepth,rightdepth) + 1; &#125;&#125;; 40.数组中只出现一次的数字题目描述一个整型数组里除了两个数字之外，其他的数字都出现了偶数次。请写程序找出这两个只出现一次的数字。 （暴力解法就不提了，肯定不是最优。） 解法一：异或注：异或运算符还可以实现无中间变量的两个数字互换：123456789int a=2;int b=4;a = a^b; // a = 2^4 = 6b = a^b; // b = 6^4 = 2a = a^b; // a = 6^2 = 4//同理有a = a + b; // a = 2+4 = 6a = a - b; // b = 6-4 = 2a = a - b; // a = 6-2 = 4 异或运算的性质：任何一个数字异或它自己都等于0 。也就是说，如果我们从头到尾依次异或数组中的每一个数字，那么最终的结果刚好是那个只出现一次的数字，因为那些出现两次的数字全部在异或中抵消掉了。 （这里不限定是一次，只要是奇数次都可以） 本题数列中，有两个出现一次的数字，第一次先全部异或，得到的结果是两个一次数字的异或值，该值至少有一位的值为1,因此，找到这一位，然后根据这一位这数组分成两拨，如此一来，每一拨都变成了上面的简单情况。 （同理，如果有N个一次数字，可以通过不断分拨的方法解决） 123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: void FindNumsAppearOnce(vector&lt;int&gt; data,int* num1,int *num2) &#123; int xor_result = 0; for(auto it = data.begin(); it!=data.end(); it++)&#123; xor_result = xor_result ^ (*it); &#125; int i = 1; while((xor_result&amp;i) == 0) i = i&lt;&lt;1; int low = 0; int high = data.size()-1; int p = data.at(low); while(low&lt;high)&#123; while(low&lt;high &amp;&amp; (data.at(high)&amp;i) != 0) high--; data.at(low) = data.at(high); if(low&lt;high)low++; //这里的判断条件一定不能少，否则low有可能超过high while(low&lt;high &amp;&amp; (data.at(low)&amp;i) == 0) low++; data.at(high) = data.at(low); if(low&lt;high) high--; //这里的判断条件一定不能少，否则hig有可能比low低 &#125; data.at(low) = p; int mid = 0; if((p&amp;i) != 0) mid = low; else mid = data.size()-1 &lt; low+1 ? data.size()-1 : low+1; *num1 = 0; for(int j = 0; j&lt;mid; j++) *num1 = (*num1) ^ data.at(j); *num2 = 0; for(int j = mid; j&lt; data.size(); j++) *num2 =(*num2) ^ data.at(j); &#125;&#125;; 41.和为S的连续正数序列解法一（自想）设置两个变量记录当前序列的start位置和end位置，判断当前序列的和: 如果=sum，则存储当前序列，并将start+1,序列前进; 如果&gt;sum,将应减去序列中的最小值，也就是start指向位置的值，然后start+1; 如果&lt;sum，则应该再加上下一个值，也就是end指向的值。 然后再进行上面的循环，直到start指向的位置值为sum/2,此时就已经不可能出现和为sum的连续序列了。该方法时间复杂度为$O(n)$ 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; FindContinuousSequence(int sum) &#123; vector&lt;vector&lt;int&gt;&gt; results; int tmp = 0; int start = 1; for(int end =start; start &lt;= sum/2 ;)&#123; if(tmp == sum)&#123; vector&lt;int&gt; numseq; for(int i = start ; i&lt;end; i++)&#123; numseq.push_back(i); &#125; results.push_back(numseq); tmp -=start; start++; &#125;else if( tmp &gt; sum)&#123; tmp -= start; start++; &#125;else&#123; tmp += end; end++; &#125; &#125; return results; &#125;&#125;; 42.和为S的两个数字解法一（自想）设置两个变量，分别指向数组的第一个位置和最后一个位置，然后将这两个变量所指位置的值相加，分以下三种情况： =sum，判断二者乘积是否比当前最小值小，如果是，则改变最小值的持有值。 不管是否小，都将num1++ sum，num2— &lt;sum，num++循环以上三步直到num1&lt;num2。最后判断minnum1和minnum2的值，如果二者相等，说明数组里面不存在这样的数对儿，返回空vector，若不相等，则输出这两个值。 123456789101112131415161718192021222324252627282930class Solution &#123;public: vector&lt;int&gt; FindNumbersWithSum(vector&lt;int&gt; array,int sum) &#123; vector&lt;int&gt; result; if(array.size() == 0) return result;//在使用容器的back()方法访问时，必须要确保容器不是空的，否则会出现段错误（访问越界） int minnum1 = array.back(); int minnum2 = array.back(); int num1 = 0; int num2 = array.size()-1; while(num1 &lt; num2)&#123; if(array.at(num1)+array.at(num2) == sum)&#123; if(array.at(num1) * array.at(num2) &lt; minnum1*minnum2)&#123; minnum1 = array.at(num1); minnum2 = array.at(num2); &#125; num1++; &#125;else if(array.at(num1) + array.at(num2) &gt; sum)&#123; num2--; &#125;else&#123; num1++; &#125; &#125; if(minnum1==minnum2) return result; result.push_back(minnum1); result.push_back(minnum2); return result; &#125;&#125;; 43.左旋转字符串题目描述汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！ 解法一（自想）：利用str.substr(pos,n)注意： 这道题看似简单，实则很容易考虑不全，主要需注意以下几点： n大于str.length()的情况 str.length()=0的情况 n为负数的情况（虽然这里牛客没考虑，我觉得题里没说正数，所以是有负数的可能的） 越是简单的题，越要注意各种情况的考虑，因为这种题的考察点就是考虑是否全面，而不是题怎么解 123456789101112class Solution &#123;public: string LeftRotateString(string str, int n) &#123; string res = ""; if(str.length() == 0) return str; if (n&gt;=str.length()) n = n % str.length(); res=str.substr(n); res += str.substr(0,n); return res; &#125;&#125;; 解法二（牛客）：反转利用多次反转的方法，首先将字符串按照n的位置分成两部分，然后进行以下三步（abcdefg，2）： 反转前一部分：ba 反转后一部分：gfed 反转整个字符串：bagfed -&gt; defgab 时间复杂度也为$O(n)$ 44.翻转单词顺序列解法一：设值两个标记i，j，都从字符串的最后一位开始，如果当前字符不是空格，那么i指向下一个，直到遇到空格为止，此时，将i到j范围内字符提取出来，然后把令j=i。重复以上过程，直到i=0为止。 该解法时间复杂度为 $O(n)$ 而且只需遍历一边字符串。 12345678910111213141516171819202122class Solution &#123;public: string ReverseSentence(string str) &#123; if(str.length() == 0) return str; string res = ""; for(int i = str.length()-1, j=str.length()-1; i&gt;=0; )&#123; if(str[i] == ' ')&#123;//这里注意不能用双引号,双引号代表字符串,在C++内部,""与''表示的是不同的东西 res += str.substr(i+1,j-i); res += " "; i--; j = i; &#125;else if(i == 0)&#123; res += str.substr(i,j-i+1); i--; &#125;else&#123; i--; &#125; &#125; return res; &#125;&#125;; 解法二（牛客）：两次反转首先反转整个字符串，然后以空格为间隔，反转每个单词。时间复杂度也是$O(n)$ 。 45.扑克牌顺子题目描述LL今天心情特别好,因为他去买了一副扑克牌,发现里面居然有2个大王,2个小王(一副牌原本是54张)他随机从中抽出了5张牌,想测测自己的手气,看看能不能抽到顺子,如果抽到的话,他决定去买体育彩票,嘿嘿！！“红心A,黑桃3,小王,大王,方片5”,“Oh My God!”不是顺子…..LL不高兴了,他想了想,决定大\小 王可以看成任何数字,并且A看作1,J为11,Q为12,K为13。上面的5张牌就可以变成“1,2,3,4,5”(大小王分别看作2和4),“So Lucky!”。LL决定去买体育彩票啦。 现在,要求你使用这幅牌模拟上面的过程,然后告诉我们LL的运气如何， 如果牌能组成顺子就输出true，否则就输出false。为了方便起见,你可以认为大小王是0。 注意:该题目需要注意：1123 这样的顺序返回的是false 解法一(自想):分析能组成顺子的数字的特征，首先，最大的数字和最小的数字他们的差一定要比numbers的size小，否则，肯定连不了顺子。比如12345和2300等。其次，如果数组中出现非0的重复数字，那么也一定不是顺子。因此，代码可以这样写： 找出非0的最大值和最小值 在找最值的时候顺便利用最简单的hash表来存储每个数字出现的次数，hash表长度为14，key值为数字，value值为key值出现的次数，如果value出现&gt;1的情况，则直接返回false 做判断，如果max-min&lt; numbers.size()，则返回true，否则返回false。 以上程序时间复杂度为$O(n)$ ，并且只需要遍历一次numbers。 12345678910111213141516171819202122232425class Solution &#123;public: bool IsContinuous( vector&lt;int&gt; numbers ) &#123; if(numbers.size() == 0) return false; int i = 0; while(numbers[i] == 0) i++; int min=numbers.at(i); int max = numbers.at(i); int zeronum = 0; int count[14] = &#123;0&#125;; for(auto it = numbers.begin(); it!=numbers.end(); it++)&#123; if(*it &lt; min &amp;&amp; *it!=0) min = *it; if(*it &gt; max) max = *it; if(*it == 0) zeronum++; count[*it]++; if(*it != 0 &amp;&amp; count[*it] &gt; 1) return false; &#125; if(max-min &lt;= numbers.size() - 1) return true; else&#123; return false; &#125; &#125;&#125;; 解法二（牛客）：先排序，在统计0的个数，再用0填补空缺，时间复杂度为 $O(nlogn)$ 不如上面的方法好。 46.圆圈中最后剩下的数：约瑟夫（Josephuse）环问题题目描述0,1,…,n-1这n个数字排成一个圆圈，从数字0开始每次删除m-1处的数字，然后从这个数字的下一位继续从0开始，删除m-1处的数字，求出圆圈里剩下的最后一个数字 解法一（自想）：利用vector维护动态数组利用一个vector维护一个动态数组，数组内的内容是每个孩子的编号，每次要删除的节点位置，都在index+m-1处，如果index+m-1超过了数组的大小，则对数组的size求余即可。该算法是最简单的一种思路，时间复杂度为：$O(n)$ ，vector或list在删除时，由于要将后面的元素向前挪，所以erase的时间复杂度为 $O(m)$ ，因此，总的时间复杂度为$O(mn)$。 空间复杂度为 $O(n)$ 1234567891011121314151617181920212223class Solution &#123;public: int LastRemaining_Solution(int n, int m) &#123; if(n &lt;= 0) return -1; vector&lt;int&gt; children; for(int i =0;i&lt;n;i++)&#123; children.push_back(i); &#125; int index = 0; while(children.size() &gt; 1)&#123; index += m-1; if(index&lt;children.size()-1) children.erase(children.begin()+index); else&#123; index = index % children.size(); children.erase(children.begin()+index); &#125; &#125; return children.front(); &#125;&#125;; 解法二（牛客）：经典解法，用环形链表模拟圆圈可以用std::list或者std::vector来模拟一个环形链表，由于它们本身不是循环的，因此需要记得手动实现循环逻辑（其实就是解法一） 如果要求不可以使用标准模板库里面的数据容器来模拟环形链表，那么可以自己设计结构体类型，实现一个循环链表。 该方法的时间复杂度为 $O(n)$ 这里由于链表无法进行随机访问，只能顺序访问，所以要时间复杂度应该为$O(nm)$ 空间复杂度为$O(n)。 解法三（牛客）：分析每次删除时的数字规律，总结出以下公式，按照公式编写递归或非递归程序，时间复杂度为 $O(n)$，空间复杂度为 $O(1)$ 。 \begin{cases} 0 & n=1 \\ [f(n-1,m)+m]\%n & n>1 \end{cases}思考过程：首先，如果只是去掉第ｍ个数，而下一次开始的地方仍然是从头开始的话，那么这个问题就可以很自然的用递归来解决。但是这里下一个开始的地方是下一个数，而不是第一个数，对此，可以想到将数组映射成从０开始的形式，然后在计算时再反映射回去，如此一来就可以得到上面的公式了（＋ｍ的操作就是反映射回去时添加上的） 1234567891011121314151617//非递归写法class Solution &#123;public: int LastRemaining_Solution(int n, int m) &#123; if(n&lt;= 0 || m&lt;=0) return -1; int res= 0 ; int i = 1; while(i &lt;= n)&#123; if(i == 1) res = 0; res = (res+m)%i; i++; &#125; return res; &#125;&#125;; 12345678910递归写法class Solution &#123;public: int LastRemaining_Solution(int n, int m) &#123; if(n&lt;=0 || m&lt;=0) return -1; if(n==1) return 0; return (LastRemaining_Solution(n-1,m)+m)%n; &#125;&#125;; 47.非常规法求前n项和题目描述求1+2+3+…+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。 这道题本身没有实际意义，侧重考察发散性思维和对C++相关机制的理解程度。 解法一：构造函数每声明一个对象，则构造函数都被调用一次，因此，可以借助静态变量来在构造函数内部实现累加操作。 123456789101112131415161718192021class sum&#123; public: static int i ; static int s; sum()&#123;i++; s+=i;&#125;; ~sum()&#123;&#125;; static void set()&#123; i = 0; s = 0; &#125;; &#125;;int sum::i =0;int sum::s = 0;class Solution &#123;public: int Sum_Solution(int n) &#123; sum::set(); sum a[n]; return sum::s; &#125;&#125;; 解法二：虚函数利用虚函数来模拟递归函数，可以在两个类中分别定义函数，其中一个函数充当递归函数的角色，另一个函数处理终止递归的情况，然后在两个函数里二选一。 这里用到了一个小trick，那就是对于整型变量n，执行!!n以后，可以将其转换成布尔值（0和1）。 1234567891011121314151617181920class A&#123; public: virtual int sum(int n)&#123;return 0;&#125;;&#125;;A* Array[2]; //这里必须为指针，否则不会进入B的sum 函数class B : public A&#123; public: virtual int sum(int n)&#123;return Array[!!n]-&gt;sum(n-1) + n;&#125;;&#125;;class Solution &#123;public: int Sum_Solution(int n) &#123; class A a; class B b; Array[0] = &amp;a; Array[1] = &amp;b; return Array[1]-&gt;sum(n); &#125;&#125;; 上面用了虚函数，那么使用普通的函数可以吗？答案是否定的，因为使用普通函数时，无法同时调用两个类的函数，最终只会调用A类的sum函数。 解法三：函数指针同样是上面的思想，不过改为使用函数指针来实现两个函数模拟递归 1234567891011121314151617int A(int n)&#123; return 0;&#125;int B(int n)&#123; static int (*fun[2])(int n) = &#123;A,B&#125;; return fun[!!n](n-1) + n;&#125;class Solution &#123;public: int Sum_Solution(int n) &#123; return B(n); &#125;&#125;; 解法四：模板类使用模板类完成递归，这种方法有一个很大的缺点就是整个过程是在编译阶段完成的，因此无法使用动态的n，而必须是在编译期间就能确定的常量，另外，编译器对递归编译代码的递归深度也是有限制的，所以n不能太大。 48.不用加减乘除做加法49.把字符串转换成整数题目描述将一个字符串转换成一个整数(实现Integer.valueOf(string)的功能，但是string不符合数字要求时返回0)，要求不能使用字符串转换整数的库函数。 数值为0或者字符串不是一个合法的数值则返回0。输入描述: 输入一个字符串,包括数字字母符号,可以为空 输出描述: 如果是合法的数值表达则返回该数字，否则返回0 解法一（自想）：从头开始逐个字符遍历，每次遇到一个“数字”，就将之间的res×10，然后再加上这个数字。需要特别注意“-123”，“+123”等情况。 时间复杂度为 $O(n)$ 。 12345678910111213141516171819202122class Solution &#123;public: int StrToInt(string str) &#123; int res = 0; bool negative = false; int i = 0; if(str[i] == '-')&#123; negative=true; i++; &#125;else if(str[i] == '+') i++; for(; i &lt; str.length() ;i++)&#123; if( str[i] &gt;= '0' &amp;&amp; str[i] &lt;= '9')&#123; res = res*10 + (int)(str[i] - '0'); &#125;else return 0; &#125; if(negative) res = 0 - res; return res; &#125;&#125;; 注意上面的代码虽然已经解决了牛客的题，但是有几点是需要特别注意的！ 首先，题目很简单，所以这道题的考察点只在于是否将所有情况都考虑到了，以下是一些可能的情况，日后再遇到一定要想起来： 首先考虑如何返回错误，首先不能使用可以转换成数值类型（int，bool，char）的数据直接指明错误（比如返回0，无法得知到底是错误当时真的是0），由此，可以创建一个全局的错误变量，如果要返回错误，则返回0并且将该变量状态改变。 非数字类符号不全是错误输出，如：+123、-123 只输入+和-时，要返回错误 string str==&quot;&quot;时，也要返回错误 如果为char str*，则要判断指针是否为空 一定要考虑数值溢出情况（当转换的数字大于最大正数，小于最小负数时，会溢出） 50.数组中重复的数字题目描述在一个长度为n的数组里的所有数字都在0到n-1的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。 解法一：暴力对于每个数组中的数字，都到前面的数字中去寻找是否有重复的。 时间复杂度： $O(n^2)$ 空间复杂度： $O(1)$ 解法二：哈希建立长度为n的哈希表，每次遇到一个数字x，就在hash[x]增1，如果此时hash[x]变为2，那么就说明有重复。 时间复杂度： $O(n)$ 空间复杂度： $O(n)$ 1234567891011121314151617181920212223class Solution &#123;public: // Parameters: // numbers: an array of integers // length: the length of array numbers // duplication: (Output) the duplicated number in the array number // Return value: true if the input is valid, and there are some duplications in the array number // otherwise false bool duplicate(int numbers[], int length, int* duplication) &#123; vector&lt;int&gt; hash(length); for (int i = 0; i&lt; length; i++)&#123; hash[numbers[i]]++; if(hash[numbers[i]] &gt; 1)&#123; *duplication = numbers[i]; return true; &#125; &#125; return false; &#125;&#125;; 解法三51.构建乘积数组题目描述给定一个数组A[0,1,…,n-1],请构建一个数组B[0,1,…,n-1],其中B中的元素B[i]=A[0]A[1]…A[i-1]A[i+1]…A[n-1]。不能使用除法。 解法一（自想）：将乘积看成两段，前i-1项的乘积，和后n-i项的乘积，分开计算，最终合并。时间复杂度： $O(n)$ 空间复杂度： $O(n)$ 123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; multiply(const vector&lt;int&gt;&amp; A) &#123; vector&lt;int&gt; B; int tmp = 1; for(auto it = A.begin(); it!=A.end(); it++)&#123; if(it!=A.begin()) tmp *= *(it-1); B.push_back(tmp); &#125; tmp = 1; for(int i = A.size()-1; i &gt;= 0; i--)&#123; if(i!=A.size()-1) tmp *= A.at(i+1); B.at(i) *= tmp; &#125; return B; &#125;&#125;; 52.正则表达式匹配题目描述请实现一个函数用来匹配包括’.’和’‘的正则表达式。模式中的字符’.’表示任意一个字符，而’‘表示它前面的字符可以出现任意次（包含0次）。 在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串”aaa”与模式”a.a”和”abaca”匹配，但是与”aa.a”和”ab*a”均不匹配 解法一：（牛客）主要分两种情况： 当前字符的下一个字符不是‘*’ 当前字符的字一个字符是‘*’ 对于第一种情况：直接判断是否相等（包含‘.’的情况） 对于第二种情况，需要分情况讨论： 当前字符与pattern当前字符不相等，则patter当前只能出现零次，调用match(str, pattern+2) 当前字符与pattern字符相等（包含‘.’的情况），则pattern的选择有两种，出现零次，或者出现一次以上，这两种情况都必须考虑，否则会丢解，如（aab和a.*ab），因此，需要调用match(str, pattern+2) || match(str+1, pattern) 12345678910111213141516171819202122232425class Solution &#123;public: bool match(char* str, char* pattern) &#123; if( *str == '\0' &amp;&amp; *pattern == '\0') return true; if( *str != '\0' &amp;&amp; *pattern == '\0') return false; if( *(pattern+1) != '*')&#123; if( *str == *pattern || *str!='\0' &amp;&amp; *pattern == '.') // *str的条件不能丢 return match(str+1, pattern+1); else return false; &#125;else&#123; if( *str == *pattern || *str!='\0' &amp;&amp; *pattern == '.') //这里的if else组合语句是必须的，否则会在不能出现多次时，函数仍然考虑出现多次的情况，造成误解 return match(str, pattern+2) || match(str+1, pattern); else return match(str, pattern+2); &#125; &#125;&#125;; 53.表示数值的字符串题目描述请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串”+100”,”5e2”,”-123”,”3.1416”和”-1E-16”都表示数值。 但是”12e”,”1a3.14”,”1.2.3”,”+-5”和”12e+4.3”都不是。 解法一（自想）：没有难点，考察点主要在于各种情况的考虑（以下均为false）： + - +12.2.2 12e 12e- 12E+4.3 123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: bool isNumeric(char* string) &#123; if(*string == &apos;\0&apos;) return false; if(*string == &apos;+&apos; || *string == &apos;-&apos;) string++; if(*string == &apos;\0&apos;) return false; int point_count = 0; while( (*string &gt;= &apos;0&apos; &amp;&amp; *string &lt;= &apos;9&apos;) || *string == &apos;.&apos;)&#123; if (*string == &apos;.&apos;) point_count++; if (point_count &gt; 1) return false; string++; &#125; if(*string == &apos;\0&apos;) return true; if(*string == &apos;e&apos; || *string == &apos;E&apos;) string++; else return false; if(*string == &apos;\0&apos;) return false; if(*string == &apos;+&apos; || *string == &apos;-&apos;) string++; if(*string == &apos;\0&apos;) return false; while( *string &gt;= &apos;0&apos; &amp;&amp; *string &lt;= &apos;9&apos; ) string++; if(*string != &apos;\0&apos;) return false; return true; &#125;&#125;; 54.字符流中第一个不重复的字符解法一（牛客）：哈希表建立一个哈希表和一个char数组（均为256大小），哈希表存储每个字符出现的次数，key为char，value为次数，数组存储所有 曾经 出现过一次的字符。 时间复杂度 $O(n)$ 空间复杂度 $O(1)$ 12345678910111213141516171819202122232425262728class Solution&#123;public: //Insert one char from stringstream char hash_c[256] = &#123;0&#125;; char first_c[256] = &#123;0&#125;; int index =0; void Insert(char ch) &#123; hash_c[ch]++; if(hash_c[ch] == 1)&#123; *(first_c+index) = ch; index++; &#125; &#125; //return the first appearence once char in current stringstream char FirstAppearingOnce() &#123; for(int i =0 ;i&lt;index; i++) if (hash_c[*(first_c+i)] == 1) return *(first_c+i); return '#'; &#125;&#125;; 55.链表中环的入口节点解法一（牛客）假设有环，并且环中的节点数为n，那么只要设值两个指针，一个slow指针指向头结点，另一个fast指针指向第n+1个节点，然后每次slow指针和fast指针都增1，那么肯定会在环的头部相遇（因为fast刚好比slow领先了一个环的长度） 因此，首先需要判断是否有环，思路是：从头结点开始，slow每次走一步，fast每次走两步，那么只要有环，slow和fast就一定会在环中的某个节点处相遇，如果无环，则fast一定先到达空指针 判断有环后，令fast从当前节点开始，继续往下走（每次走一步），并记录步数，最终遇到slow时的步数就是环的长度。 该方法时间复杂度为 $O(n)$ 空间复杂度为 $O(1)$ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* EntryNodeOfLoop(ListNode* pHead) &#123; ListNode* slow = pHead; ListNode* fast = pHead; while(slow!=nullptr &amp;&amp; fast != nullptr)&#123; if(slow-&gt;next == nullptr) return nullptr; else slow = slow-&gt;next; if(fast-&gt;next == nullptr || fast-&gt;next-&gt;next == nullptr) return nullptr; else fast = fast-&gt;next-&gt;next; if(slow == fast) break; &#125; fast = fast-&gt;next; int step = 1; while(slow != fast)&#123; fast = fast-&gt;next; step++; &#125; fast = pHead; while(step&gt;0)&#123; fast = fast-&gt;next; step--; &#125; slow = pHead; while(slow!=fast)&#123; slow = slow-&gt;next; fast = fast-&gt;next; &#125; return slow; &#125;&#125;; 解法二（牛客）： 断链法同理，先判断有环无环 然后记录两个指针，一个当前节点指针cur，一个相邻祖先指针pre，每经过一个节点时，都将pre指针的next置为nullptr，则当cur的next为空时，既为环的首个节点。 该方法的时间复杂度为O(n)，且只需遍历两次，且第二次遍历的时候正好遍历n个节点，但是缺点是会破坏链结构，补救办法是使用额外的标记来替代断链，但是这样会增加额外空间开销 1234567891011121314151617181920212223242526272829303132333435363738394041/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* EntryNodeOfLoop(ListNode* pHead) &#123; ListNode* slow = pHead; ListNode* fast = pHead; if(slow == nullptr) return nullptr; while(slow!=nullptr &amp;&amp; fast != nullptr)&#123; if(slow-&gt;next == nullptr) return nullptr; else slow = slow-&gt;next; if(fast-&gt;next == nullptr || fast-&gt;next-&gt;next == nullptr) return nullptr; else fast = fast-&gt;next-&gt;next; if(slow == fast) break; &#125; if(pHead-&gt;next == pHead) return pHead; //需要特别考虑只有一个节点并且自己组成环的情况 slow = pHead; fast = pHead-&gt;next; while(fast-&gt;next!=nullptr)&#123; slow-&gt;next = nullptr; slow = fast; fast = fast-&gt;next; &#125; return fast; &#125;&#125;; 解法三：没太看懂https://blog.csdn.net/dawn_after_dark/article/details/82564271对应文中解法一 56.删除链表中重复的结点题目描述在一个排序的链表中，存在重复的结点，请删除该链表中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;5 解法一（自想）：这道题本身比较简单，只需要维护一个pre指针和cur指针，分别指向前一个结点和当前结点，如果当前结点和下一个结点的值相等，那么就删除当前结点，最后我pre指针的next值设置为指向未重复的结点 但是！本题恶心了我很久，一直报段错误，主要原因是有的结点没有做空判断，就访问了结点的val或者next成员，此时如果结点是空的，那么就会报段错误，主要有以下这么几个情况： 头结点本身就是重复的，这个需要删除头结点，另外判断是否重复时，还要检查头结点的下一个结点是否为空，如果为空，则不能访问其val值，否则，报段错误 在进行重复判断时，访问cur-&gt;next-&gt;val时，需要先判断cur-&gt;next是否为空，如果为空，则不能访问其val值 123456789101112131415161718192021222324252627282930313233343536373839/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* deleteDuplication(ListNode* pHead) &#123; if(pHead == nullptr || pHead-&gt;next == nullptr) return pHead; ListNode* newHead = new ListNode(0); // 建立一个新的结点，其next用于标识头结点，以便在头结点重复时，指向新的头结点 newHead-&gt;next = pHead; ListNode* cur = pHead; ListNode* pre = newHead; while(cur != nullptr &amp;&amp; cur-&gt;next !=nullptr)&#123; // 注意 这里一定必须是 &amp;&amp; ，如果是|| ，则下面有可能会访问到空结点的val，造成段错误 if(cur-&gt;val == cur-&gt;next-&gt;val)&#123; ListNode* dup = cur-&gt;next; while(cur-&gt;val == dup-&gt;val &amp;&amp; dup!=nullptr)&#123; // 同理，让验证所有欲访问的结点不为空 dup = dup-&gt;next; &#125; cur = dup; pre-&gt;next = cur; &#125;else&#123; cur = cur-&gt;next; pre = pre-&gt;next; &#125; &#125; return newHead-&gt;next; &#125;&#125;; 57.二叉树的下一个节点58.对称的二叉树 题目描述请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。 解法一（牛客）：递归要判断一个树是否对称，需要判断其树的左右子节点是否相等，同时还要判断左子树的右子树和右子树的左子树是否相等，以及左子树的左子树和右子树的右子树是否相等，然后如此递归解之： 12345678910111213141516171819202122232425262728293031/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: bool isSymmetrical(TreeNode* pRoot) &#123; if(pRoot == nullptr ) return true; return isSymHelper(pRoot-&gt;left, pRoot-&gt;right); &#125; bool isSymHelper(TreeNode* subRoot1, TreeNode* subRoot2)&#123; if(subRoot1 == nullptr) return subRoot2==nullptr; if(subRoot2 == nullptr) return false; if(subRoot1-&gt;val != subRoot2-&gt;val) return false; bool b1 = isSymHelper(subRoot1-&gt;right, subRoot2-&gt;left); bool b2 = isSymHelper(subRoot1-&gt;left, subRoot2-&gt;right); return b1&amp;&amp;b2; &#125;&#125;; 解法二（牛客）：非递归关键还是知道怎么样才能判断一个二叉树是否对称，只要采用前序、中序、后序、层次遍历等任何一种遍历方法，分为先左后右和先右后左两种方法，只要两次结果相等就说明这棵树是一颗对称二叉树。 1234567891011121314151617181920212223242526272829303132333435363738394041//以下为层次遍历//与普通遍历不同的是，对于这道题，必须要把左右子树都存入到queue中，不论是否为空，因为只有这样才能将整个二叉树的结构存储起来，以便判断/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: bool isSymmetrical(TreeNode* pRoot) &#123; queue&lt;TreeNode*&gt; q1; queue&lt;TreeNode*&gt; q2; if( nullptr==pRoot) return true; q1.push(pRoot); q2.push(pRoot); TreeNode* cur1; TreeNode* cur2; while(!q1.empty() &amp;&amp; !q2.empty())&#123; cur1 = q1.front(); q1.pop(); cur2 = q2.front(); q2.pop(); if(cur1 == cur2 &amp;&amp; nullptr == cur1) continue; if(nullptr == cur1 || nullptr == cur2) return false; if(cur1-&gt;val != cur2-&gt;val) return false; q1.push(cur1-&gt;left); q1.push(cur1-&gt;right); q2.push(cur2-&gt;right); q2.push(cur2-&gt;left); &#125; return true; &#125;&#125;; 解法三（牛客）：非递归=非递归算法，利用DFS和BFS=========================== BFS使用Queue来保存成对的节点 出队的时候也是成对成对的 1.若都为空，继续； 2.一个为空，返回false; 3.不为空，比较当前值，值不等，返回false； 确定入队顺序，每次入队都是成对成对的，如left.left， right.right ;left.rigth,right.left 123456789101112131415161718192021222324252627282930313233/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: bool isSymmetrical(TreeNode* pRoot) &#123; if(pRoot == nullptr) return true; queue&lt;TreeNode*&gt; q; q.push(pRoot-&gt;left); q.push(pRoot-&gt;right); TreeNode* lnode; TreeNode* rnode; while(!q.empty())&#123; lnode = q.front(); q.pop(); rnode = q.front(); q.pop(); if(nullptr == lnode &amp;&amp; nullptr == rnode) continue; if(nullptr == lnode || nullptr == rnode) return false; if(lnode-&gt;val != rnode-&gt;val) return false; q.push(lnode-&gt;left); q.push(rnode-&gt;right); q.push(lnode-&gt;right); q.push(rnode-&gt;left); &#125; return true; &#125;&#125;; DFS使用stack来保存成对的节点 出栈的时候也是成对成对的 ， 1.若都为空，继续； 2.一个为空，返回false; 3.不为空，比较当前值，值不等，返回false； 确定入栈顺序，每次入栈都是成对成对的，如left.left， right.right ;left.rigth,right.left 12345678910111213141516171819202122232425262728293031323334353637/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: bool isSymmetrical(TreeNode* pRoot) &#123; stack&lt;TreeNode*&gt; s; if(pRoot == nullptr) return true; s.push(pRoot-&gt;left); s.push(pRoot-&gt;right); TreeNode* lnode; TreeNode* rnode; while(!s.empty())&#123; rnode = s.top(); s.pop(); lnode = s.top(); s.pop(); if( nullptr==lnode &amp;&amp; nullptr == rnode) continue; if( nullptr == lnode || nullptr == rnode) return false; if(lnode-&gt;val != rnode-&gt;val) return false; s.push(lnode-&gt;left); s.push(rnode-&gt;right); s.push(lnode-&gt;right); s.push(rnode-&gt;left); &#125; return true; &#125;&#125;; 59.按之字形顺序打印二叉树题目描述请实现一个函数按照之字形打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右至左的顺序打印，第三行按照从左到右的顺序打印，其他行以此类推。 解法一（自想）：利用两个queue，一个用于层次遍历树节点，另一个用于存储对应节点的depth，然后每次访问节点时，都判断当前节点的层数，如果为奇数层，则将该层直接push back到结果向量中，如果为偶数，则将该层数据进行reverse后再push back到结果向量中。 时间复杂度为 $O(n^2)$ 空间复杂度为 $O(n)$ 需要注意的是最后一层的边界条件与其它层不同一样，需要专门判断以下，具体可以看下面的点注释。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; Print(TreeNode* pRoot) &#123; vector&lt;vector&lt;int&gt; &gt; res; if(pRoot==nullptr) return res; queue&lt;TreeNode*&gt; q_node; queue&lt;int&gt; q_depth; q_node.push(pRoot); q_depth.push(1); TreeNode* cur; int depth; int global_depth = 1; vector&lt;int&gt; cur_layer; while(!q_node.empty())&#123; cur = q_node.front(); q_node.pop(); depth = q_depth.front(); q_depth.pop(); if(cur-&gt;left != nullptr)&#123; q_node.push(cur-&gt;left); q_depth.push(depth+1); &#125; if(cur-&gt;right != nullptr)&#123; q_node.push(cur-&gt;right); q_depth.push(depth+1); &#125; if(depth == global_depth)&#123; cur_layer.push_back(cur-&gt;val); if(q_node.empty())&#123; // 对应最后一层的情况，当到了最后一层时，depth不会再继续增1了， //所以不能通过global depth或depth的大小来判断是否进行pushback， //需要通过看是否达到了最后一个节点来判断 if(global_depth % 2 == 1)&#123; res.push_back(cur_layer); &#125;else&#123; reverse(cur_layer.begin(), cur_layer.end()); res.push_back(cur_layer); &#125; &#125; &#125;else&#123; if(global_depth % 2 == 1)&#123; res.push_back(cur_layer); &#125;else&#123; reverse(cur_layer.begin(), cur_layer.end()); res.push_back(cur_layer); &#125; cur_layer.clear(); cur_layer.push_back(cur-&gt;val); global_depth=depth; if(q_node.empty()) res.push_back(cur_layer); //这句话用于处理最后一层只有一个节点的情况，如果只有一个节点的话， //那么当前queue就为空，不会进入下一次循环，从而导致最后一层没有pushback进去 &#125; &#125; return res; &#125;&#125;; 解法二：牛客同样的思路，另一种写法，更加简洁，通过while里面内置for循环，来保证每次for循环都会将一整层的节点放进队列中，无需额外的数组来存储depth信息123456789101112131415161718192021222324252627282930313233链接：https://www.nowcoder.com/questionTerminal/91b69814117f4e8097390d107d2efbe0来源：牛客网class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; Print(TreeNode* pRoot) &#123; vector&lt;vector&lt;int&gt;&gt; res; if(pRoot == NULL) return res; queue&lt;TreeNode*&gt; que; que.push(pRoot); bool even = false; while(!que.empty())&#123; vector&lt;int&gt; vec; //将vec声明在内部，省去每次的clear操作，clear操作需要对vector进行遍历，并将每个元素置为null？ const int size = que.size(); //当前存的节点数目就是这一层所有的节点，之前层的到已经被取出, 并且这一层的子节点还没有开始入队列 for(int i=0; i&lt;size; ++i)&#123; //将该层所有节点的子节点入队列，同时当到达该层最后一个节点时终止 TreeNode* tmp = que.front(); que.pop(); vec.push_back(tmp-&gt;val); if(tmp-&gt;left != NULL) que.push(tmp-&gt;left); if(tmp-&gt;right != NULL) que.push(tmp-&gt;right); &#125; if(even) //根据奇偶标识判断是否需要reverse std::reverse(vec.begin(), vec.end()); res.push_back(vec); even = !even; &#125; return res; &#125;&#125;; 60.把二叉树打印成多行题目描述从上到下按层打印二叉树，同一层结点从左至右输出。每一层输出一行。 解法一（半自想）：while循环加for循环，无需额外记录层数，具体看59题解法二分析 时间和空间复杂度为 $O(n)$ 123456789101112131415161718192021222324252627282930313233/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; Print(TreeNode* pRoot) &#123; vector&lt;vector&lt;int&gt; &gt; res; if(pRoot== nullptr) return res; queue&lt;TreeNode*&gt; q_node; q_node.push(pRoot); while(!q_node.empty())&#123; vector&lt;int&gt; cur_layer; const int cur_size = q_node.size(); for(int i = 0;i&lt;cur_size; i++)&#123; TreeNode* cur_node = q_node.front(); q_node.pop(); cur_layer.push_back(cur_node-&gt;val); if(cur_node-&gt;left != nullptr) q_node.push(cur_node-&gt;left); if(cur_node-&gt;right != nullptr) q_node.push(cur_node-&gt;right); &#125; res.push_back(cur_layer); &#125; return res; &#125;&#125;; 61.序列化二叉树62.二叉搜索树的第k个节点题目描述给定一棵二叉搜索树，请找出其中的第k小的结点。例如， （5，3，7，2，4，6，8） 中，按结点数值大小顺序第三小结点的值为4。 解法一（自想）：中根遍历，遍历到第k个节点时将其输出，如果k大于节点数量，输出nullptr, 时间复杂度 $O(n)$ 12345678910111213141516171819202122232425262728293031323334353637/*struct TreeNode &#123; int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: TreeNode* KthNode(TreeNode* pRoot, int k) &#123; if(pRoot == nullptr) return nullptr; stack&lt;TreeNode*&gt; s_node; TreeNode* P = pRoot; //ctor&lt;TreeNode*&gt; vec_node; int cur_k = 0; while(P!=nullptr || !s_node.empty())&#123; while(P!=nullptr)&#123; s_node.push(P); P = P-&gt;left; &#125; if(!s_node.empty())&#123; P = s_node.top(); s_node.pop(); cur_k++; if(cur_k == k) break; P = P-&gt;right; &#125; &#125; if(cur_k == k) return P; return nullptr; &#125;&#125;; 63.数据流中的中位数解法一(自想):插入时用vector的insert方法,按顺序插入,空间为 $O(n)$ ,时间复杂度为$O(n)$ 返回中位数时直接利用下标,时间复杂度和空间复杂度都为 $O(1)$. 这里关于vector的insert方法,有两个需要注意的点: it = vec.insert(it,num); 如果后序还要继续插入的话, 就必须将insert的结果重新赋值给it, 否则如果没有重新赋值而直接继续使用it的话,会导致段错误, 这里因为已经不需要继续插入了,所以可以用break直接跳出,无需赋值 插入时,如果num比vec里面所有的数都大, 那么会导致插入失败, 此时 ,应使用push_back将num插入到最后 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: vector&lt;int&gt; vec; void Insert(int num) &#123; if(vec.size() == 0)&#123; vec.insert(vec.begin(), num); return; &#125; bool is_insert=false; for(auto it=vec.begin(); it!=vec.end(); it++)&#123; if(*it &gt; num)&#123; vec.insert(it,num); is_insert=true; break; &#125; &#125; if(!is_insert) vec.push_back(num); &#125; double GetMedian() &#123; if(vec.size() == 0) return 0; int x1 = vec.size()/2; int x2 = (vec.size()-1)/2; return (vec[x1]+vec[x2])/2.0; &#125;&#125;; 解法二:插入的时候不考虑排序,在查找中位数时可以使用基于Partition的方法,时间复杂度为 $O(n)$. 解法三:AVL树插入时间复杂度为 $O(logn)$ 找中位数时间复杂度为 $O(1)$ 解法四(牛客):用大顶堆和小顶堆思路: 如果能够保证数据容器左边的数据都小于右边的数据，这样即使左、右两边内部的数据没有排序，也可以根据左边最大的数及右边最小的数得到中位数。如何快速从一个容器中找出最大数？用最大堆实现这个数据容器，因为位于堆顶的就是最大的数据。同样，也可以快速从最小堆中找出最小数。 因此可以用如下思路来解决这个问题：用一个最大堆实现左边的数据容器，用最小堆实现右边的数据容器。往堆中插入一个数据的时间效率是 O(logn)。由于只需 O(1)时间就可以得到位于堆顶的数据，因此得到中位数的时间效率是 O(1)。 首先要保证数据平均分配到两个堆中，因此两个堆中数据的数目之差不能超过 1 还要保证最大堆中里的所有数据都要小于最小堆中的数据 当数据的总数目是偶数时，按照前面分配的规则会把新的数据插入到最小堆中。如果此时新的数据比最大堆中的一些数据要小，怎么办呢？ 可以先把新的数据插入到最大堆中，接着把最大堆中的最大的数字拿出来插入到最小堆中。由于最终插入到最小堆的数字是原最大堆中最大的数字，这样就保证了最小堆中的所有数字都大于最大堆中的数字。 当需要把一个数据插入到最大堆中，但这个数据小于最小堆里的一些数据时，这个情形和前面类似。 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: priority_queue&lt;int, vector&lt;int&gt;, std::less&lt;int&gt; &gt; q_max; priority_queue&lt;int, vector&lt;int&gt;, std::greater&lt;int&gt; &gt; q_min; void Insert(int num) &#123; if( q_max.size()&gt; q_min.size() )&#123; q_max.push(num); int tmp = q_max.top(); q_max.pop(); q_min.push(tmp); &#125;else&#123; q_min.push(num); int tmp = q_min.top(); q_min.pop(); q_max.push(tmp); &#125; &#125; double GetMedian() &#123; double res; if(q_max.size() == q_min.size())&#123; int x1 = q_max.top(); int x2 = q_min.top(); res = (x1+x2)/2.0; &#125;else&#123; res = q_max.top(); &#125; return res; &#125;&#125;; 插入时间复杂度为 $O(logn)$ 找中位数时间复杂度为 $O(1)$ 64.滑动窗口的最大值题目描述给定一个数组和滑动窗口的大小，找出所有滑动窗口里数值的最大值。例如，如果输入数组{2,3,4,2,6,2,5,1}及滑动窗口的大小3，那么一共存在6个滑动窗口，他们的最大值分别为{4,4,6,6,6,5}； 针对数组{2,3,4,2,6,2,5,1}的滑动窗口有以下6个： {[2,3,4],2,6,2,5,1}， {2,[3,4,2],6,2,5,1}， {2,3,[4,2,6],2,5,1}， {2,3,4,[2,6,2],5,1}， {2,3,4,2,[6,2,5],1}， {2,3,4,2,6,[2,5,1]}。 解法一(自想):用最直接的办法, 每次求出滑动窗口内的最大值, 然后存到max_res向量里面, 该方法时间复杂度为 $O(nm)$ . 空间为 $O(n)$ 123456789101112131415161718class Solution &#123;public: vector&lt;int&gt; maxInWindows(const vector&lt;int&gt;&amp; num, unsigned int size) &#123; vector&lt;int&gt; max_res; if(size == 0) return max_res; //无符号整数, 要首先考虑size为0的情况, 否则会导致下面的程序数组越界 for(int i = 0 ; i&lt; num.size()-size+1 ; i++)&#123; int tmp_max; //if(i&lt;num.size()) tmp_max = num[i]; //这里的if语句看起来是多余的, 实际上可以帮助进行数组越界检查, 有助于快速确定bug位置 for(int j = i+1; j&lt; i+size ; j++)&#123; if(num[j] &gt; tmp_max) tmp_max = num[j]; // 这里同样可以进行越界检查, 有助于bug定位, bug修复后可去掉 &#125; max_res.push_back(tmp_max); &#125; return max_res; &#125;&#125;; 解法二(讨论区):使用双端队列deque, 从下标0开始, 一直到n-1, 每次进行如下步骤: 当前元素是否比队列中最后一个元素大, 如果大, 说明队列元素以后也不可能再成为较大值, 直接pop, 如此循环, 直到队列为空或者遇到比当前值大的元素 判断队列中队首的元素是否过期(若队空则直接下一步, 无需判断), 若过期, 则pop, 否则, 不管( 只看队首, 队内的元素是否过期不影响算法, 因为就算过期后面也会将其淘汰) 将当前元素的下标存到队尾 将新的队首元素存到结果向量max_res中 注意: 队列里面存的是下标, 而不是元素本身的值, 后面在提到队列的元素值时, 均是指队列中存储的下标对应的元素值. 时间复杂度分析: 不是 $O(n*szie)$ 而是 $O(n)$ ? 原因: 假设队列里面的正好包含size个元素(最多就为size个), 那么这三个元素对应的值一定是递减的, 因为如果不是递减中, 在进行第一个判断时, 就会将其移除, 此时, 如果新来了一个元素, 如果该元素值小于队列中所有的值, 那么就只可能进行一次判断, 而不是循环size次, 而如果均大于队列中的值, 那么队列中的元素个数就会变成1个, 这样, 在下次进行判断时, 只会与一个元素做判断, 如果是元素值位于中间, 那么下一次做判断的元素个数也会减少一部分, 综上, 内部while循环时, 相对于普通的循环嵌套, 该种循环可以认为是常数级(虽然还是与size的大小有关, 但是总体来说, 要做的判断次数比通常的循环小).12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; maxInWindows(const vector&lt;int&gt;&amp; num, unsigned int size) &#123; vector&lt;int&gt; max_res; deque&lt;int&gt; dq_index; for(int i =0; i&lt; num.size(); i++)&#123; while(!dq_index.empty() &amp;&amp; num[i] &gt; num[dq_index.back()] )&#123; dq_index.pop_back(); &#125; if(!dq_index.empty() &amp;&amp; i-dq_index.front()&gt;= size) dq_index.pop_front(); dq_index.push_back(i); if(i&gt;=size-1) max_res.push_back(num[dq_index.front()]); &#125; return max_res; &#125;&#125;; 65.矩阵中的路径题目描述请设计一个函数，用来判断在一个矩阵中是否存在一条包含某字符串所有字符的路径。路径可以从矩阵中的任意一个格子开始，每一步可以在矩阵中向左，向右，向上，向下移动一个格子。如果一条路径经过了矩阵中的某一个格子，则之后不能再次进入这个格子。 例如 a b c e s f c s a d e e 这样的3 X 4 矩阵中包含一条字符串”bcced”的路径，但是矩阵中不包含”abcb”路径，因为字符串的第一个字符b占据了矩阵中的第一行第二个格子之后，路径不能再次进入该格子。 解法一:这是一个可以用回朔法解决的典型题。首先，在矩阵中任选一个格子作为路径的起点。如果路径上的第i个字符不是ch，那么这个格子不可能处在路径上的第i个位置。如果路径上的第i个字符正好是ch，那么往相邻的格子寻找路径上的第i+1个字符。除在矩阵边界上的格子之外，其他格子都有4个相邻的格子。重复这个过程直到路径上的所有字符都在矩阵中找到相应的位置。 由于回朔法的递归特性，路径可以被开成一个栈。当在矩阵中定位了路径中前n个字符的位置之后，在与第n个字符对应的格子的周围都没有找到第n+1个字符，这个时候只要在路径上回到第n-1个字符，重新定位第n个字符。 由于路径不能重复进入矩阵的格子，还需要定义和字符矩阵大小一样的布尔值矩阵，用来标识路径是否已经进入每个格子。 当矩阵中坐标为（row,col）的格子和路径字符串中相应的字符一样时，从4个相邻的格子(row,col-1),(row-1,col),(row,col+1)以及(row+1,col)中去定位路径字符串中下一个字符如果4个相邻的格子都没有匹配字符串中下一个的字符，表明当前路径字符串中字符在矩阵中的定位不正确，我们需要回到前一个，然后重新定位。 一直重复这个过程，直到路径字符串上所有字符都在矩阵中找到合适的位置 本题一定要注意边界条件即特殊情况的判断: 当矩阵所有元素一样时(这种情况一定要注意先) 当矩阵只有一个元素时(这两种情况要注意, 先进入递归程序, 然后再对flag矩阵进行判断, 否则, 当子串和矩阵大小一样时, 就无法判断到下一个字符是否==’\0’了)- 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123;public: bool hasPath(char* matrix, int rows, int cols, char* str) &#123; if(str[0] == &apos;\0&apos;) return true; int* flag_matrix = new int[rows*cols]; for(int i = 0; i&lt;rows; i++)&#123; for(int j =0 ;j&lt;cols; j++)&#123; flag_matrix[i*cols+j] = 1; &#125; &#125; for(int i = 0; i&lt; rows; i++)&#123; for(int j = 0;j&lt; cols; j++)&#123; if(matrix[i*cols+j] == str[0])&#123; bool is_path = hasPath_helper(matrix,flag_matrix,i,j, rows, cols, str, 0); if(is_path) return true; &#125; &#125; &#125; delete []flag_matrix; return false; &#125; bool hasPath_helper(char* matrix,int* flag_matrix, int i, int j, int rows, int cols, char* str,int x)&#123; if(str[x] == &apos;\0&apos;) return true; if(i&lt;0 || i&gt;=rows || j&lt;0 || j&gt;=cols) return false; if(flag_matrix[i*cols+j] == 0 || matrix[i*cols+j] != str[x]) return false; flag_matrix[i*cols+j] = 0; bool is_path = hasPath_helper(matrix, flag_matrix, i, j-1, rows, cols, str, x+1) || hasPath_helper(matrix, flag_matrix, i-1 , j, rows, cols, str, x+1) || hasPath_helper(matrix, flag_matrix, i, j+1, rows, cols, str, x+1) || hasPath_helper(matrix, flag_matrix, i+1, j, rows, cols, str, x+1); flag_matrix[i*cols+j] = 1; return is_path; &#125;&#125;; 66.机器人的运动范围题目描述地上有一个m行和n列的方格。一个机器人从坐标0,0的格子开始移动，每一次只能向左，右，上，下四个方向移动一格，但是不能进入行坐标和列坐标的数位之和大于k的格子。 例如，当k为18时，机器人能够进入方格（35,37），因为3+5+3+7 = 18。但是，它不能进入方格（35,38），因为3+5+3+8 = 19。请问该机器人能够达到多少个格子？ 解法一:回溯法, 如果当前节点的位数值满足要求, 那么从当前节点开始, 满足要求的格子数字应该等于” 1+左+右+上+下”, 其中方向代表这个方向上的满足要求的格子数. 注意每走过一次格子, 需要将flag矩阵中当前格子的标识设为”已走过(1)”, 并且, 由于此任务是统计符合条件的格子总数, 所以和一般的回溯法不同, 不能在递归结束后将该格子的标识重新复位(否则不同路径上回到同一个格子重复计数). 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int mc_helper(int threshold,int cur_i, int cur_j, vector&lt; vector&lt;int&gt; &gt;&amp; flag_matrix)&#123; int rows = flag_matrix.size(); int cols = flag_matrix[0].size(); int cur_val = cur_i/10 + cur_i%10 + cur_j/10 + cur_j%10; if(cur_val &gt; threshold || cur_i&lt;0 || cur_i &gt;=rows || cur_j&lt;0 || cur_j&gt;=cols || flag_matrix[cur_i][cur_j]) return 0; flag_matrix[cur_i][cur_j] = 1; return 1 + mc_helper(threshold, cur_i, cur_j-1, flag_matrix)+ mc_helper(threshold, cur_i, cur_j+1, flag_matrix)+ mc_helper(threshold, cur_i-1, cur_j, flag_matrix)+ mc_helper(threshold, cur_i+1, cur_j, flag_matrix); //flag_matrix[cur_i][cur_j] = 0; //return cur_count; &#125; int movingCount(int threshold, int rows, int cols) &#123; if(rows&lt;=0 || cols&lt;=0) return 0; vector&lt; vector&lt;int&gt; &gt; flag_matrix(rows, vector&lt;int&gt;(cols)); int count = mc_helper(threshold,0, 0, flag_matrix); return count; &#125;&#125;;]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>算法刷题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fully Convolutional Networks for Semantic Segmentation---ICCV]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-FCN%2F</url>
    <content type="text"><![CDATA[摘要本文的主要亮点是建立一个全卷积网络，该网络可以接受任意尺寸的图片（因为没有全连接层，所以无需限定图片尺寸）,同时可以十分高效的输出相应尺寸的结果。本文定义和详细描述了全卷积网络的空间信息，解释了它们可以应用与空间密集型预测任务，并且画出了与之前模型的联系。本文将当前流行的AlexNet、VGGNet和GoogLeNet应用到全卷积网络中去，并对其进行迁移学习。然后，本文定义了一个新的网络，它将一个深层的粗糙layer的语义信息和一个浅层的精化layer的语义信息结合起来，最终生成了一个精确的详细的分割结果。本文的模型在众多数据集上都取得了sota表现（2015） 介绍简要介绍了一下从图像分类到语义分割任务中，卷积网络起到的推进作用。并且指出本文的模型是目前（2015）为止第一个可以训练FANs end to end预测像素，并且支持supervised pre-training的网络模型。 本文模型无需任何前处理或后处理操作，也将不会产生随之而来的负面影响。本文还定义了一种新式的“skip”结构来结合深层粗糙的语义信息和浅层，精化的语义信息。后面会详细介绍 相关工作简单提了一下从分类到实例分割的相关论文。然后从以下几个方面进行了介绍。 Fully convolutional networks： 介绍了全卷积网络的发展的现状，从90年代开始，就已经有人开始使用全卷积网络了，但是全卷积网络相对研究成果还是较少。 Dense prediction with convnets： 目前已经有一些工作将convnets应用到了密集型预测任务。这些方法都包含有以下几点共有特征： 模型较小：模型和容量和感受野都有一定限制。 patchwise training：在预测指定像素时，只将此像素和其周围像素作为输入送入模型里训练，即每一个像素都会作为中心像素被训练来预测这个像素所属的分类。patch-wise的问题无疑非常明显，第一：训练中用的patch会大量重叠，非常低效。第二：由于patch-wise大量的计算量，预测的时候很慢。 后处理：超像素映射，随机field正则化，局部分类 input shifting and output interlacing for dense output as introduced by OverFeat 多尺寸金字塔处理 tanh非线性包含 融合（ensembles） FCN则没有以上机制。 与现有模型不同，本文使用image classification作为有监督的预训练，同时fine-tune全卷积，以期望从整张输入图片中快速且高效的学到相应的特征。目前大多数的模型和方法都不是端到端的。 Fully convolutional networks开始的时候介绍了一下卷积网络是怎么回事，在此不坐赘述。 关于FCN的一个real-valued损失函数定义了一个任务：如果损失函数是最后一层中spatial dimensions的总和 $\ell(x;\theta) = \sum{ij}\ell’(x{ij};\theta)$ ，那么它的梯度就会是它所有spatial components的梯度的综合。因此对于在整张图片上 $\ell$ 的sgd就是等于将最后一层所有感受野作为一个minibatch的$\ell’$的sgd。 当这些感受野重合度非常大时，layer-by-layer方式的前向计算和反向计算相比于path-by-patch的方式，就变得是否高效。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>网络模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《GPU高性能编程CUDA实战 CUDA By Example》]]></title>
    <url>%2Fz_post%2FCUDA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-GPU%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8BCUDA%E5%AE%9E%E6%88%98CUDAByExample%2F</url>
    <content type="text"><![CDATA[第一章 为什么需要CUDA1.1 本章目标了解历史和发展历程 1.2 并行处理的历史中央处理器性能的提升逐渐变得困难 1.3 GPU计算的崛起1.4 CUDA1.4.1 CUDA架构是什么cuda架构包含了一个统一的着色器流水线，使得执行通用计算的程序能够对芯片上的每个数学逻辑单元（Arithmetic Logic Unit，ALU）进行排列。另外，NVIDIA在实现ALU时都确保它们满足IEEE单精度浮点数学运算的需求，并且可以使用一个裁剪后的指令集来执行通用计算，而不是仅限于执行图形计算。此外，GPU上的执行单元不仅能任意地读写内存，同时还能访问由软件管理的缓存，也称为共享内存。 CUDA架构的所有这些功能都是为了使GPU不仅能执行传统的图形计算，还能高效的执行通用计算。 1.4.2 CUDA架构的使用NVIDIA专门开发了一款编译器来编译CUDA C语言。现在，用户不再需要了解OpenGL或者DirectX图形编程结构，也不需要将通用计算问题伪装为图形计算问题。 1.5 CUDA的应用医学影像、流体力学等等 第二张 入门2.1 本章目标配置环境 2.2 开发环境 支持CUDA的图形处理器 NVIDIA设备驱动程序 CUDA开发工具箱 标准C编译器 由于CUDA C应用程序将在两个不同的处理器上执行计算，因此需要两个编译器。其中一个编译器为GPU编译代码，另一个为CPU编译代码。 第三章 CUDA简介3.1 本章目标第一段cuda c代码、了解host和device之间的区别、了解其他信息 3.2 第一个程序3.2.1 Hello，World！将CPU以及系统的内存成为主机（host）。而将GPU及其内存成为设备（device）。 在GPU设备上执行的函数通常称为核函数（kernel）。 没有核函数，只考虑在主机运行的CUDA代码和标准的C在很大程度上是没有区别的。 12345int main(void)&#123; printf("Hello, World!\n"); return 0;&#125; 3.2.2 核函数调用在上面的示例中添加核函数 1234567891011#include &lt;iostream&gt;__global__ void kernel(void)&#123;&#125;int main(void)&#123; kernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); printf("Hello,World!\n"); return 0;&#125; 上面的代码有两处新增： 一个空的核函数kernel()，并且带有修饰符__global__ 对这个空的核函数的调用语句，并且带有修饰字符&lt;&lt;&gt;&gt; cuda的host代码默认是由系统的标准C编译器来编译的（如Linux的GNU gcc和Windodws的VS），NVIDIA工具只是将代码交给host编译器，它表现出的行为就好像CUDA不存在一样。 而当遇到具有__global__修饰符的函数时，编译器就会将该函数编译为在device上运行。在此例子中，函数kernel()将被交给编译device代码的编译器，而main()函数将被交给host编译器。 而对kernel()函数的调用语句则使用了一种尖括号和两个数值的方式。这将在后面相似介绍。 3.2.3 传递参数以下代码展示了如何像核函数传递参数并取得返回结果 123456789101112131415161718192021#include "stdio.h"__global__ void add(int a, int b, int *c)&#123; *c = a+b;&#125;int main()&#123; int c; int *dev_c; HANDLE_ERROR(cudaMalloc((void**)&amp;dev_c, size(int))); add&lt;&lt;&lt;1,1&gt;&gt;&gt;(2,7,dev_c); HANDLE_ERROR(cudaMemcpy(&amp;c, dev_c, sizeof(int), cudaMemcpyDeviceToHost)); printf("2+7 = %d\n",c); cudaFree(dev_c); return 0;&#125; 以上多行代码包含两个概念： 可以像调用C函数那样将参数传递给核函数 当设备执行任何有用的操作时，都需要分配内存，例如将计算值返回给主机 cudaMalloc()函数：（注意，分配内存的指针不是该函数的返回值，这点与malloc()不同） 参数一： 一个指针，指向用于保存新分配内存地址的变量。注意，由于C语言中，指针传递是本身也是值传递的，所以为了使指针本身的值（不是指针地址指向的值）可以改变，因此在传递时要使用双重指针void**，这样做的主要原因还是因为分配内存的指针最终不是通过函数返回，而是直接改变参数值导致的（如果传的是一重指针，则改变的是pd指向的内存空间的数据，而不是pd本身，所以pd也就不能指向GPU的内存了）。 参数二：分配内存的大小 CUDA C的简单行及其强大功能在很大成都上都是来源于它淡化了主机代码和设备代码之间的差异。然而，程序员一定不能在主机代码中对cudaMalloc()返回的指针进行解引用（Dereference）。主机代码可以将这个指针作为参数传递，对其执行算术运算，甚至可以将其转换为另一种不同的类型。但是，绝对不饿昆虫使用这个指针来读取或写入内存。 CUDA中对设备指针的使用限制总结如下： 可以将cudaMalloc()分配的指针传递给在设备上执行的函数 可以在设备代码中使用cudaMalloc()分配的指针进行内存读写操作 可以将cudaMalloc()分配的指针传递给在主机上执行的函数 不能在主机代码中使用cudaMalloc()分配的指针进行内存读写操作 在主机代码中，可以通过调用cudaMemcpy()来访问设备上的内存。这个函数调用的行为类型与标准C中的memcpy()，只不过多了一个参数来指定设备内存指针究竟是源指针还是目标指针。如，当最后一个参数为cudaMemcpyDeviceToHost时，代表运行时源指针是一个设备指针，而目标指针是以个主机指针。此外还有参数cudaMemcpyHostToDevice和cudaMemcpyDeviceToDevice等，如果源指针和目标指针都是位于主机上，那么可以直接调用标准C的memcpy()函数。 3.3查询设备对于拥有多个支持CUDA的设备，需要通过某种方式来确定使用的是哪一个设备。 首先，我们希望知道在系统中有多少个设备是支持CUDA架构的，并且这些设备能够运行基于CUDA C编写的核函数。要获得CUDA设备的数量，可以调用cudaGetDeviceCount()。12int count;HANDLE_ERROR(cudaGetDeviceCount(&amp;count)); 在调用cudaGetDeviceCount()后，可以对每个设备进行迭代，并查询各个设备的相关信息。CUDA runtime将返回一个cudaDeviceProp类型的结构，其中包含了设备的相关属性。相关属性的含义可见书p20。可以利用cudaGetDeviceProperties()来获得i号设备的属性: 12345678910111213#include &lt;iostream&gt;int main()&#123; cudaDeviceProp prop; int count; cudaGetDeviceCount(&amp;count); for(int i =0 ; i&lt; count; i++)&#123; cudaGetDeviceProperties(&amp;prop, i); //对设备的属性执行某些操作 &#125; std::cout&lt;&lt;count&lt;&lt;std::endl;&#125; 在知道了每个可用的属性以后，接下来就可以进行一些具体的操作，如：1std::cout&lt;&lt;prop.major&lt;&lt;std::endl; 3.4 设备属性的使用根据在cudaGetDeviceCount()和cudaGetDeviceProperties()中返回的结果，我们可以对每个设备进行迭代，来找到我们期望的某些达到要求的设备。但是这种迭代操作执行起来有些繁琐，因此CUDA runtime提供了一种自动方式来执行这个迭代操作。首先，找出希望设备拥有的属性并将这些属性填充到一个cudaDeviceProp结构。1234cudaDeviceProp prop;memset(&amp;prop, 0 , sizeof(cudaDeviceProp));prop.major = 1;prop.minor = 3; 之后，将该结构传递给cudaChooseDevice()，这样CUDA runtime运行时将查找是否存在某个设备满足这些条件，并返回一个设备ID，我们可以将这个设备ID传递给cudaSetDevice()。随后，所有的设备操作都将在这个设备上执行。 12345678910111213141516#include &lt;iostream&gt;using std::cout;using std::endl;int main()&#123; cudaDeviceProp prop; memset(&amp;prop, 0 , sizeof(cudaDeviceProp)); prop.major = 1; prop.minor = 3; int dev; cudaGetDevice(&amp;dev); cudaChooseDevice(&amp;dev, &amp;prop); cout&lt;&lt;"ID:"&lt;&lt;dev&lt;&lt;endl;&#125; 第四章 CUDA C并行编程4.1 本章目标 了解CUDA在实现并行性时采用的一种重要方式。 用CUDAC编写第一段并行代码 4.2 CUDA并行编程4.2.1 矢量求和运算假设有两组数据，将这两组数据中对应的元素两两想加，并将结果保存在第三个数组中。 基于CPU的矢量求和 123456789#define N 10void add(int *a, int *b, int *c)&#123; int tid = 0; //这是第0个CPU，因此索引从0开始 while(tid&lt;N)&#123; c[tid] = a[tid] + b[tid]; tid += 1; // 由于只有一个CPU，因此每次递增1 &#125;&#125; &emsp;&emsp;上面将代码特意写成方便修改为并行代码的形式，如，在双核处理器上，tid的设置可以分别为0和1，tid递增的大小可以改为2等。这就相当于在两个CPU上，一个执行奇数位想加，一个执行偶数位想加。 基于GPU的矢量求和 首先给出mian()函数： 123456789101112131415161718192021222324252627282930#define N 10int main()&#123; int a[N],b[N],c[N]; int *dev_a, *dev_b, *dev_c; //在GPU上分配内存，注意这里要知道为什么使用void** cudaMalloc( (void**)&amp;dev_a, N*sizeof(int)); cudaMalloc( (void**)&amp;dev_a, N*sizeof(int)); cudaMalloc( (void**)&amp;dev_a, N*sizeof(int)); ...//创建a，b数组并赋值 //将数组a，b复制到GPU cudaMemcpy(dev_a, a, N*sizeof(int),cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, N*sizeof(int), cudaMemcpyHostToDevice); add&lt;&lt;&lt;N,1&gt;&gt;&gt;(dev_a, dev_b, dev_c); //将数组c从GPU复制到CPU cudaMemcpy(c, dev_c, N*sizeof(int), cudaMemcpyDeviceToHost); ...//显式结果 //释放GPU上分配的内存 cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c); return 0;&#125; 看一下核函数的调用：1add&lt;&lt;&lt;N,1&gt;&gt;&gt;(dev_a, dev_b, dev_c); 尖括号中的两个数值将传递给runtime，作用是告诉runtime如何启动核函数： 第一个参数：表示设备在执行款核函数时使用的并行线程块的数量。 参数二：需要多少个线程格（Grid）（一格表示N个线程块的集合） 我们将每个并行执行环境都称为一个线程块（Block），对于此例，将有N个线程块在GPU上运行（N个运行核函数的副本）。 问题：如何在代码中知道当前正在运行的是哪一个线程块？ 回答：利用变量blockIdx.x 。 这是一个内置变量，在CUDA runtime中已经预先定义了这个变量，无需在代码中声明，该变量中包含的值就是当前执行设备代码的线程块的索引。 接下来是GPU版本的add()函数： 123456__global__ void add(int *a, int *b, int *c)&#123; int tid = blockIdx.x; //计算机该索引处的数据 if(tid &lt; N) c[tid] = a[tid] + b[tid];&#125; 当启动核函数时，我们将并行线程块的数量指定为N。这个并行线程块集合就称为一个“线程格（Grid）”。因此，此例表示我们想要一个一维的线程格，其中每个线程格包含N个线程块，每个线程块的blockInx.x的值都是不同的，cuda会为每个设备代码副本提供不同的blockInx.x。 需要注意的一点是：在启动线程块数组时，数组每一维（N）的最大数量不能超过65535。这是一种硬件限制，如过启动的线程块数量超过了这个限制，那么程序将运行失败。 4.2.2 一个有趣的示例绘制Julia集的曲线 Julia集算法：通过下面的迭代等式对复平面中的点求值。如果在计算某个点时，迭代等式的计算结果是发散的，那么这个点就不属于Julia集合。 Z_{n+1} = Z_n^2 + C 基于CPU的Julia集 先看main函数，它通过工具库创建了一个大小合适的位图图像，接着，将一个指向位图数据的指针传递给了核函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//julia.cpp#include&lt;iostream&gt;#include "opencv2/core/core.hpp"#include "opencv2/highgui/highgui.hpp"using namespace cv;void kernel(Mat&amp; M);int julia(int x, int y);//定义一个通用结构来保存复数值,r为实部，i为虚部struct cuComplex&#123; float r; float i; cuComplex(float a , float b ):r(a),i(b)&#123;&#125; float magnitude2()&#123;return r*r+i*i;&#125; cuComplex operator*(const cuComplex&amp; a)&#123; return cuComplex(r*a.r-i*a.i, i*a.r + r*a.i); &#125; cuComplex operator+(const cuComplex&amp; a)&#123; return cuComplex(a.r+r, a.i+i); &#125;&#125;;int DIM = 800;int main()&#123; cv::Mat M(DIM,DIM,CV_8UC1); kernel(M); imshow("Test",M); //窗口中显示图像 imwrite("E:/灰度图.jpg",M); //保存生成的图片 waitKey(0); //等待按任意键后窗口自动关闭 getchar(); return 0;&#125;void kernel(Mat&amp; M)&#123; for (int y=0;y&lt;M.rows;y++)//遍历每一行每一列并设置其像素值 &#123; for (int x=0;x&lt;M.cols;x++) &#123; int juliaValue = julia(x,y); M.at&lt;uchar&gt;(x,y)=155*juliaValue+100; &#125; &#125;&#125;//判断函数，如果该点属于集合返回1，否则返回0int julia(int x, int y)&#123; const float scale = 1.5; float jx = scale*(float)(DIM/2 - x)/(DIM / 2); float jy = scale*(float)(DIM/2 - y)/(DIM / 2); cuComplex c(-0.8, 0.154); cuComplex a(jx,jy); int i = 0; for(i = 0; i&lt;200; i++)&#123; a = a*a+c; if(a.magnitude2() &gt; 1000) return 0; &#125; return 1;&#125; 下面是kernel核函数对将要绘制的所有点进行迭代，并在每次迭代时调用julia来判断该点是否属于Julia集（“是”则涂红色，“否”则涂黑色）。 该函数首先将像素坐标转换为复数空间的坐标，为了将复平面的原点定位到图像中心，代码将像素位置移动了MID/2，然后，为了确保图像的范围为-1.0到1.0，我们将图像的坐标缩放了DIM/2倍。在计算处复空间中的点之后，需要判断这个点是否属于Julia集。通过迭代判断（本示例迭代200次，在每次迭代完成后，都会判断结果是否超过某个阈值），如果属于集合，就返回1，否则，返回0。最后运行指令g++ julia.cpppkg-config —cflags —libs opencv-o julia生成的效果图如下： 基于GPU的Julia集 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include&lt;iostream&gt;#include &quot;opencv2/core/core.hpp&quot;#include &quot;opencv2/highgui/highgui.hpp&quot;using namespace cv;__global__ void kernel(unsigned char* ptr);__device__ int julia(int x, int y);const int DIM = 800;struct cuComplex&#123; float r; float i; __device__ cuComplex(float a , float b ):r(a),i(b)&#123;&#125; __device__ float magnitude2()&#123;return r*r+i*i;&#125; __device__ cuComplex operator*(const cuComplex&amp; a)&#123; return cuComplex(r*a.r-i*a.i, i*a.r + r*a.i); &#125; __device__ cuComplex operator+(const cuComplex&amp; a)&#123; return cuComplex(a.r+r, a.i+i); &#125;&#125;;int main()&#123; cv::Mat M(DIM,DIM,CV_8UC1); unsigned char bitmap[DIM][DIM]; unsigned char *dev_bitmap; //定义一定char二维数组，用来存储GPU传过来的结果 cudaMalloc(&amp;dev_bitmap, DIM*DIM); dim3 grid(DIM,DIM); kernel&lt;&lt;&lt;grid,1&gt;&gt;&gt;(dev_bitmap); cudaMemcpy(bitmap,dev_bitmap, DIM*DIM , cudaMemcpyDeviceToHost); for (int y=0;y&lt;M.rows;y++) //遍历每一行每一列并设置其像素值 &#123; for (int x=0;x&lt;M.cols;x++) &#123; M.at&lt;uchar&gt;(x,y)=bitmap[y][x]; //M.at&lt;uchar&gt;(x,y)=juliaValue+100; &#125; &#125; imshow(&quot;Test&quot;,M); //窗口中显示图像 waitKey(0); getchar(); return 0;&#125;__global__ void kernel(unsigned char* ptr)&#123; int x = blockIdx.x; int y = blockIdx.y; int offset = x+ y*gridDim.x; int juliaValue = julia(x,y); ptr[offset] = 255*juliaValue;&#125;__device__ int julia(int x, int y)&#123; const float scale = 1.5; float jx = scale*(float)(DIM/2 - x)/(DIM/2); float jy = scale*(float)(DIM/2 - y)/(DIM/2); cuComplex c(-0.8, 0.156); cuComplex a(jx,jy); int i = 0 ; for(i = 0; i&lt;200; i++)&#123; a = a*a +c; if(a.magnitude2() &gt; 1000) return 0; &#125; return 1;&#125; 这里需要注意的是，在程序中指定了多个并行线程块来执行函数kernel。并且，使用了一种新的类型来声明了一个二维的线程格：1dim3 grid(DIM, DIM); 类型dim3并不是标准C定义的类型，它可以表是一个三维数组，至于为什么不直接用二维数组，CUDA开发人员主要是为了日后的扩展，所以用三维数组来表示二维数组，数组的第三维默认为1。下面的代码将线程块grid传递给CUDA运行时：1kernel&lt;&lt;&lt;grid,1&gt;&gt;&gt;(dev_bitmap); 代码中还使用了修饰符__device__，这代表代码将在GPU而不是主机上运行，由于这些函数已声明为__device__，因此只能从其他__device__函数或者__global__函数中调用它们。 通常，我们将在GPU上启动的线程块集合称为一个线程格。从名字的含义可以看出，线程格既可以是一维的线程块集合，也可以是二维的线程块集合。核函数的每个副本都可以通过内置变量blockIdx来判断哪个线程块正在执行它。塌秧，还可以通过内置变量gridDim来获得线程格的大小。 第五章 线程协作5.1 本章目标 了解CUDA C中的线程 了解不同线程之间的通信机制 了解并行执行线程的同步机制 5.2 并行线程块的分解当启动核函数时，我们会指定第一个参数的值，也就是指定多个并行副本，我们将这些兵行副本称为线程块（Block）。尖括号中的第二个参数表示CUDA运行时在每个线程块中创建的线程数量，因此，总共启动的线程数量可按下面的公式计算： N个线程块 \times M个线程每线程块 = N个并行线程5.2.1 矢量求和：重新回顾使用线程块中的并行线程，能够完成一些并行线程块无法完成的工作。 1.使用线程实现GPU上的矢量求和（即在一个线程块内设置多条线程）相较于之前的矢量求和，需要修改两个地方，第一是将下面的代码#1式改成代码#2式：123add&lt;&lt;&lt;N,1&gt;&gt;&gt;(dev_a, dev_b, dev_C);add&lt;&lt;&lt;1,N&gt;&gt;&gt;(dev_a, dev_b, dev_c); 第二是修改索引方式，有限现在只有一个线程块，所以不能再用blockIdx来获取索引了，而应使用线程索引，如下所示：1int tid = threadIdx.x; 完整的代码如下所是：12345678910111213141516171819202122232425262728293031323334353637#include&lt;iostream&gt;const int N = 10;/*#define N 20*/__global__ void add(int * dev_a, int* dev_b, int* dev_c)&#123; int tid = threadIdx.x; //注意此处使用的是线程索引 if(tid&lt;N) dev_c[tid] = dev_a[tid] + dev_b[tid];&#125;int main()&#123; int a[N]; int b[N]; int c[N]; for(int i=0;i&lt;N;i++) a[i]=i; for(int i=0;i&lt;N;i++) b[i]=i; int* dev_a; int* dev_b; int* dev_c; cudaMalloc(&amp;dev_a, sizeof(int)*N); cudaMalloc(&amp;dev_b, sizeof(int)*N); cudaMalloc(&amp;dev_c, sizeof(int)*N); cudaMemcpy(dev_a,a,sizeof(int)*N, cudaMemcpyHostToDevice); //第一个参数为目的地址，第二个为原地址，第三个为空间大小 cudaMemcpy(dev_b,b,sizeof(int)*N, cudaMemcpyHostToDevice); add&lt;&lt;&lt;1,N&gt;&gt;&gt;(dev_a,dev_b,dev_c); //线程块数为1，每块内的线程数为N cudaMemcpy(c, dev_c, sizeof(int)*N, cudaMemcpyDeviceToHost); for(auto x:c) std::cout&lt;&lt;x&lt;&lt;std::endl;&#125; 2.在GPU上对更长的矢量求和之前在第四章我们提到，由于硬件原因，线程块的数量不能超过65535。 同样，对于启动核函数时每个线程块中的线程数量，也有一定的限制。具体来说，最大的线程数量不能超过设备属性结构中maxThreadsPerBlock域的值。对于很多图形处理器而言，这个限制值是每个线程块512个线程（目前GTX 980Ti为1024个）。通过下面的代码可以获得当前机器上的最大线程数：12345678910111213#include &lt;iostream&gt;int main()&#123; cudaDeviceProp prop; int count; cudaGetDeviceCount(&amp;count); for(int i =0 ; i&lt; count; i++)&#123; cudaGetDeviceProperties(&amp;prop, i); std::cout&lt;&lt;count&lt;&lt;std::endl; std::cout&lt;&lt;prop.maxThreadsPerBlock&lt;&lt;std::endl; &#125;&#125;//output：1024 为了通过并行对长度大于1024的矢量进行相加，必须将线程和线程块结合起来才能实现，因此仍然需要改动两个地方：核函数中的索引计算方法和核函数的调用方式：（使用多个线程块，并且每个线程块包含多个线程） 首先是修改索引计算方法：12int tid = threadIdx.x + blockIdx.x * blockDim.x; 在上面的赋值语句中使用了一个新的内置变量，blockDim。对于所有线程块来说，这个变量是一个常数，保存的是线程块中每一维的线程数量。（回顾第四章，在gridDim中保存了一个类似的值，即在线程格中每一维的线程块数量。但要知道，gridDim是二维的，blockDim是三维的，只是很少用的高维索引值） 另一处修改是核函数调用本身，为了保证最终启动的线程数量不少于预期量，可以通过一种常见的技术来对需要启动的线程块数量进行向上取整，如下所示：1add&lt;&lt;&lt; (N+127)/128, 128 &gt;&gt;&gt; (dev_a, dev_b, dev_c); 上面的代码当N不是128的整数倍时，会启动过多的线程，这时候，判断语句if (tid&lt;N)就表现处作用了，它可以确保进行计算的线程的不会对越过数组边界的内存进行读取或写入：12if (tid &lt; N) c[tid] = a[tid] + b[tid]; 3.在GPU上对任意长度的矢量求和]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DenseNet-xxx]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-DenseNet%2F</url>
    <content type="text"></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>网络模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【置顶】基于深度学习的目标检测综述]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[前言本文是对目标检测相关算法和模型的一个梳理和综述。文中有关模型的解读和阐述大多是笔者自己的理解和平时学习的积累，在这里整理成文分享给大家。另外，由于笔者水平有限，所以肯定也有不全面或者说的不对的地方，大家如果发现的话，欢迎批评指正。 重要参考： https://github.com/hoya012/deep_learning_object_detection Deep Learning for Generic Object Detection: A Survey 基于深度学习的目标检测发展轨迹下图为自RCNN以来，提出的有关目标检测的文章，其中，标红的部分为具有标志性意义的检测模型。 标志性模型介绍其他模型简介]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Inception系列V1-V4]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Inception%E7%B3%BB%E5%88%97V1-V4%2F</url>
    <content type="text"><![CDATA[Inception V1论文概览Going Deeper with Convolutions 摘要文章提出了一个深度卷积神经网络结构，并取名为Inception。该模型最主要的特点在于提高了网络内部计算资源的利用率。在保证计算负载不变的前提下，通过人工设计提升了网络的深度和宽度。该模型基于Hebbian原理和多尺度处理的intuition来提高性能。关于该模型的一个实例正是提交在ILSVRC14上的GoogLeNet，一个22层深的深度网络，主要针对分类和检测任务。 1.介绍简要介绍了深度学习和神经网络技术近年来在图像分类和目标检测任务的发展。文章主要关注针对计算机视觉的高效深度神经网络，取名为Inception，名字来自于NIN。在文章中，“deep”具有两层含义：第一，指代文章新提出的Inception module，第二是指网络的深度。通常情况下，可以将Inception model视作NIN的“逻辑顶点”。 2.相关工作略 3.动机和High Level的考虑提高深度卷积网络最直接的方式就是增加它们的size，包括网络的深度（层数）和宽度（每层的神经元个数），这对于高质量的网络结构来说是ok的，尤其是在拥有大量优质数据的情况下。但是，这种方法存在这两个主要的缺点： 更大的size通常意味着更多的参数，这会使得网络更容易过拟合，尤其是在数据标签有限的情况下。由于获得大量优质数据具有一定难度，因此这往往会称为一个主要的瓶颈。 第二个缺点就是更大的size往往需要消耗更多的计算资源 文章认为解决以上问题的一个经济可行的办法是将全连接层置换成稀疏连接结构，甚至是在卷积内。 目前的硬件结构在面对非均匀分布的稀疏数据结构时，计算效率很低。 为此，文章希望找到一个新的结构，可以更高效的处理稀疏矩阵的运算。 文章通过多个实验验证了Inception模型在面对图像分类和检测问题时，可以取得十分好的效果。但是，对于Inception model是否能够成为其他领域任务的指导原则，还尚未有定论，需要更多的验证和实验才能说明。 4.框架细节Inception模型的一个核心思想在于找到 卷积网络中的最优局部稀疏结构可以在多大程度上被稠密组件近似和覆盖 。需要注意，由于假设了平移不变性，因此本文的模型将从卷积模块中开始建立，本文所需要做的就是找到一个局部最优结构，然后将这些结构在空间上组合起来。 为了避免path-alignment问题，现在滤波器大小设值为1×1,3×3,和5×5。 由于pooling层的重要性，本文才采用了pooling层。 将上面的Inception模块叠加起来，形成一个整体的模型。 但是直接叠加会使得向量维度剧增，因此，通过1×1卷积来控制维度。 当max pooling层的stride为1时，并不会缩小输出的feature map的size，只会影响depth的值。 关于此结构的一个好处在于它可以提高神经元的个数，同时避免网络不受控制的提升计算机复杂度。 5. GooLeNet GoogLeNet的网络结构图细节如下： GoogLeNet网络结构明细表解析如下： 0、输入 原始输入图像为224x224x3，且都进行了零均值化的预处理操作（图像每个像素减去均值）。 1、第一层（卷积层） 使用7x7的卷积核（滑动步长2，padding为3），64通道，输出为112x112x64，卷积后进行ReLU操作经过3x3的max pooling（步长为2），输出为((112 - 3+1)/2)+1=56，即56x56x64，再进行ReLU操作 2、第二层（卷积层） 使用3x3的卷积核（滑动步长为1，padding为1），192通道，输出为56x56x192，卷积后进行ReLU操作 经过3x3的max pooling（步长为2），输出为((56 - 3+1)/2)+1=28，即28x28x192，再进行ReLU操作 3a、第三层（Inception 3a层） 分为四个分支，采用不同尺度的卷积核来进行处理 （1）64个1x1的卷积核，然后RuLU，输出28x28x64 （2）96个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x96，然后进行ReLU计算，再进行128个3x3的卷积（padding为1），输出28x28x128 （3）16个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x16，进行ReLU计算后，再进行32个5x5的卷积（padding为2），输出28x28x32 （4）pool层，使用3x3的核（padding为1），输出28x28x192，然后进行32个1x1的卷积，输出28x28x32。将四个结果进行连接，对这四部分输出结果的第三维并联，即64+128+32+32=256，最终输出28x28x256 3b、第三层（Inception 3b层） （1）128个1x1的卷积核，然后RuLU，输出28x28x128 （2）128个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x128，进行ReLU，再进行192个3x3的卷积（padding为1），输出28x28x192 （3）32个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x32，进行ReLU计算后，再进行96个5x5的卷积（padding为2），输出28x28x96 （4）pool层，使用3x3的核（padding为1），输出28x28x256，然后进行64个1x1的卷积，输出28x28x64。 将四个结果进行连接，对这四部分输出结果的第三维并联，即128+192+96+64=480，最终输出输出为28x28x480 第四层（4a,4b,4c,4d,4e）、第五层（5a,5b）……，与3a、3b类似，在此就不再重复。 要点整理说明一下GoogLeNet采用多个卷积核的动机NIN网络和Inception Module这类结构非常看中模型在局部区域的拟合能力。它们认为：一张图像通常具有总体特征和细节特征这两类特征，一般小卷积核能够更好的捕捉一些细节特征，随着深层网络的小卷积不断计算下去，总体特征也会慢慢的被提炼出来，但是这样存在一个问题，那就是在如果只采用小卷积，那么网络结构的前段一般只有细节特征，后段才慢慢有一些总体特征，而我们希望这两方面的特征总是能够一起发挥作用，因此，上面的两种模型考虑采用更多不同尺寸的卷积核来提取特征，并把这些特征连接起来，一起送到后面的网络中去计算，使得网络可以获取到更多的特征信息。 Inception模块还采用了一个stride为1的max pooling层，它的主要功能是减少空间大小，降低过拟合风险（只选最大值，所以值的范围变少了）。 Inception中为什么使用1×1卷积？1×1卷积的作用是什么？关于Inception Module，有一种很直接的做法就是将1×1,3×3,5×5卷积和3×3 max pooling直接连接起来，如下面的左图所示，但是这样的话就有个问题，那就是计算量增长太快了。 为了解决这个问题，文章在3×3和5×5的卷积之前，3×3max pooling之后使用了1×1卷积，使其输出的feature map的depth降低了，从而达到了降维的效果，抑制的过快增长的计算量。 1×1卷积核的作用：1x1卷积的主要目的是为了减少维度，还用于修正线性激活（ReLU）。比如，上一层的输出为 100x100x128，经过具有256个通道的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256，其中，卷积层的参数为128x5x5x256= 819200。而假如上一层输出先经过具有32个通道的1x1卷积层，再经过具有256个输出的5x5卷积层，那么输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256= 204800，大约减少了4倍 1×1的卷积核，在一定程度上可以实现全连接层：具体的操作是，输入是224x224x3 的图像，假设经过变换之后最后一层是[7x7x512]的，那么传统的方法应该将其展平成为一个7x7x512长度的一层，然后做全连接层，假设全连接层为4096×1000层的（假设有1000个分类结果）。 那么用1×1卷积核怎么做呢，因为1×1卷积核相当于在不同channel之间做线性变换，所以： 先选择7×7的卷积核，输出层特征层数为4096层，这样得到一个[1×1×4096]层的 然后再选择用1×1卷积核，输出层数为1000层，这样得到一个[1×1×1000]层的 用卷积层代替全连接层的好处：这样做其实有非常多的好处，比如上面的例子中输入是224x224x3 的图像，如果此时图像变得更大了，变成384x384大小的了，那么一开始按照32作为步长来进行卷积操作，最后还按照这个网络结构能得到一个[6×6×1000]层的，那么前面那个[6×6]有什么用呢，这个代表每一个位置上，其属于1000个分类结果中的打分，所以这在图像分割等领域等领域有着非常重要的作用【之前一篇论文就是用的这种方法Fully Convolutional Networks for Semantic Segmentation】。 Auxiliary Classifier当时Inception网络还是太深了，不好训练，因此网络中还加了两个侧枝，通过中间层的feature map，来得到预测结果（有了ResNet的shortcut以后，这种侧枝用的比较少了）。 为什么使用侧枝？为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度（辅助分类器）。辅助分类器是将中间某一层的输出用作分类，并按一个较小的权重（0.3）加到最终分类结果中，这样相当于做了模型融合，同时给网络增加了反向传播的梯度信号，也提供了额外的正则化，对于整个网络的训练很有裨益。而在实际测试的时候，这两个额外的softmax会被去掉。也就是说在测试的时候，只会用最后的softmax结果作为分类依据。 Inception Model有没有使用全连接层？在两个侧枝使用了卷积+FC+FC+SoftmaxActivation的结构，在最后一层使用了全局平均池化+FC+SoftmaxActivation的结构。 LRN：LocalRespNormInception V2论文概览Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift 要点整理GoogLeNet设计的初衷就是要又准又快，而如果只是单纯的堆叠网络虽然可以提高准确率，但是会导致计算效率有明显的下降，所以如何在不增加过多计算量的同时提高网络的表达能力就成为了一个问题。 Inception V2版本的解决方案就是 修改Inception的内部计算逻辑，提出了比较特殊的“卷积”计算结构。 卷积分解（Factorizing Convolutions）主要受到VGG的启发 大尺寸的卷积核可以带来更大的感受野，但也意味着会产生更多的参数，比如5×5卷积核的参数就有25个（不算depth和filters的数量）。因此，GoogLeNet团队提出可以用2个连续的3×3卷积层组成的小网络来代替单个的5×5卷积层，即在 保持感受野范围的同时又减少了参数量，如下图： 大量实验表明，这种分解并不会造成表达缺失，那么是否可以进一步分解，GoogLeNet团队尝试了n×1的卷积核，如下图所示，用3个3×1取代3×3卷积： 因此，任意nxn的卷积都可以通过1xn卷积后接nx1卷积来替代。GoogLeNet团队发现在网络的前期使用这种分解效果并不好，在中度大小的特征图（feature map）上使用效果才会更好（特征图大小建议在12到20之间）。 降低特征图大小一般情况下，如果想让图像缩小，可以有如下两种方式： 前者先做pooling会导致在做卷积的时候缺少特征，后者是在卷积计算后，提取完特征以后进行的正常的图像缩小，但是计算量很大（卷积计算比pooling计算复杂）。为了同时保持特征表示且降低计算量，将网络结构改为下图，使用两个并行化的模块来降低计算量（卷积、池化并行执行，最后再进行合并）。 网络结构使用Inception V2作改进版的GoogLeNet，网络结构图如下： 注：上表中的Figure 5指没有进化的Inception，Figure 6是指小卷积版的Inception（用3x3卷积核代替5x5卷积核），Figure 7是指不对称版的Inception（用1xn、nx1卷积核代替nxn卷积核）。 Batch NormalizatinBatch Normalization, 批标准化, 和普通的数据标准化类似, 是将分散的数据统一的一种做法, 也是优化神经网络的一种方法. 详见: Inception V3论文概览要点整理]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>网络模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++创建对象时new与不new的区别]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E6%97%B6new%E4%B8%8E%E4%B8%8Dnew%2F</url>
    <content type="text"><![CDATA[C++在创建对象的时候可以采用两种方式：（例如类名为Test） Test test 或者 Test* pTest = new Test()。这两种方法都可以实例化一个对象，但是这两种方法有很大的区别，区别在于对象内容所在的内存空间不同，众所周知，内存的分配方式有三种（1）从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static 变量。（2） 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束后在将这些局部变量的内存空间回收。在栈上分配内存空间效率很高，但是分配的内存容量有限。（3） 从堆上分配的。程序在运行的时候用 malloc 或 new 申请任意多少的内存，程序员自己负责在何时用 free 或 delete 释放内存。那么当使用Test test给对象分配内存空间的时候，是分配在堆中的还是栈中的呢？ 在不使用new创建对象时，对象的内存空间是在栈中的，其作用范围只是在函数内部，函数执行完成后就会调用析构函数，删除该对象。 而使用new创建对象是创建在堆中的，必须要程序员手动的去管理该对象的内存空间。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VIM指令速查及常用技巧]]></title>
    <url>%2Fz_post%2FLinux-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-VIM%E6%8C%87%E4%BB%A4%E9%80%9F%E6%9F%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[VIM 常用指令fa,i,r,o,A,I,R,O 进入编辑模式h,backspace 左移动 l,space 右移动 j 下移动 k 上移动0 移动到行首$ 移动到行末 1$表示当前行的行尾，2$表示当前行的下一行的行尾b 按照单词向前移动 字首e 按照单词向后移动 字尾w 按照单词向后移至次一个字首H 移动到屏幕最上 非空白字M 移动到屏幕中央 非空白字L 移动到屏幕最下 非空白字G 移动到文档最后一行gg 移动到文档第一行v 进入光标模式，配合移动键选中多行Ctrl+f 向下翻页Ctrl+b 向上翻页u 撤销上一次操作.. 回到上次编辑的位置dw 删除这个单词后面的内容dd 删除光标当前行dG 删除光标后的全部文字d$ 删除本行光标后面的内容d0 删除本行光标前面的内容y 复制当前行，会复制换行符yy 复制当前行的内容yyp 复制当前行到下一行，此复制不会放到剪切板中nyy 复制当前开始的n行 全选（高亮显示）：按esc后，然后ggvG或者ggVG 全部复制：按esc后，然后ggyG 全部删除：按esc后，然后dG 二、复制多行任务：将第9行至第15行的数据，复制到第16行 方法1：（强烈推荐）：9，15 copy 16 或 ：9，15 co 16由此可有：：9，15 move 16 或 :9,15 m 16 将第9行到第15行的文本内容到第16行的后面 ubuntu系统, 默认不支持系统剪切板与vim的交互, 需要先安装一个东西: sudo apt-get install vim-gnome 再set clipboard=unnamed 然后就可以使用ggyG了 选中指定行：方法3：把光标移到第9行 shift + v再把光标移动到第15行 Vim 有12个粘贴板依次编号为：0、1、2、…、9、a、”、+，其中 + 号为系统粘贴板，” 为临时粘贴板。系统剪切板中的内容可在其他程序中使用。上面的复制指令都可以配合剪切板进行操作。kj “nyw 复制当前单词到 n 号剪切板（双引号开始）“np 粘贴 n 号剪切板内容到当前位置后“+Y 复制当前行到系统剪切板“+nY 复制当前行往下 n 行到系统剪切板“+p 粘贴系统剪切板内容到当前位置后 “+yy // 复制当前行到剪切板“+p // 将剪切板内容粘贴到光标后面“ayy // 复制当前行到寄存器 a“ap // 将寄存器 a 中的内容粘贴到光标后面 p,P,. 粘贴ddp 当前行和下一行互换位置J 合并行Ctrl+r 恢复刚才撤销（u）的动作Ctrl+z 暂停并退出ZZ 保存离开xp 交换字符后面的交换到前面~ 更换当前光标位置的大小写，并光标移动到本行右一个位置，直到无法移动 Ctrl+e 向下滚动Ctrl+b 向上翻页b 按照单词向前移动 字首B 按照单词向前移动 字首 忽略一些标点符号e按照单词向后移动 字尾E 按照单词向后移动 忽略一些标点符号w 按照单词向后移至次一个字首W 按照单词向后移至次一个字首 忽略一些标点符号 H 移动到屏幕最上 非空白字M 移动到屏幕中央 非空白字L 移动到屏幕最下 非空白字 G 移动到文档最后一行gg 移动到文档第一行( 光标到句尾) 光标到局首{ 光标到段落开头} 光标到段落结尾nG 光标下移动到n行的首位n$ 光标移动到n行尾部n+ 光标下移动n行n- 光标上移动n行 zz将当前行移到屏幕中部，zb移到底部,zt 顶部 * 向下查找同样光标的字符# 向上查找同样光标的字符/code 查找 code 一样的内容，向后?code 查找 code 一样的内容，向前n 查找下一处N 查找上一处ma 在光标处做一个名叫a的标记 可用26个标记 (a~z)`a 移动到一个标记ad`a 删除当前位置到标记a之间的内容:marks 查看所有标记 :q 一般退出:q! 退出不保存:wq 保存退出:w filename 另存为 filename:jumps 历史编辑文档记录 ctrl+i，ctrl+o跳转位置, Ctrl+f 向文件尾翻一屏幕Ctrl+b 向文件首翻一屏幕Ctrl+d 向文件尾翻半屏幕Ctrl+u 向文件首翻半屏幕 i 在光标前I 在当前行首a 在光标后A 在当前行尾部o 在当前行下新开一行O 在当前行上新开一行r 替换当前字符R 替换当前行及后面的字符，直到按esc为止s 从当前行开始，以输入的文本替代指定数目的字符S 删除指定数目的行，并以输入的文本替代ncw,nCW 修改指定数目n的字符nCC 修改指定数目n的行 x 删除当前光标字符X 删除光标前字符nxnX dw 删除到下一个单词开头de 删除到本单词末尾dE 删除到本单词末尾包括标点在内db 删除到前一个单词dB 删除到前一个单词包括标点在内 ndw,nDW 删除光标开始及其后 n-1 个worddw 删除这个单词后面的内容dd 删除光标当前行dG 删除光标后的全部文字d$ 删除本行光标后面的内容d0 删除本行光标前面的内容ndd 删除当前行，以及其后的n-1行x 删除一个字符，光标后X 删除一个字符，光标前Ctrl+u 删除输入模式下的输入的文本 :split 创建新窗口Ctrl+w 切换窗口Ctrl-w = 所有窗口一样高Ctrl-w+方向键 多窗口视图切换 :args 列出当前编辑的文件名:next 打开多文件，使用 n(Next) p(revious) N(ext) 切换:file 列出当前打开的所有文件 替換（substitute） :[range]s/pattern/string/[c,e,g,i]]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《CUDA并行程序设计-GPU编程指南》]]></title>
    <url>%2Fz_post%2FCUDA-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CUDA%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1_GPU%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[前言部分——本书编排： 第一章：从宏观上介绍流处理器（streaming processor）的演变历史。 第二章：介绍并行编程的概念，建立基本认识。 第三章：详尽地讲解CUDA设备及与其紧密相关的硬件和架构。 第四章：介绍了如何在Windows、Mac和Linux等不同操作系统上安装和配置CUDA软件开发工具包。 第五章：介绍CUDA线程模型。 第六章：详细讲解了不同类型内存的工作机制。 第七章：详述了如何在若干任务中恰当地协同CPU和GPU。 第八章：介绍如何在应用程序中编写和使用多GPU。 第九章：对CUDA编程中限制性能的主要因素予以讲解。 第十章：介绍了CUDA软件开发工具包的示例和CUDA提供的库文件。 第十一章：关注构建自己的GPU服务器或者GPU集群时的几个问题。 第十二章：检视多数程序员在开发CUDA应用程序时易犯的错误类型。 第一章 超级计算机简史简介``]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HelloCUDA]]></title>
    <url>%2Fz_post%2FCUDA-CUDA%E7%A4%BA%E4%BE%8B%E5%AD%A6%E4%B9%A0-HelloCUDA%2F</url>
    <content type="text"><![CDATA[1234567891011121314//hellocuda.cu#include &lt;iostream&gt;#include "stdio.h"__global__ void kernel(void)&#123; printf("hello, cvudakernel\n");&#125;int main(void)&#123; kernel&lt;&lt;&lt;1,5&gt;&gt;&gt;(); cudaDeviceReset(); return 0 ;&#125; 在命令行执行12$nvcc hellocuda.cu -o hellocuda$./hellocuda 输出结果：12345hello, cvudakernelhello, cvudakernelhello, cvudakernelhello, cvudakernelhello, cvudakernel]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA示例学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中typeid实现原理和使用方法]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84typeid%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[先好好理解一下C++的typeid运算符到底是什么意思，再问“原理是什么”会比较好。先看这里学习typeid是什么意思：typeid operator针对题主给的例子：int i = 1;const char* name = typeid(i).name(); 这里的typeid(i)根本不需要做任何运行时动作，而是纯编译时行为——它使用变量i的静态类型直接就知道这是对int类型做typeid运算，于是可以直接找出int对应的std::type_info对象返回出来。 If expression is not a glvalue expression of polymorphic type, typeid does not evaluate the expression, and the std::type_info object it identifies represents the static type of the expression. Lvalue-to-rvalue, array-to-pointer, or function-to-pointer conversions are not performed.此时的typeid运算符就跟sizeof运算符的大部分情况一样，只需要编译器算出表达式的静态类型就足够了。算出表达式的静态类型是C++编译器的基本功能了，类型检查、类型推导等许多功能都依赖它。而当typeid运算符应用在一个指向多态类型对象的指针上的时候，typeid的实现才需要有运行时行为。If expression is a glvalue expression that identifies an object of a polymorphic type (that is, a class that declares or inherits at least one virtual function), the typeid expression evaluates the expression and then refers to the std::type_info object that represents the dynamic type of the expression. If the glvalue expression is obtained by applying the unary operator to a pointer and the pointer is a null pointer value, an exception of type std::bad_typeid or a type derived from std::bad_typeid is thrown.实际实现的时候，通常是在类的vtable里会有个slot保存着指向该类对应的std::type_info对象的指针。要形象的理解的话，请参考我在另一个回答里画的图：为什么bs虚函数表的地址（int）(&amp;bs)与虚函数地址（int）(int*)(&amp;bs) 不是同一个？ - RednaxelaFX 的回答可以看到Clang++在LP64上用的vtable布局，不禁用RTTI时，在-8偏移量上的slot就是存typeinfo指针的。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Image-Generation-from-Scene-Graphs]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-Image_Generation_from_Scene_Graphs%2F</url>
    <content type="text"><![CDATA[本篇论文解读的排版主要参见原文的格式，针对原文中的每一个小节进行展开，有的是对原文的一个提炼和简单概括，有的是对原文中一些要点的补充和说明。 摘要&emsp;&emsp;近几年来（至2018），针对某些特定目标（花，鸟等）的图片生成已经取得了令人激动的研究成果，但是当文本描述中包含多个物体和物体之间的关系时，仍然具有一些困难。 为了克服这一点，本文提出了从场景图来生成图片的方法，该方法可以推理出具体的物体和物体之间的关系。 本文的模型使用“图卷积层”（graph convolution）来处理输入的“图”（graph），通过预测物体的bounding boxes和segmentation masks来计算“场景布局”（scene layout），然后利用“级联精细化网络”（cascaded refinement network）将“场景布局”转换成一张图片输出。在训练网络时，通过对抗式的训练一对儿discriminators来确保生成图片的真实感。 本文在Visual Genome和COCO-Stuff数据集是验证了以上模型的有效性，结合高质量的生成图片、消融实验和人工调研的方法证明了本文提出的模型可以生成含有多个物体的复杂图片。 介绍——IntroductionWhat I cannot create，I do not understand —— Richar Feynman &emsp;&emsp;要想让计算机生成图片，就需要令其对图片有更深刻的理解。 &emsp;&emsp;为了达到以上目标，目前在text to image synthesis领域已经有许多的工作成果。这些模型可以在limited domains内产生十分惊人的结果，但是当文本信息变得复杂起来时，其生成出来的图片就不尽人意了。 &emsp;&emsp;句子通常都是由一个单词接一个单词组成的线性结构，但是，一个复杂的句子，其内部携带的信息，通常需要由基于物体的“场景图”在具体表示，“场景图”中包含物体和物体之间的关系。“场景图”作为表征图片和文本的强有力的工具，常常被用于语义图片检测、提高和评价图片描述领域中。也有关于将自然语言或图片转换成“场景图”的研究。 22,1，31,47,32,36，57,58 &emsp;&emsp;本篇文章的主要研究目的是在“场景图”约束条件下，生成带有多个物体和物体之关系的复杂图片。这一任务也带来了许多新的挑战。首先，必须要找到可以处理场景图的输入方法，对此本文使用了“graph convalution network”，它可以沿着“场景图”的“边”将信息传递。处理完“图”以后，还必须建立图结构的输入与二维图片的输出之间的联系。为此 ，本文通过预测图中所有物体的bounding boxes和segmentation masks构建了“场景布局（scene layout）”。得到“布局”以后，就需要生成图片，本文使用了“cascaded refinement network（CRN）”，它可以不断增大空间尺寸，生成图片。 最后，我们必须确保生成的图片具有一定的真实感并且包含多个可辨识的物体，为此我们针对image patches和generated objects训练了一对儿discriminator网络。另外，所有的模型可以进行端到端的联合训练。 &emsp;&emsp;我们在2个数据集上进行了实验：Visual Genome（提供人工标注的场景图）和COCO-stuff（从真实的物体位置生成场景图）。两个数据集的生成结果都证明了本文提出的方法的可以生成包含多个物体并且反映它们之间关系的复杂图片。同时，还进行了综合的消融实验来验证本文提出的模型中每一部分的有效性。 相关工作——Related Work&emsp;&emsp;生成图片模型 Generative Image Models 目前，生成模型主要可分为三类：Generative Adversarial Networks（GANs）、Variational Autoencoders（VAE）和基于像素的似然法autoregressive approaches。 [12,40,24,38,53] &emsp;&emsp;条件图片生成 Conditional Image Synthesis 通过在生成图片时向GAN网络添加条件的方式来控制最终输出图片的结果。由两种不同方法：一是将条件作为附加信息同时送入到generator和discriminator中，二是强制让discriminator去预测图片的label。本文选择后者。 [10,35,37,42,59,41,43,6,9,21,4,5,20,27,28,55,56,22] &emsp;&emsp;场景图 Scene Graph 表现为有向图，它的结点是物体，边是物体之间的关系。场景图多倍用于图片检索、图片描述评价等，有些工作也场景从文本或图片中生成场景图 [1,47,32,36,57,58,26] &emsp;&emsp;针对图的深度学习 Deep Learning on Graphs 有的工作是对图进行embedding学习，类似于word2vec，但这与本文的方法不同，因为本文在进行一次前向计算时，传过来的图都是新的。与本文方法更相关的是Graph Neural Networks，它可以对任意的图进行处理。 [39,51,14,34,11,13,46,8,49,48,7,19,29,54,2,15,25] 方法——Methond&emsp;&emsp;我们的目标是得到一个模型，该模型的输入描述物体和它们之间关系的“场景图”，输出是基于该场景图的图片。主要的挑战和困难有三个方面：一、必须找到可以处理“场景图”输入的方法;二、确保生成的图片可以真实反映出场景图中缩描述的物体;三、确保生成的图片具有真实感。 &emsp;&emsp;如图2所示，本文通过“image generation network f”将场景图转换成图片。该网络的inputs是场景图 $G$ 噪声变量 $z$ ，ouputs是 $\hat I = f(G,z)$ 。 图2 &emsp;&emsp;场景图经过“图卷积网络”后，会得到每个物体的embedding vectors，如图2和图3所示，每一层“图卷积层”都会沿着图的边将信息混合在一起。 图3 &emsp;&emsp;本文利用从图卷积网络中得到的object embedding vectors来预测每个物体的bounding boxes和segmentation masks。将它们结合起来形成一个“场景图 scene layout”，如图2中心所示，场景布局相当于是场景图和图片中间媒介。 &emsp;&emsp;最终将布局送入到CRN中，生成图片，如图2右边所示，CRN中会不断将布局的尺寸放大，指定生成新的图片为止。本文训练的生成器是CRN网络 $f$ 和两个分辨器 $D{img}$ 和 $D{obj}$ ，它们可以确保图片的真实感以及图片中物体的可识别力。关于这部分的详细介绍可以查看后文以及附加材料中的内容。 &emsp;&emsp;场景图 Scene Graphs 给定一个物体类别集合 $C$ 和一个关系集合 $R$ 。一个场景图可以用一个元组 $(O,E)$ 表示，其中 $O \subseteq C$ ， $E \subseteq O \times R \times O$ 。在处理的第一阶段，使用学习好的embedding layer将场景图中的结点和边转换成一个dense vector，就像语言模型中的那样。 &emsp;&emsp;图卷积网络 Graph Convolution Network 为了实现端到端的处理，本文需要一个可以对场景图进行处理的神经网络模型，为此，采用了由若干图卷积层构成的图卷积网络。 本文的图卷积网络与传统的卷积网络的工作方式类似：给定一个input graph，它每个结点和边的vecotrs维度为 $D{in}$ ，然后经过一层图卷积层以后，就会生成一个新的vector，其维度为 $D{out}$ 。（输出结点的值是关输入结点周围像素的函数）。 具体来说，对于所有的 $oi \in O , (o_i,r,o_j) \in E$ ，给定输入向量 $v_i,v_r \in R^{D{in}}$ 都会计算出输出向量 $vi^{‘} , v_r^{‘} \in R^{D{out}}$ 。 对于所有的结点和边，都会使用3个函数： $g_s , g_p , g_o$ ，其接受的输入为一个向量的三元组 $(v_i, v_r, v_j)$。&emsp;计算边的输出向量时，直接使用 $v_r^{‘} = g_p(v_i, v_r, v_j)$ 。而更新结点的值时较为复杂，因为结点往往连接了很多条边。对于每条始于 $o_i$ 的结点，都利用 $g_s$ 去计算候选向量（candidate vector），收集到所有的候选向量以后，将其放置于集合 $V_i^s$ 中。用 $g_o$ 以同样的方式处理止于 $o_i$ 的边。公式表示如下： V_i^s = {g_s(v_i, v_r, v_j) : (o_i, r, o_j) \in E}V_i^o = {g_o(v_j, v_r, v_i) : (o_j, r, o_i) \in E}然后再利用公式 $v_i^{‘} = h(V_i^s \cup V_i^o)$ 计算得到物体 $o_i$ 的输出向量 $v_i^{‘}$ （ $h$ 为池化操作）。有关计算的例子可以看图3。在本文中，函数 $g_s , g_p , g_o$ 的实现采用了一个单一网络，该网络会将输入向量连接起来，然后送到一个多层感知机（MLP）当中。pooling 函数 $h$ 会将输入结果进行平均值池化，然后送到MLP当中。 图4 &emsp;&emsp;场景布局 Scene Layout 为了生成图片，本文利用object embedding vectors去计算场景布局，该布局给出了要生成的图片的2D结构。本文利用图4中的object layout network来预测每个物体的bounding boxes和 segmentation masks，进而生成场景布局。 object layout networks接受形状为 $D$ 的embedding vector $v_i$ ，并把它送入到一个 mask regression network中去预测形状为 $M \times M$ 的soft binary mask $\hat m_i$ ，同时也送到一个 box regression network中去预测bounding box $\hat b_i = (x_0, y_0, x_1, y_1)$ 。 我们将 embedding vectors $v_i$ 和 mask $\hat m_i$ 逐个元素相乘，得到一个masked embedding ， 其shape为 $D \times M \times M$ ，然后，再利用双线性插值法结合物体的bounding box得到一个object layout。将所有的object layout相加，最终得到scene layout。在训练阶段，我们使用ground-truth bounding boxes来计算scene layout，在测试阶段我们使用预先预测好的bounding boxes进行计算。 &emsp;&emsp;级联精细化网络 Cascaded Refinement Network 在给定场景布局以后，本文使用CRN来根据场景布局生成图片。一个CRN网络包含了一系列的convolutional refinement modules，modules之间的spatial resolutoin会不断变大（double），最终达到预定义的图片大小。 每个module都以scene layout（downsampling到当前module接受的大小）和前一层module的输出结果。 这两部分输入沿着channel连接在一起,送到2层3×3的卷积层里，然后利用最近邻插值对结果进行upsampling，之后继续传送到下一个module中。第一个module以scene layout和高斯噪声 $z \sim p_z$ 作为输入。把从最后一个module得到的结果再送到两个final convolution layers中去，生成最终的图片。 &emsp;&emsp;分辨器 Discriminators 本文训练了两个分辨器 $D{img}$ 和 $D{obj}$ patch-based image discriminators $D_{img}$ ：确保生成图片的overall appearance是realistic的。利用全卷积网络实现。 object discriminator $D_{obj}$ ：确保图片中的每个物体都是recognizable并且realistic的。分别利用辅助分类器 auxiliary classifier和全卷积网络实现。 &emsp;&emsp;训练 Training 本文将generation network $f$ 和 $D{img} , D{obj}$ 联合训练。generation network的训练目标是minimize下面的6个损失函数的权重和： $Box \ loss\ \ L{box} = \sum{i=1}^n ||b_i - \hat b_i||_1$ ：计算真实box和预测box之间的L1范式 $Mask\ loss\ \ L_{mask}$ ：计算真实mask和预测mask之间基于像素的交叉熵 $Pixel\ loss\ \ L_{pix} = ||I - \hat I||_1$ ：真实图片和生成图片之间的L范式 $Image\ adversarial\ loss\ \ L{GAN}^{img}$ ：针对 $D{img}$ 的损失函数 $Object\ adversarial\ loss\ \ L{GAN}^{obj}$ ：针对 $D{obj}$ 的损失函数，确保物体的realistic $Auxiliarly\ classifier\ loss\ \ L{AC}^{obj}$ ：针对 $D{obj}$的损失函数，确保物体的recognizable &emsp;&emsp;实现细节 Implementation Details 本文对所有的scene graphs都进行了数据增强，并且添加了特殊的图片间的relationships，可以把每个真实物体与图片物体进行连接，确保所有的scene graphs都是连通的。我们使用Adam训练所有的模型，学习率设置为 $10^{-4}$ ， batch size 设置为32, 迭代次数为一百万次，使用单个Tesla P100训练了3天。 对于每一次minibatch，我们首先更新 $f$ ，而后更新 $D{img}$ 和 $D{obj}$ 。对于所有的graph convolution 本文使用ReLU作为激活函数，对于CRN和discriminators 使用Leaky ReLU作为激活函数，同时使用了batch normalization技术。 实验&emsp;&emsp;在实验中，我们将证明本文提出的方法可以生成复杂的图片，并且正确反应场景图中的物体和物体之间的关系。 数据集&emsp;&emsp;COCO 使用2017 COCO-Stuff 数据集，该数据集共有80个物体类别，40K的训练集和5K的验证集，所有的图片标注都具有bounding boxes和segmentation masks 。利用这些标注，本文建立了2D平面上的场景图，总共包含6中人工设定的关系：左边，右边，上边，下边，里面，外面。我们忽略了图片中占图片比例小于2%的物体，使用的图片包含3～8个物体。将COCO val分为val和test两部分。最终，我们得到了24972张训练图片，1024张val图片，2048张test图片。 &emsp;&emsp;Visual Genome 本文使用VG 1.4数据集，它包含108077张图片，并且具有标注好的场景图。将其中的80%用作训练集，10%分别用作val和test，本文仅仅使用在训练集中出现次数大于2000次的物体和大于500次的关系，最终，我们得到的训练集具有178种物体和45种关系类型。我们忽略图片中的小物体，并且使用图片中具有3～30个物体和至少一种关系类型的图片，最终我们得到了62565张图片作训练集，5506张val和5088张test，平均每张图片包含10个物体和5种关系类型。由于VG数据集没有提供segmentation masks标注，所以在使用VG数据集时，我们忽略mask loss 。 定性结果——Qualitative Results&emsp;&emsp;由本文提出的模型生成的图片示例如图5,6所示 图5 图6 消融实验&emsp;&emsp;在消融实验中，如表1所示，我们验证了模型每一部分对最终图片质量的重要性和必要性。文本使用 $inception\ score^2$作为衡量生成图片好坏的标准。 表1 表1 我们测试了以下几种不同的消融模型： &emsp;&emsp;无图卷积 no gconv ：去掉图卷积层，因此boxes和masks会直接从原始的object embedding vectors预测而来。 &emsp;&emsp;无关系 no relationships ：使用图卷积层，但是忽视场景图中的所有“边”，即关系信息。 &emsp;&emsp;无分辨器 no discriminators ：去掉分辨器 $D{img}$ 和 $D{pix}$ ，依靠像素回归损失函数 $L_{pix}$ 来引导图片的生成。 &emsp;&emsp;去掉一个分辨器 omit one of the Discriminators ：仅去掉其中一个分辨器 &emsp;&emsp;GT Layout ：除了消融实验外，本文还使用了GT layout来代替 $L{box} 和 $L{mask}$ 损失函数。 物体定位 Object Localization&emsp;&emsp;除了关注生成图片的质量外，我们还对本文模型预测到的bounding boxes进行了分析。在表2中，我们展示了object的召回率和2种交并比的分值。另一个评价标准就是多样性。 表2 用户调研 User Studies&emsp;&emsp;作者找来了数名志愿者，让他们根据以下两个评价标准对本文模型的生成结果和StackGAN的结果进行评价。 Caption Matching Object Recall]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>图片生成 image generation</tag>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络的复杂度分析]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%2F</url>
    <content type="text"></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>深度学习</tag>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树结构知识点总结]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E6%A0%91%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[注：本文的对各个概念的定义不一定采用常用的标准定义，原因有二： 常用的定义描述在百度百科上即可查到 更多的是想通过自己的理解，用简短的几个关键词语或句子，来点明核心要点 二叉树基本概念和性质二叉树的定义：二叉树中的每个节点至多有2棵子树，并且子树有左右之分，其次序不能任意颠倒。 二叉树的性质： 对于非空二叉树：$N_0 = N_2 +1$ 在于非空二叉树，第k层上的节点数不超过：$2^{k-1}$ 高为h的二叉树，总节点数不超过：$2^h-1$ 具有N个节点的完全二叉树，其高度为： $\lceil log_2(N+1) \rceil$ 或 $\lfloor log_2{N} \rfloor +1$ 对于完全二叉树，如果各个节点按照顺序存储(从 1 开始)，则节点之间编号具有一定关系： 节点 $i$ 的父节点为 $\lfloor \frac{i}{2} \rfloor (i&gt;1)$ $i$的左右子树分别为：$2i$ 和 $2i+1$ （如果$2i/2i+1 \geq N$，则无左/右子树 给定N个节点，能够成$h(N)$ 种不同的二叉树：$h(N)=…$ 设有$i$个枝点，$I$为所有枝点的道路长度总和，$J$为叶的道路长度总和$J=I+2i$ 注意： 二叉树不是度为2的树。 度为2的树至少要有3个节点，而二叉树可以为空;度为2的树的左右子树是相对而言的，当只有一个孩子时，就无须分左右 满二叉树与完全二叉树满二叉树： 除叶子节点外的所有节点均有两个子节点 完全二叉树： 最后一个不满的“满二叉树”，最后一层所有节点集中在左边 二叉树的遍历先根遍历：根节点、左子树、右子树递归实现12345void preOrder(Tree t)&#123; visit(t-&gt;value); //访问根节点 if (t-&gt;left) preOrder(t-&gt;left); //访问左孩子 if (t-&gt;right) preOrder(t-&gt;right); //访问右孩子&#125; 非递归实现对于任一节点，其可看做是根节点，因此直接访问，访问后，若其左孩子不为空，则按相同规则访问其左子树，当访问完左子树之后，再访问其右子树： 对于任一节点P： 访问节点P，并将P入栈 如果P的左孩子不为空，则令P = P-&gt;left，并转向第一步。若为空，则将P出栈，并令P = P-&gt;right，然后转向第一步。 直到P为nullptr并且栈为空时，结束循环 123456789101112131415vector&lt;TreeNode*&gt; preOrder;if(pRoot == nullptr) return preOrder;stack&lt;TreeNode*&gt; s_node;TreeNode* P = pRoot;while(!s_node.empty() || P!=nullptr)&#123; while(P!=nullptr)&#123; preOrder.push_back(P); // visit P s_node.push(P); P = P-&gt;left; &#125; if(!s_node.empty())&#123; P = s_node.top(); s_node.pop(); P = P-&gt;right; // go to right child &#125;&#125; 中根遍历：左子树、根节点、右子树递归1234567void in_order(TreeNode* pRoot)&#123; if(pRoot != nullptr)&#123; in_order(pRoot-&gt;left); visit(pRoot); in_order(pRoot-&gt;right); &#125;&#125; 非递归对于任一节点，优先查看其左孩子，而左孩子节点又可以看作是一个根节点，则继续优先查看其左孩子，直到遇到左孩子节点为空的根节点才进行访问。然后再转向查看其右孩子，右孩子可看作是一个根节点，继续按上面的规则循环： 对于任一节点P： 若其左孩子不为空，则就P入栈并将P的左孩子置为当前的P，然后继续查看当前P的左孩子，直到为空； 经过上一步后，P指向了空的左孩子，因此取栈顶元素并进行出栈操作，同时访问该栈顶节点，然后将P置为栈顶节点的右孩子（无需判断右孩子是否为空，若为空则下一次循环会自动继续取栈顶） 知道P为nullptr并且栈为空时循环结束 1234567891011121314vector&lt;TreeNode*&gt; inOrder;if(pRoot == nullptr) return inOrder;stack&lt;TreeNode*&gt; stack_node;TreeNode* P = pRoot;while(!stack_node.empty() || P !=nullptr)&#123; while(P!=nullptr)&#123; stack_node.push(P); P = P-&gt;left; &#125; if(!stack_node.empty())&#123; P = stack_node.top(); stack_node.pop(); inOrder.push_back(P); // visit P P = P-&gt;right;&#125; 后根遍历：左子树、右子树、根节点递归1234567void in_order(TreeNode* pRoot)&#123; if(pRoot != nullptr)&#123; in_order(pRoot-&gt;left); in_order(pRoot-&gt;right); visit(pRoot); &#125;&#125; 非递归后序遍历的非递归实现是最难的一种。因为在后序遍历中，要保证左孩子和右孩子都已被访问，并且左孩子在右孩子之间访问，最后才能访问根节点。有两种思路： 思路一：思路二：二叉排序树（Binary Sort Tree, BST）基本概念和性质定义： 也叫二叉查找树或有序二叉树。当树不为空时，该树具有如下性质： 左子树上的所有节点值，均小于其根节点的值 右子树上的所有节点值，均大于其根节点的值 左、右子树也分别为二叉排序树 没有键值相等的节点 性质： 对二叉排序树进行中根遍历，即可得到一串有序数列（从小到大） 时间复杂度： 插入与查找的复杂度均为$O(logn)$，但在最坏情况下为$O(n)$（原因在于树不一定是平衡的） 平衡二叉书(AVL树, 名字来源于其发明者 Adelson-Velsky 和 Landis)]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的封装、继承、多态、重载、重写基本概念解析]]></title>
    <url>%2Fz_post%2FCpp-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-Cpp%E4%B8%AD%E7%9A%84%E5%A4%9A%E6%80%81%E3%80%81%E9%87%8D%E8%BD%BD%E3%80%81%E9%87%8D%E5%86%99%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[面向对象的三个基本特征封装继承多态实现多态具有两种方法：重载overload（利用参数列表）和覆盖override（利用virtual关键字） C++中的override关键字从C++11起，引入了新的关键字override，主要用于紧随成员函数声明或定义内成员函数的声明器之后使用。 在成员函数声明或定义中，override确保该函数为虚并覆写（overrride）来自基类的虚函数。override是在成员函数声明器后使用时才拥有特殊含义的标识符，其他情况下不是保留的关键字。 123456789101112struct A&#123; virtual void foo(); void bar();&#125;;struct B : A&#123; void foo() const override; // 错误： B::foo 不覆写 A::foo（签名不匹配） void foo() override; // OK ： B::foo 覆写 A::foo void bar() override; // 错误： A::bar 非虚&#125;; C++中的final关键字指定派生类不能覆写虚函数，或类不能被继承。 在虚函数声明或定义中使用时，final确保函数为虚且不可被派生类覆写，否则程序生成编译时错误。 在类定义中使用时，final指定此类不可出现于另一类的定义的 base-specifier-list 中（换言之，不能从它派生出其他类），否则程序生成编译时错误。 final是在用于成员函数声明或类头部时有特殊含义的标识符，其他语境中它非保留关键字，可用于命名对象或函数。 1234567891011121314151617181920struct Base&#123; virtual void foo();&#125;;struct A : Base&#123; void foo() final; // A::foo 被覆写且是最终覆写 void bar() final; // 错误：非虚函数不能被覆写或是 final&#125;;struct B final : A // struct B 为 final&#123; void foo() override; // 错误： foo 不能被覆写，因为它在 A 中是 final&#125;;struct C : B // 错误： B 为 final&#123;&#125;;]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深入理解TensorFlow架构设计与实现原理》]]></title>
    <url>%2Fz_post%2FTensorFlow-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3TF%2F</url>
    <content type="text"><![CDATA[第一章 TensorFlow系统概述人工智能和深度学习的热潮将Tensoflow推向了很高的地位，本章主要是作为引子，来对TF进行一个概述 1.1 简介1.1.1 产生背景近年来深度学习在图像、视觉和语音领域的突破，促使了各种深度学习框架的诞生 1.1.2 独特价值TF能在众多开源框架中杀出重围，除了Google的背书以外，还少不了以下独特价值： 运算性能强劲：TF1.0利用线性代数编译器XLA全方位的提升了计算性能，XLA帮助TF在CPU、GPU、TPU、嵌入式设备等平台上更快速的运行机器学习模型的训练与推理任务。同时，还提供了大量针对不同软硬件环境的优化配置参数 框架设计通用：TF既提供高层封装API（如Slim、Keras、TF Layers等），又提供底层原生API 支持生产环境部署 语言借口丰富：支持python、C、C++、java、Go等 端云协同计算：支持同时在云侧和端侧运行（移动设备等终端） 1.1.3 版本变迁迭代更新非常快，慢慢走向成熟 1.1.4 与其他主流深度学习框架对比起初，TF的内存消耗和计算速度一直是短板。但是，随着XLA和RDMA等特性的发布，TF的性能在绝大多数情况下都不输于其他深度学习框架。 TF的灵活性导致了学习成本也相应较高，API过于丰富。（不过，可以使用Keras、TF Layers来解决此问题） 1.2 设计目标TF的设计目标并非局限一套深度学习库，Google希望其成为一套面向多种应用场景和编程范式、支持异构计算平台、具备优异性能与可伸缩性的通用人工智能引擎。 1.2.1 灵活通用的深度学习库TF的灵活性主要体现在以下几个方面： 算子定义：粒度更细，数量更多 编程范式：支持声明式编程，将模型的定义和执行解耦 runtime框架 多语言支持 1.2.2 端云结合的人工智能引擎TF对云计算场景的支持是其竞争力的基础，主要体现在以下方面： 提供多种标准化的安装包、构建脚本和容器化封装，支持在不同Linux发行版以及Windows Server等服务器上部署 支持对接多种常见的公有云和私有云服务 兼容若干种常见的高性能计算与通信硬件 灵活的runtime框架设计，既提供标准且易用的PS-worker分布式模式，也允许用户自由开发针对特定环境需求的分布式框架 TF在端侧方面也毫不逊色，主要体现在以下几个方面 推理（预测）态代码能够运行于多种主流的终端平台 通过XLA AOT（ahead of time）编译技术及其他软硬件解耦设计，简化对接 提供量化参数和低精度代数等算法层机制 提供模型与框架一体化的精简版runtime平台 1.2.3 高性能的基础平台软件TF的高性能设计体现在它对高端和专用硬件的深入支持。 1.3 基本架构1.3.1 工作形态TF采用了库模式，其工作形态是有用户编写主程序代码，调用Python或其他语言函数库提供的借口以实现计算逻辑。 1.3.2 组件结构结构示意图可查看书上p13 构成TF的主体使其运行时核心库。 对于普通的python应用层开发者而言，这个核心库就是值通过pip命令等方式安装TF之后，部署到site-packages或类似目录中的动态链接库文件。 生成这个库的C++源代码大致分为3个层次：分布式运行时、公共运行时和算子核函数。其中，公共运行时实现了数据流图计算的基本逻辑，分布式运行时在此基础上实现了数据流图的跨进程协同计算逻辑，算子核函数则包含图上具体操作节点的算法实现代码。 第二章 TensorFlow环境准备2.1 安装可查看官方文档 有一点需要注意：为了保证软件对操作系统和硬件平台的通用性，Google官方发布的TensorFlow whl包没有使用过多的编译优化选项，如 XLA、AVX、SSE等，如果想要打开这些编译优化选项来提升TF的计算性能，那么必须使用源代码编译安装的方式。 2.2 依赖项2.2.1 Bazel软件构建工具Bazel是Google开源的一套软件构建工具，功能定位与CMake、GNU Autotools和Apache Ant等类型，但具有一些独特的优势，如下所示： 多语言支持：C++、Java、Python等 高级构建语言 多平台支持 可重现性 可伸缩性 Bazel使用工作空间、包和目标三层抽象组织待构建的对象 工作空间（workspce）： 包（package）： 目标（target）： 2.2.2 Protocal Buffers 数据结构序列化工具2.2.3 Eigen线性代数计算库2.2.4 CUDA统一计算设备架构CUDA是NVIDIA公司退出的一种用于并行计算的软硬件架构，发布于2007年。该架构以通用计算图形处理器（GPGPU）作为主要的硬件平台，提供一组用于编写和执行通用计算任务的开发库与运行时环境。 CUDA作为软件依赖项提及时，往往指的是CUDA架构中的软件组件，即NVIDIA驱动程序和CUDA Toolkit。除了基本的CUDA开发库和编译器外，CUDA工具包还包括cuBLAS、cuFFT、cuSOLVER、cuDNN等高级算法库，以及IDE、调试器、可视化分析器等开发工具，其中部分组件需要独立安装。 在CUDA架构中，不同层次的软件组件均为开发者提供编程接口，以适应不同类型软件的开发需求： NVIDIA驱动层的开发接口（即cu开头的函数，也称为CUDA Driver API）较为底层，暴露了GPU的若干内部实现抽象。这种接口能够对GPU的运行时行为进行细粒度控制，有助于提升程序的运行时效率，但缺点在于开发过程烦琐。一般的GPU应用程序不会直接使用这一层接口，然而TF内部的GPU计算引擎——StreamExecutor为了追求性能，选择使用这一层接口实现GPU任务调度和内存管理等功能 CUDA开发库的API（即以cuda开头的函数，也称为CUDA Runtime API）是CUDA架构中使用最为广泛的接口，功能涵盖GPU设备管理，内存管理，时间管理以及图形处理相关的逻辑。 cuBLAS、cuDNN等高级算法库：提供了面向通用计算（如线性代数）或领域专用计算（如神经网络）需求的高层次接口。在这个层次，GPU设备的很多技术细节已被屏蔽，开发者可以专注于算法逻辑的设计与实现。TF面向NVIDIA GPU的计算类操作大多基于cuBLAS和cuDNN接口实现。 对于TF而言，CUDA工具包是不受Bazel管理的外部依赖项，因此，用户如果想要使用NVIDIA GPU加速深度学习时，需要事先安装带有NVIDIA驱动程序的CUDA工具包即cuDNN库 2.3 源代码结构2.3.1 根目录TF源码的组织复合Bazel构建工具要求的规范。其根目录是一个Bazel项目的工作空间。 2.3.2 tensorflow目录TF项目的源码主体位于tensorflow目录，该目录下的源文件几乎实现了TF的全部功能，同时体现了TF的整体模块布局。 2.3.3 tensorflow/core 目录TF核心运行时库的源代码位于tensorflow/core目录 2.3.4 tensorflow/python 目录TF Python API的源码位于tensorflow/python目录 2.3.5 安装目录pip命令会将TF运行时所需的Python文件、动态链接库以及必要的依赖项复制到当前Python环境的site-packages或dist-packages目录中，其中TF软件本身的的运行时代码会被部署到tensorflow子目录，这一目录具有与源码tensorflow目录相似的组织结构。二者的不同点在于以下几点： 安装目录中只包含每个模块的Python语言接口文件，不再包含C++源码。所有使用到的C++源码已被编译到了python子目录下的动态链接库文件中（在Linux下为_pywrap_tensorflow_internal.so）。如果某个模块未提供Python API，那么相应的子目录不会在安装目录中出现 安装目录中的python/ops子目录比同名的源代码子目录增加了一系列名称有gen_开头的Python接口文件。这些文件是TensorFLow编译脚本自动创建的，旨在为C++核心库的一部分数据流图操作提供Python编程接口 安装目录比源代码目录多出一个include子目录。这个目录包含了TensorFLow本身以及Protocol Buffers、Eigen等依赖库的C++头文件，允许用户通过编程方式使用核心库的功能。 第三章 TensorFlow基础概念3.1 编程范式：数据流图TF采用了更适合描述深度神经网络模型的声明式编程范式，并以数据流图作为核心抽象。 优势（相比更广泛的命令式编程范式）： 代码可读性强 支持引用透明 提供预编译优化能力 3.1.1 声明式编程与命令式编程二者的最大区别在于：前者强调“做什么”， 后者强调“怎么做”。 声明式编程：结构化、抽象化，用户不必纠结每个步骤的具体实现，而是通过下定义的方式描述期望达到的状态。声明式编程比较接近人的思考模式；程序中的变量代表数学符号或抽象函数，而不是一块内存地址，程序的最终输出仅依赖于用户的输入数据，计算过程不受内部和外部状态影响。 命令式编程：过程化、具体化、用户告诉机器怎么做，机器按照用户的指示一步步执行命令，并转换到最终的停止状态。命令式编程起源于对汇编语言和机器指令的进一步抽象，本身带有明显的硬件结构特征。它通过修改存储器的值、产生副作用的方式实现计算。这里的副作用是值对外部环境产生的附加影响。 编程是一种输入到输出的转换机制，这两种范式提供了截然不同的解决方案： 声明式编程：程序是一个数学模型，输入是自变量，输出是因变量，用户设计和组合一系列函数，通过表达式变换实现计算。 命令式编程：程序是一个有穷自动机，输入是起始状态，输出是结束状态，用户设计一系列指令，通过指令的执行完成状态转换。 适用范围： 声明式编程：DL、AI 命令式编程：交互式UI、OS 3.1.2 声明式编程在DL应用上的优势 代码可读性强 &emsp;&emsp;以目标为导向，更接近于数学公式或人类的思维方式 支持引用透明 &emsp;&emsp;引用透明是指：如果一个函数的语义同他出现在程序中的上下文无关，则称它是引用透明的。关于引用透明的一个推论是：函数的调用语句可以被它的返回值取代，而不影响程序语义。因此，用户可以选择执行任意的模块组合（子图），以得到不同模型结构的输出结果。 提供预编译优化能力 &emsp;&emsp;TF需要实现编译得到完整的数据流图，然后根据用户选择的子图、输入数据进行计算。因此，声明式编程能够实现多种预编译优化，包括无依赖逻辑并行化、无效逻辑移除、公共逻辑提取、细粒度操作融合等。 3.1.3 TensorFlow数据流图的基本概念TF的数据流图是一个 有向无环图 。 图中的节点代表各类操作（opertion），具体包括数学运算、数据填充、结果输出和变量读写等操作，每个节点上的操作都需要分配到具体的物理设备（CPU、GPU）上执行。 图中的有向边描述了节点间的输入、输出关系（也就是各个操作的输入和输出），边上流动（flow）着代表高位数据的张量。 1.节点前向图中的节点统一称为操作，它们根据功能可以分为以下3类： 数学函数或表达式 存储模型参数的变量（variable） 占位符（placeholder） 后向图中的节点同样分为三类： 梯度值 更新模型参数的操作 更新后的模型参数 2.有向边数据流图中的有向边用于定义操作之间的关系，它们分为两类：一类用来传输数据，绝大部分流动着的张量的变都是此类，简称数据边；另一类用来定义控制依赖，通过设定节点的前置依赖决定相关节点的执行顺序，简称控制边。 3.执行原理声明式编程的特点决定了在深度神经网络模型的数据流图上，各个节点的执行顺序并不完全依赖于代码中定义的顺序，而是与节点之间的逻辑关系以及运行时库的实现机制相关。 抛开运行时库内部的复杂实现，数据流图上节点的执行顺序参考了拓扑排序的设计思想，其过程可以简述为以下4个步骤： 以节点名称作为关键字、入度作为值，创建一张散列表，并将次数据流图上的所有节点放入散列表中。 为此数据流图创建一个可执行节点队列，将散列表中入度为0的节点加入到该队列，并从散列表中删除这些节点 依次执行该队列中的每一个节点，执行成功后将此节点输出指向的节点的入度值减1，更新散列表中对应节点的入度值 重复步骤2和步骤3，直到可执行节点队列变为空 3.2 数据载体：张量TF提供Tensor和SparseTensor两种张量抽象，分别表示稠密数据和系数数据。后者旨在减少高维稀疏数据的内存占用。 3.2.1 张量：Tensor与数学和物理学中的张量不同，在NumPy或TF中，通常使用多维数组的形式描述一个张量，数组的维数表示对应张量的阶数。张量的阶数决定了其描述的数据所在高维空间的维数，在此基础上，定义每一阶的长度可以唯一确定一个张量的形状。 TF中的张量形状用python中的列表表示，列表中的每个值依次表示张量各阶的长度（如图片的张量：[128,128,3]）。 TF的张量在逻辑定义上是数据载体，但在物理实现时是一个句柄，它存储张量的元信息以及指向张量数据的内存缓冲区指针。这样设计是为了实现 内存复用。在某些前置操作（生产者）的输出值被输入到多个后置操作（消费者）的情况下，无须重复存储输出值。 1.创建一般情况下，用户不需要使用Tensor类的构造方法直接创建张量，而是通过操作间接创建张量，如constant和add操作等： 1234567import tensorflow as tfa = tf.constant(1.0)b = tf.constant(1.0)c = tf.add(a,b)print([a,b,c])//output: [&lt;tf.Tensor....&gt;,&lt;...&gt;,&lt;...&gt;] 没有执行会话，所以不会输出值，而是输出abc的类型 2.求解3.成员方法Tensor具有eval，get_shape等成员方法 4.操作TF为Tensor提供了abs,add,reduce_mean等大量操作 5.典型用例见书p44 3.2.2 稀疏张量：SparseTensorTF提供了专门用于处理高维稀疏数据的SparseTensor类。该类以键值对的形式表示高维稀疏数据，包含indices、values和dense_shape三个属性。 1.创建在TF中创建稀疏张量时，一般可以直接用SparseTensor类的构造方法，如下：123import tensorflow as tfsp = tf.SparseTensor(indices=[[0,2],[1,3]], values=[1,2],dense_shape=[3,4]) 2.操作TF为稀疏张量提供了一些专门的操作，方便用户处理。 3.典型用例见书p46 模型载体：操作TF中每个节点均对应一个具体的操作。因此，操作是模型功能的实际载体，数据流图主要有以下三种节点： 计算节点：对应的是无状态的计算或控制操作，主要负责算法逻辑表达式或流程控制 存储节点：对应的是有状态的变量操作，通常用来存储模型参数 数据节点：对应的是特殊的占位符操作，用于描述待输入数据的属性 3.3.1 计算节点：OperationOperation类定义在tensorflow/python/framework/ops.py文件中，提供了获取操作的名称、类型、输入张量、输出张量等基本属性的方法。 对于无状态节点，其输出有输入张量和节点操作共同决定 3.3.2 存储节点：Variable存储节点作为数据流图中的有状态节点，其主要作用是在多次执行相同数据流图时存储特定的参数，如深度学习或机器学习的模型参数。 对于有状态的节点，其输出除了跟输入张量和节点操作有关之外，还会受到节点内部保存的状态值的影响。 1.变量TF中的存储节点抽象是Variable类 2.变量操作每个变量对应的变量操作对象在变量初始化时构造，变量支持两种初始化方式： 初始值。根据用户输入或采用缺省值初始化 VariableDef。使用Protocol Buffers定义的变量完成初始化 3.read节点通过解释read节点的实现原理，加深对于变量、变量操作和变量值的理解。 3.3.3 数据节点：Placeholder数据流图本身是一个具有计算拓扑和内部结构的“壳”。在用户向数据流图填充数据前，图中并没有真正执行任何计算。当数据流图执行时，TF会向数据节点填充（feed）用户提供的、复合定义的数据。 TF的数据节点有占位符操作（placeholder Operation）实现，其对应的操作函数是tf.placeholder。针对稀疏数据，TensorFlow也提供了稀疏占位符操作（sparse placeholder operatin），其操作函数是tf.sparse_placeholde。 3.4 运行环境：会话]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[报错module 'tensorflow' has no attribute 'FIFOQueue']]></title>
    <url>%2Fz_post%2FTensorFlow-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95-no_attribute_FIFOQueue%2F</url>
    <content type="text"><![CDATA[报错原因可能是因为当前路径下存在有与tensorlfow官方库相冲突的文件名，解决办法有2个。 1、更改掉有冲突性质的名字这里如果你回忆一下在创建了哪个文件以后产生报错，然后将那个文件的名字更改一下就行了。以我自己为例，我这里创建了一个queue.py的文件，然后运行时就报这个错误了，并且不只是这个文件，在当前路径下的其他py文件也不能正常运行，但是如果换一个文件夹路径，运行其他文件夹下的py文件是没有问题的。所以这里我把queue.py改名成了q.py（其他名字也行），然后在运行，就不会报错了 2、tensorlfow本身问题如果你不管在什么路径下运行任何还有tensorflow代码的文件，都会报错的话，建议使用指令重装TF： 123pip3 uninstall tensorflow-gpu#卸载pip3 install --upgrade tensorflow-gpu #安装]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>踩坑记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[StackGAN---ICCV2017]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-StackGAN%2F</url>
    <content type="text"><![CDATA[本篇论文解读的排版主要参见原文的格式，针对原文中的每一个小节进行展开，有的是对原文的一个提炼和简单概括，有的是对原文中没有详细介绍的技术的补充和说明。 摘要&emsp;&emsp;要想从给定的文字描述中生成一幅高质量的图片，是一件十分具有挑战性的事情。而现有的方法（截止至2017年）生成的图片，虽然可以表现出文字中的一些关键信息，但是它们都缺少了很多局部细节。这篇文章提出了一个“堆叠式的生成式对抗神经网络——Stacked Generative Adversarial Networks（StackGAN）”。它可以在根据给定的文本信息，生成像素为256×256的高质量图片。具体的做法是利用“分治”的思想，将一个复杂的问题分解成更易解决的多个小问题。这篇文章将生成图片的过程分为了2个阶段： Stage-1：根据给定的文本信息，生成64×64大小的图片草图，着重于描绘图片中主要目标的轮廓和颜色 Stage-2：结合64×64的图片草图和文本信息，生成256×256的更高质量的图片，这个过程不仅修正了第一阶段中的错误信息，同时还反映了的图片中更多的细节。 &emsp;&emsp;另外，为了提高训练时的稳定性和生成图片的多样性，本文还提出了一种新颖的“条件数据增强技术”，可以确保训练过程的平缓（ 不懂 ） 介绍&emsp;&emsp;作者简要介绍了有关“图像生成”和“GAN”的研究现状和存在的困难，然后阐述了本文的3点主要贡献： 提出了一个“堆叠式的生成式对抗神经网络——StackGAN”。该网络是第一个能够生成256×256图片大小的神经网络模型 提出了一个新颖的“条件数据增强技术”。以此来稳定网络训练过程，同时提高了生成图片的多样性 大量的实验和高质量的实验结果表明本文设计的模型框架是有效的，这对以后的研究和发展具有一定的帮助作用 相关工作 VAE PixelRNN energy-based GAN $S^2$-GAN … 堆叠的生成式对抗神经网络——StackGAN&emsp;&emsp;为了生成高质量的图片，本文提出了一个简单但是十分有效的网络模型，它将生成过程分成了两个阶段： Stage-1：根据给定的文本信息，生成64×64大小的图片草图，着重于描绘图片中主要目标的轮廓和颜色 Stage-2：结合64×64的图片草图和文本信息，生成256×256的更高质量的图片，这个过程不仅修正了第一阶段中的错误信息，同时还反映了的图片中更多的细节。 正文之前——Preliminaries&emsp;&emsp;作者在这里简单介绍了GAN和Conditional GAN的核心原理。 GAN：由两个“子模型”组成，这两个“子模型”不断交替训练，它们的训练目标恰好相反，仿佛实在彼此对抗一般。生成模型G的目标是习得能够代表真实数据分布 $p{data}$ 的生成概率分布 $p_g$ ，而分辨模型D的目标则是要习得能够准确分辨出 $p{data}$ 和 $p_g$ 的二分类器。它们之间的关系就像是一场“two-player min-max game”一样，其目标方程可以如下表示： \min_G \max_D V(D,G) = E_{x\sim p_{data}}[logD(x)] + E_{z\sim p_z}[log(1-D(G(z)))] Conditional GAN：是GAN的一种扩展，它令生成器和分辨器均接受一个条件向量 $c$ ，分别写成 $G(z,c)$ 和 $D(x,c)$ ，如此一来，生成器就可以根据不同的条件 $c$ 来限定生成的图片。（ $c$ 通常为图片标签或者图片描述） 条件增强技术——Conditioning Augmentation&emsp;&emsp;如图1所示，文本描述信息 $t$ 首先会通过一个编码器进行编码，生成一个text embedding: $\phi_t$ 。 在之前的工作中，会将text embedding非线性的传送到生成器当中去。但是，由于text embedding通常维度很高（100以上），所以当我们的数据十分有限时，text embedding表现出不连续，稀疏等特点，这对训练生成器来说是不利的。为了缓和这个问题，本文不再将text embedding直接送入的生成器中进行训练，而是随机的从一个独立高斯分布 $N(\mu(\phi_t), \Sigma(\phi_t))$ 当中进行采样，生成新的变量 $\hat{c}$ 。利用该技术，可以从一小部分数据中生成更多的训练数据（pairs）。 &emsp;&emsp;另外，为了更进一步的增强训练时的平滑性，同时为了抑制过拟合，本文还在目标函数中增加了下面的正则惩罚项(KL离散度——KL divergence)： D_{KL}(N(\mu(\phi_t), \Sigma(\phi_t)) || N(0,I))（引入随机性变量 $\hat z$ 的原因，可以考虑是因为同样的特别描述往往可以对应到不同的图片） Stage-1 GAN&emsp;&emsp;通过预训练好的编码器对给定的图片描述进行编码，生成text embedding: $\phi_t$ 。利用Conditioning Augmentation技术根据 $\phi_t$ 对 $N(\mu_0(\phi_t),\Sigma_0(\phi_t))$ 采样得到 $\hat c_0$ 。 最后，利用 $\hat c_0$ 和随机向量 $z$ 进行第一阶段的生成，得到 $G(z,\hat c_0)$ 。 在Stage-1的训练阶段，模型通过交替训练以下2个目标函数来分别优化生成器和分辨器： 生成器， $min(L_{G_0})$ ：L_{G_0} = E_{z\sim p_z,t\sim p_{data}}[log\bigl(1-D_0(G_0(z,\hat c_0), \phi_t)\bigr)] + \lambda D_{KL}\bigl( N(\mu_0 (\phi_t), \Sigma_0(\phi_t)) || N(0,I_0) \bigr) 分辨器， $max(L_{D_0})$ ， $D(I,\phi_t)$ 代表图片 $I$ 在 $\phi_t$ 条件下是真实图片的概率：L_{D_0} =E_{(I_0,t)\sim p_{data}} [logD_0(I_0,\phi_t)] + E_{z\sim p_z,t\sim p_{data}}[log \bigl(1-D_0(G_0(z,\hat c_0), \phi_t) \bigr)] 上面公式中： $I0$ ：来自真实分布 $p{data}$ 的图片 $t$ ：来自真实分布 $p_{data}$ 的图片描述 $\phi_t$ ：t经过预训练好的编码器编码后得到的text embedding $z$ ：噪声，从 $p_z$ 分布中随机采样而来（本文用的是高斯分布） $\lambda$ ：惩罚项的权重，本文采用 $\lambda = 1$ $N(\mu_0 (\phi_t), \Sigma_0(\phi_t))$ ：用于生成 $\hat c_0$ 的高斯分布，其期望值和方差都是通过神经网络学习出来的 模型架构 ： &emsp;&emsp;对于生成器 $G_0$ 来说，要想得到文本条件变量 $\hat c_0$ ，首先要将text embedding $\phi_t$ 送到一个全连接层中以此来生成 $\mu_0$ 和 $\sigma_0$ （ $\sigma_0$ 是 $\Sigma_0$ 对角线上的值），得到高斯分布 $N(\mu(\phi_t),\Sigma(\phi_t))$ 。然后从高斯分布中采样得到文本条件变量 $\hat c_0 = \mu_0 + \sigma_0 \cdot \epsilon$ ， $\hat c_0$ 的维度为 $N_g$ 。 这里，“ $\cdot$ ”代表点乘，$\epsilon \sim N(0,I)$ 。之后，将 $\hat c_0$ 和噪声向量 $z$ 连接起来，它们经过一些列“升维块”（upsampling block）之后，会生成大小为 $W_0 \times H_0$ 的图片。 &emsp;&emsp;对与分辨器 $D0$ 来说，首先利用全连接层将 $\phi_t$ 压缩到 $N_d$ 维，然后，将其在空间上进行复制，形成一个 $M_d \times M_d \times N_d$ 的张量。 同时，将图片送到一系列“降维块”（downsampling block）中，使其具有 $M_d \times M_d \times N{filter}$ 的空间结构，然后将图片的tensor和文本的tensor沿着channel的维度连接的一起，然后将其送到 $1 \times 1$ 的卷积层当中，联合学习图片和文本之间的关系特征。最后，将特征传送到输出为一个节点的全连接层，得到当前图片与文本属于真实数据的概率。 Stage-2 GAN&emsp;&emsp;从Stage-1 GAN中得到的低分辨率图像通常会缺少一些局部细节，有时候还会造成主要目标物不同程度的形变。另一方面，有些存在于文本中的重要信息，也可能被忽视。 因此，本文的Stage-2 GAN在Stage-1的基础上进行构建。它将Stage-1返回的低分辨率图片和图片描述的text embedding作为GAN的条件，使之返回的结果不仅能修正Stage-1中的错误信息，同时还可以补充在Stage-1中没有捕捉到的信息。 &emsp;&emsp;当选取Stage-1低分辨率结果 $s_0 = G_0(z,\hat c_0)$ 和 高斯变量 $\hat c$ 作为GAN的条件时，生成器和分辨器的目标函数如下所示： 生成器， $min(L_G)$ ：L_G = E_{z\sim p_z,t\sim p_{data}}[log\bigl(1-D(G(s_0,\hat c), \phi_t)\bigr)] + \lambda D_{KL}\bigl( N(\mu (\phi_t), \Sigma(\phi_t)) || N(0,I) \bigr) 分辨器， $max(L_D)$ ， $D(I,\phi_t)$ 代表图片 $I$ 在 $\phi_t$ 条件下是真实图片的概率：L_D =E_{(I,t)\sim p_{data}} [logD(I,\phi_t)] + E_{z\sim p_z,t\sim p_{data}}[log \bigl(1-D(G(s_0,\hat c), \phi_t) \bigr)] &emsp;&emsp;与第一阶段的GAN不同的是，在Stage-2中，本文提出了一个假设，那就是作为Stage-1条件之一的随机变量 $z$ ，可以确保Stage-1的生成结果具有多样性。在这样的假设下，本文在Stage-2阶段并不使用 $z$ 作为条件，而是采用Stage-1的生成结果 $s_0$ 作为条件。 高斯条件变量 $\hat c$ 和 $\hat c_0$ 分别作为Stage-2和Stage-1阶段的CA（Contioning Augmentation），它们共享同一个text embedding—— $\phi_t$ ， $\phi_t$ 由同一个预训练的编码器生成。 但是，Stage-1和Stage-2的CA会通过不同的全连接层，因此，它们生成的关于 $\phi_t$ 的均值和方差不同。 通过这种方式，Stage-2可以学习到被Stage-1所忽略的一些有用的信息。 模型架构： &emsp;&emsp;对于生成器，本文利用残差模块（residual blocks）将Stage-2的生成器设计成一个“编码-解码网络”（encoder-decoder network）。 首先，根据给定的text embedding $\phi_t$ 生成维度为 $N_g$ 的文本条件向量 $\hat c$ ，然后对其进行复制，使之形成形状为 $M_g \times M_g \times N_g$ 的张量。 同时，将Stage-1的结果 $s_0$ 送到若干个“降维模块”（downsampling block）中，直至其size变为 $M_g \times M_t$ 为止。然后将文本特征和图片特征沿着channels连接到一起，并将其送到若干个“残差模块”中去，目的是为了学习到图片和文本交织在一起的多模态表征。最终，通过一系列的“升维模块”（upsampling block），也就是解码器（decoder），生成size为 $W \times H$ 的高分辨率图片。 &emsp;&emsp;对于分辨器，它的结构与Stage-1中的结构相似，只不过由于接受的图片size变大了，所以需要更多的“降维模块”（downsampling block）。为了让分辨器更好的学到图片和文本之间的联系，本文采用了matching-aware discriminator，而非vanilla discriminator，具体可以参考才论文中的参考文献部分。 在训练阶段，正反例构成如下： 正例：真实的图片和与之对应的文本描述 反例：1、真实的图片和不相匹配的文本描述&emsp; 2、生成器生成的图片和与之对应的文本描述 实现细节&emsp;&emsp;“升维模块”由 $3 \times 3 stride 1$ 的卷积层后接最近邻upsampling组成。除了最后的卷积层外，其他卷积层都使用了Batch Normalization和ReLU激活函数。 “残差模块”由 $3 \times 3 stride 1$ 的卷积层、Batch Normalization和ReLU激活函数组成。 在 $128 \times 128$ 的StackGAN模型中，使用了2个“残差模块”，而在 $256 \times 256$ 的StackGAN模型中，使用了4个“残差模块”。 “降维模块”由 $4 \times 4 stride 2$ 的卷积层、Batch Normalization（除第一层）和LeakyReLU组成。&emsp;&emsp;默认情况下，$N_g = 128$ , $N_z = 100$, $M_g = 16$, $M_d = 4$, $N_d = 128$, $W_0 = H_0 = 64$ , $W = H = 256$ 。在训练时，首先固定Stage-2 ，同时迭代训练Stage-1 GAN的 $D_0$ 和 $G_0$ 600 epochs。然后再固定Stage-1 ，同时迭代训练Stage-2 GAN的 $G$ 和 $D$ 600epochs。所有的网络训练时都使用ADAM优化算法，batch size为64,初始的学习率为0.0002 ，学习率每经过100epochs都会衰减成原来值的一半。 实验&emsp;&emsp;为了验证上面提出的模型和方法的有效性，本文进行了大量的高质量实验。本文采用的对照方法是目前（2017）最有效的两个图片生成方法：GAN-INT-CLS和GAWWN 。 测试这两个方法时使用的代码来自于各自的作者。 除此以外，文本还设计了多个baseline models来验证模型整体的设计和每个部分对模型的重要程度。对于第一个baseline，本文直接训练Stage-1 GAN来生成64×64和256×256大小的图片，来探究本文提出的stack结构和CA技术是否对最终结果有帮助。然后修改本文的StackGAN，令其分别生成128×128和256×256大小的图片，来验证在生成更大的图片时，本文的模型是否可以生成取得更好的图片质量。另外，我们还验证了是否有必要在每个Stage都将图片描述作为约束条件之一。 数据集和评价标准&emsp;&emsp;CUB数据集包含200种鸟类，共11788张图片。由于该数据集中80%的鸟的大小与图片大小的比例小于0.5,因此我们需要对其进行剪裁预处理，确保所有的图片中鸟占总大小的比例在0.75以上。Oxford-102数据集包含102种花类，共8189张图片。为了证实本文方法的有效性，同时还对一个更具挑战性的数据集——MS COCO数据集进行了实验， MS COCO数据集中的图片具有不同的背景，同时每张图片会有多个不同的物体， 它具有80k张图片作为训练集，40k张图片作为作为验证集。 COCO中的每张图片具有5条描述，CUB和Oxford-102中的每张图片具有10条描述。 &emsp;&emsp; 评价标准： 目前，关于图片生成还没有很适合的权威的评价标准，在这里，本文采用的是最近比较流行的“inception score”来对生成图片的质量进行评价，公式如下： I = exp(E_x D_{KL}( p(y|x) || p(y)))其中， $x$ 代表生成的图片， $y$ 代表Inception model预测的图片标签。该评价公式背后包含的隐层含义是： 好的模型应该能生成多种多样并且有意义的图片 。因此，边缘分布 $p(y)$ 和条件分布 $p(y|x)$ 之间的KL散度应该越大越好。对于MC COCO数据集，本文直接使用预训练好的模型进行评价，而对于CUB和Oxfor-102数据集，本文先对其进行fine-tune迁移学习，训练出不同的模型，然后，再分别进行评价。评价时，对每个模型都需要大量的样本参与（随机挑选30k以上个生成模型产生的样本）。 &emsp;&emsp;尽管inception score可以表现出类似于人的对“高质量图片”的感知能力，但是它却不能准确反应出生成的图片和图片描述信息之间的相关联系。因此，本文还进行人工评价。本文随机选取了CUB和Oxfor-102测试集中的50条图片描述信息，从MS COCO测试集中随机选取了4k条图片描述。 对于每条描述信息，对应的生成模型都会产生5张图片， 然后让10个用户通过不同的方法对这些图片进行排序。最后用平均排序结果作为最终的人工评价。 定性/定量结果——Quantitative and qualitative results&emsp;&emsp;本文在3个数据集上与现有的两种stage of art方法进行比较，inception scores和平均人工排序结果如下表所示。可以看出，本文的Stack GAN方法在三个数据集上全都取得了最好的结果。 &emsp;&emsp;从下面的图中，也可以看出本文提出的方法，可以生成更加生动的图片，同时生成的图片也具有多样性，而非单纯的“记忆”了训练集中的数据。 成分分析——Component analysis&emsp;&emsp;在本小节中，我们会利用baseline mdoels来分析StackGAN每个成分的作用。下表展示了不同baseline models的inception socres StackGAN的设计： 如表中前四行所示，如果令Stage-1 GAN直接生成256×256的图片，inception scores会大大下降，并且在不使用CA的情况下，甚至无法生成合理的具有含义的图片。即使在使用CA的情况下可以生成含有一定意义的图片，它的图片质量也远不如Stack GAN生成的图片质量，详情如下图所示。这说明了本文提出了Stack结构是有效的。 另外，当把生成图片的分辨率降到128×128以后，inception socres的值从3.70降到了3.35。需要注意的是，inception model接受的图片大小为299×299,所以它在计算inception scores之前，会先将所有输入图片放缩到规定大小后再送入网络进行计算。因此，如果本文的模型仅仅是将128×128的图片放大到256×256，那么，最终计算出的inception scores就不会产生差异（多个线性放缩的叠加会退化成一个放缩计算），这就说明了本文的模型在生成256×256的图片时，相较于128×128的图片，确确实实生成了更多有效的信息。对于256×256的Stack GAN来说，如果仅仅只在Stage-1使用图片描述作为约束条件，inception scores的值会从3.70降到3.45，这说明将Stage-2阶段确实可以捕捉到Stage-1所忽略的文本信息，从而有助于生成高质量的图片。 条件增强——Conditioning Augmentation： 本文同时还探究了CA技术的有效性，在不使用CA技术时，inception scores的值明显下降，并且，在训练时还容易崩溃，导致生成的图片难以识别。而在使用CA时，不仅能提成inception scores的值，还能生成更加多样的鸟（如姿态、脸的朝向等）。 语句嵌入插值——Sentence embedding interpolation： 为了更进一步的证明我们的模型可以学习到更加光滑的潜在的数据信息，本文通过对text embedding线性插值的方式来进行验证。首先固定住噪声变量 $z$ ，这样一来生成的图片仅受图片text embedding约束的影响。下图中第一行的图片使用的text embedding是由我们自己可以制作的句子生成的，这些句子仅仅包含一些简单的颜色描述。结果显示，生成的图片可以根据不同的text embedding生成与之对应的鸟，可以反映出text embedding中描述的颜色，同时还能保持合理的外形。第二行展示了一些更加复杂句子生成的图片，这些句子包含更多的描述信息，用这些句子生成的图片中的鸟，它们的主要颜色会从红色慢慢变成蓝色，而翅膀的颜色会从黑色慢慢的变成棕色。 总结&emsp;&emsp;在本篇文章中，作者提出了一个Stack GAN模型框架，同时结合CA技术，来生成具有照片真实度的图片。 该模型将text-to-image synthesis任务变成了一个“草图——细化”的过程。 Stage-1 GAN主要负责输出图片的“草图”，它侧重于输出图片的基本颜色搭配和主要目标的轮廓信息。 Stage-2 会修正Stage-1中的一些错误，同时很会再次根据图片描述来补充Stage-1中遗漏的信息，从而生成更高质量的图片。 大量的实验表明，本文提出的方法是有效的。 同时，与现有的最领先的方法进行比较后，本文的模型可以生成更高分辨率的图片，同时包含更多的信息和细节。]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>图片生成 image generation</tag>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Linux命令行与shell脚本编程大全》]]></title>
    <url>%2Fz_post%2FLinux-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-Linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8Eshell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习与计算机视觉》]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%2F</url>
    <content type="text"></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy和tensorflow中的关于参数axis的辅助理解方法]]></title>
    <url>%2Fz_post%2FPython-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-numpy%E5%92%8Ctensorflow%E4%B8%AD%E7%9A%84%E5%85%B3%E4%BA%8E%E5%8F%82%E6%95%B0axis%E7%9A%84%E8%BE%85%E5%8A%A9%E7%90%86%E8%A7%A3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一句话总结：固定除axis之外的其他维度，在axis指定的维度上进行函数操作，轴的计数按shape的形状从左往右为0轴，1轴，2轴…（详解请看下面的推导） 首先声明：axis的默认值不是0，这一点我发现很多博客文章都搞错了。所以一定要知道，axis的默认值不是0，0代表0轴，而默认值是将整个shape拉伸成一个一维向量，在整个向量上求解过 axis的默认值不是0当给axis赋值为0时，和采取默认值时的表现是完全不同的，从下面的代码就可以看出。 1234567891011121314&gt;&gt;&gt; z #大小为2×3×4的数组array([[[ 2, 3, 4, 8], [ 3, 1, 4, 1], [ 6, 3, 2, 6]], [[10, 2, 45, 2], [ 2, 4, 5, 10], [22, 4, 4, 1]]])&gt;&gt;&gt; np.sum(z,axis=0) # axis=0array([[12, 5, 49, 10], [ 5, 5, 9, 11], [28, 7, 6, 7]])&gt;&gt;&gt; np.sum(z) #axis不指定，取默认值154 理解axis参数的作用刚开始学习numpy和tensorflow的朋友经常遇到类似下面这样的一些函数： 123456789101112#pythonx=[[1,2],[5,1]]x=np.array(x)z1=np.max(x,axis=0)z2=np.max(x,axis=1)#tensorflowx=tf.constant([[1.,2.],[5.,2.]]) x=tf.shape(x) z1=tf.reduce_max(x,axis=0)#沿axis=0操作 z2=tf.reduce_max(x,axis=1)#沿axis=1操作 类似的还有argmax，sum等等函数，它们都含有一个名为axis的参数，那这个参数到底是什么意思呢？一句话总结就是：沿着axis指定的轴进行相应的函数操作 直接看这句话可能看不懂，下面用一个最简单的例子来说明一下。 123456789101112import numpy as np#首先，创建一个2×3维的numpy的array数组x=[[2,3,4],[1,2,5]]x=np.array(x)#然后，计算不同参数下np.max的输出print(np.max(x))# 5print(np.max(x,0))# [2,3,5]print(np.max(x,1))# [4,5] 可以看到，如果不知道axis，那么默认就是取得整个数组的最大值，这相当于把多维数组展开成一维，然后找到这个一维数组里的最大值。而当axis=0时，直观上来看就是取得每一列的最大值，源数组总共为2行3列，所以最终的输出包含3个元素。当axis=1时，就相当与是取每一行的最大值。 上面的理解方式在二维数组还比较直观，但是如果数组达到3维4维甚至更高维时，就不能简单的从行列角度出发去理解了，这时应该考虑从“轴”的角度来看。首先，明确一点，“轴”是从外向里的，也就是说，最外层的是0轴，往内一次是1轴，2轴… 。 具体可以看下面的例子： 12345678910&gt;&gt;&gt; zarray([[[ 2, 3, 4, 8], [ 3, 1, 4, 1], [ 6, 3, 2, 6]], [[10, 2, 45, 2], [ 2, 4, 5, 10], [22, 4, 4, 1]]])&gt;&gt;&gt; z.shape(2, 3, 4) 可以看到，这是一个2×3×4的三位数组，其中0轴对应第一维（2），1轴对应第二维（3），2轴对应第三维（4）。当我们指定了函数按某一轴来计算时，函数的输出数组的shape就是去掉当前轴的shape，如下所示。 123456&gt;&gt;&gt; np.max(z,axis=0).shape(3, 4)&gt;&gt;&gt; np.max(z,axis=1).shape(2, 4)&gt;&gt;&gt; np.max(z,axis=2).shape(2, 3) 而对于输出数组的每一个元素output[i][j]的值，实际上就是z[i][...][j]集合中的最大值，如下面的代码所示。其中当axis=0时，输出数组output的shape为3×4，其中output.[2][3]的值，实际上就是z[0][2][3],z[1][2][3]的最大值，也就是（6，1）中的最大值，即为output.[2][3]=6。 再如axis=1时，输出数组output的shape为2×4，其中output.[1][2]的值，实际上就是z[1][0][2],z[1][1][2],z[1][2][2]中的最大值，也就是（45，5，4）中的最大值，即为output.[1][2]=45]。 12345678910&gt;&gt;&gt; np.max(z,axis=0)array([[10, 3, 45, 8], [ 3, 4, 5, 10], [22, 4, 4, 6]])&gt;&gt;&gt; np.max(z,axis=1)array([[ 6, 3, 4, 8], [22, 4, 45, 10]])&gt;&gt;&gt; np.max(z,axis=2)array([[ 8, 4, 6], [45, 10, 22]]) 数学公式总结用形式化的数学语言总结上面的过程就是：对于大小为[i,j,k]的输入数组z，假设axis=0，那么输出矩阵output的大小就为[j,k]，并且output的每一个元素的计算方式如下： x^{y^z}=(1+{\rm e}^x)^{-2xy^w}output[j,k]=\max_{i}(z[i,j,k])如果axis=1，那么输出矩阵output的大小就为[i,k]，并且output的每一个元素的计算方式如下： output[i,k]=\max_{j}(z[i,j,k])对于4维，5维甚至无限维的情况，计算方法是一样的，你不妨自己推导一下，如果有任何问题，欢迎可以在评论中留言。 另外，对于其他的sum，argmax等等函数中的计算方法也是一样的，只需要把函数max换成对应的函数即可，如下所示： sum： output[j,k]=\sum_{i}(z[i,j,k])argmax: output[j,k]=argmax_{i}(z[i,j,k])]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github源码：DenseCap]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-DenseCap%E6%BA%90%E7%A0%81%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[本篇博文是对论文DenseCap的源码实现，作者是斯坦福的Justin Johnson项目地址：https://cs.stanford.edu/people/karpathy/densecap/源码地址：https://github.com/jcjohnson/densecap论文地址：http://arxiv.org/abs/1511.07571 注意事项：源码是15年写的，所以使用的是比较老版本的cuda和cudnn（8.0 v5.1），并且作者也没有在继续更新代码了，所以如果你想成功运行起来的话，尽量不要用太高版本的cuda，否则可能会出现文件丢失错误（libcudnn (R5) not found in library path.） 安装安装以下依赖： 123456$luarocks install torch$luarocks install nn$luarocks install image$luarocks install lua-cjson$luarocks install https://raw.githubusercontent.com/qassemoquab/stnbhwd/master/stnbhwd-scm-1$.rockspec$luarocks install https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/torch-rnn-scm-1.rockspec （可选）安装GPU相关依赖（如果你不使用GPU跑代码，可以不装这里） 123$luarocks install cutorch$luarocks install cunn$luarocks install cudnn 下载预训练模型在命令行中键入下面的指令，运行脚本下载预训练模型（注意，下面的脚本文件在github上的项目代码里，所以你要先把github上的源代码下载下来，然后进入到项目目录里面）1$sh scripts/download_pretrained_model.sh 用图片来测试模型源码中自带了一张大象的图片，你可以用下面的指令来对大象图片进行测试，如果你想测试自己的图片，把图片放到项目中的imgs文件里，然后修改指令后面的图片名称为你自己图片的名称就可1$th run_model.lua -input_image imgs/elephant.jpg 如果你没有GPU，记得要加上-gpu -1指令来告诉模型在cpu上指令（CPU上的指令速度较慢，我自己的执行情况是：GTX980Ti：0.3s 酷睿i5/7：5～10min） 以上指令会生成vis/data文件夹，这就是模型的运行结果，可以用下面的方式查看结果， 12$cd vis$python -m SimpleHTTPServer 8181（或者python -m http.server 8181) 然后，在浏览器中打开http://localhost:8181/view_results.html. 当然，如果你想一次运行数张图片，可以使用下面的指令，该指令会将指定路径下的图片全部执行1$th run_model.lua -input_dir /path/to/my/image/folder 问题：我遇到了以下问题，这里列出我自己的解决方法，如果你还遇到了其他不同的问题，可以留言，我会尽快答复你 问题1：cutorch问题提示找不到cutorch，或者其他什么相关的错误 解决办法：重新安装cutorch1$luarocks install cutorch 不幸的是，这个解决方法对我并没有用，我最后发现是因为代码运行的cutorch版本是5.1，而由于此时我安装了高版本的cuda（9），所以在使用上面的指令安装时，安装的是cutorch 5.2，所以提示找不多5.1的cutorch，最后，我重新换回了的cuda8.0，并重新安装cutorch，解决了问题，切换cuda版本的方法可以看这里：https://blog.csdn.net/ksws0292756/article/details/80120561 问题2：libcudd.5.so.5 找不到主要原因还是cuda和cudnn的版本问题，我切换了cuda和cudnn的相关版本，换到cuda8.0和cudnn_v5.1以后， 解决了问题]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图片描述 image captioning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《TensorFlow实战》]]></title>
    <url>%2Fz_post%2FTensorFlow-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-TF%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从RCNN到Faster RCNN]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-RCNN%E7%B3%BB%E5%88%97%2F</url>
    <content type="text"></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第十二章～第十三章]]></title>
    <url>%2Fz_post%2FCpp-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CppPrimerPlusChapter12_13%2F</url>
    <content type="text"><![CDATA[第一章 预备知识第二章 开始学习C++第三章 处理数据第四章 复合类型第五章 循环和关系表达式第六章 分支语句和逻辑运算符第七章 函数——C++的编程模块第八章 函数探幽第八章 函数探幽第八章 函数探幽第八章 函数探幽第十二章 类和动态内存分配动态内存和类复习示例和静态成员 所有的对象都共用一个静态成员副本。 不能在类声明中初始化静态成员变量 ，这是因为声明描述了如何分配内存，但并不分配内存。p428 对于静态类成员，可以在类声明之外使用单独的语句来进行初始化，这是因为静态类成员是单独存储的，而不是对象的组成部分。注意下面的初始化语句，指出了类型，并使用了作用域运算符，但没有使用关键字static。p428 1int StringBad::num_strings = 0; 在构造函数中使用new来分配内存时，必须在相应的析构函数中使用delete来释放内存。如果使用new[]来分配内存，则应使用delete[]来释放内存。p429 特殊成员函数 C++提供了一些特殊的成员函数，它们会在一定条件下自动创建。p432 默认构造函数，如果没有定义构造函数; 默认析构函数，如果没有定义; 复制构造函数，如果没有定义; 赋值运算符，如果没有定义; 地址运算符，如果没有定义。 C++11提供了另外两种特殊成员函数：移动构造函数和移动赋值运算符。这将在第十八章讨论。 其中，隐式地址运算符返回调用对象的地址（即this指针的值），这与我们的初衷一致。主要引起问题的是复制构造函数和赋值运算符。p432 复制构造函数 用于将一个对象复制到 新创键 的对象中。也就是说，它用于初始化过程中，而不是常规的复制过程中。类的复制构造函数原型通常如下：Class_name(const Class_name&amp;); p433 何时调用复制构造函数：每当程序产生了对象副本时，都将使用复制构造函数，如用赋值语句初始化，函数按值传递等。具体地说，当函数按值传递对象或者函数按值返回对象时，都将使用复制构造函数。因此，进行传递时，多用引用，可以减少调用复制构造函数的时间和存储新对象的空间。 默认复制构造函数的功能：默认的复制构造函数逐个复制非静态成员，复制的是成员的值（按值复制，浅复制），如果成员本身就是类对象，则将使用这个类的复制构造函数来复制成员对象。静态函数不受影响，因为它们属于整个类。 复制构造函数容易引起的问题 如果常规构造函数中设置了一个静态变量用于计录创建对象的个数，那么就应在复制构造函数中显示写出该逻辑，否则会导致计数结果不准确。p434 由于隐式复制构造函数是按值进行复制的。在这成员变量中含有指针时是十分危险的，因为这样依赖两个对象中的成员指针就会指向同一块内存，如果其中一个对象被释放后，其指针指向的内存块可能会导致不确定的错误。另外，程序有可能会因为两次释放同一块内存而导致程序终止。具体的错误取决于系统和相关实现。p435 深度复制。深度复制可解决上述的问题。复制时应当复制指针指向内容的副本，并将副本的地址赋给新的对象，这样一来，两个对象就是完全独立的。必须自定义复制构造函数的原因就在于，一些类成员是使用new初始化的、指向数据的指针，而不是数据本身。p435 赋值运算符容易引起的问题 赋值运算符的完整函数原型如下：Class_name &amp; Class_name::operator = (const Class_name&amp;);。它接受并返回一个指向类对象的引用。 赋值运算符的功能以及何时使用：将已有的对象赋给另一个对象时，将使用重载的复制运算符。（注意，初始化赋值时，不会调用赋值运算符重载，而是调用复制构造函数）。p436 赋值的问题：主要是由于浅复制造成的数据问题，由于赋值时是按值赋值的，导致指针变量会指向相同的地址。解决的方法是提供赋值运算符（进行深度复制）的定义，其实现与复制构造函数相似，但也有一些差别。p436 由于目标对象是已经存在的对象，所以它可能引用了以前分配的数据，因此函数应使用delete[]来释放这些数据。 函数应当避免将对象赋给自身，否则，给对象重新赋值前，释放内存操作就已经删除了对象内容。这一点可以通过程序逻辑实现：if(this == &amp;s) return *this; 函数应返回一个指向调用对象的引用。通过返回一个对象，函数可以想常规赋值操作那样，连续进行赋值。 改进后的新String类 下面两种方式分配的内存量相同，区别在于前者与类析构函数兼容，而后者不兼容。p438 12str = new char[1]; //与析构函数中的delete []str; 兼容str = new char; C++11空指针： 在C++98中，字面值0有两个含义：可以表示数字值零，也可以表示空指针，这使得阅读程序的人和编译器难以区分。C++11提供了更好的解决方案，引入新关键字nullptr，用于表示空指针。原来的表示依然合法，但建议使用nullptr。 p438 静态成员函数： 不能通过对象调用静态成员函数，也不能使用this指针。如果静态成员函数是在公有部分声明，则可以使用类名和作用域解析符来调用它。 其次，由于静态成员函数不与特定的对象相关联，因此只能使用静态数据成员，不能访问其他成员数据。p441 较早的get(char *, int)版本在读取空行后，字符串中第一个字符将是一个空字符。较新的C++标准则会返回false。p446 在构造函数中使用new时应注意的事项 使用new初始化对象的指针成员时，必须注意下面几项：p446 如果在构造函数中使用new来初始化指针成员，则应在析构函数中使用delete。 new和delete必须相互兼容。new对应于delete，new[]对应于delete[]。 如果有多个构造函数，则必须以相同的方式使用new，要么都带中括号，要么都不带。因为只有一个析构函数，所有的构造函数都必须与它兼容。然而，可以在一个构造函数中使用new初始化指针，而在另一个构造函数中将指针初始化为空（0或C++11中的nullptr），这是因为delete（无论是否带[]）可以用于空指针。 应定义一个复制构造函数，通过深度复制将一个对象初始化为另一个对象。它应分配足够的空间来存储复制的数据，并复制数据，而不仅仅是数据的地址。另外，还应该更新所有受影响的静态类成员。 应定义一个赋值运算符，通过深度复制将一个对象赋值给另一个对象。它应该检查自我赋值的情况，释放成员指针以前指向的内存，复制数据而不仅仅是数据的地址，并返回一个指向调用对象的引用。 有关返回对象的说明返回指向const对象的引用 返回的对象应该是函数参数传递进来的对象，并且是const的，所以需要返回const引用。p449 返回指向非const对象的引用 返回的对象应该是函数参数传递进来的对象，但是由于参数不是const的，所以返回非const（当然也可以返回const）。常见的两种情况是重载赋值运算符以及重载与count一起使用的&lt;&lt;运算符。p449 返回对象 如果返回的对象是被调用函数中的局部变量，则不应该按引用方式返回它，因为在调用函数执行完毕时，局部对象将调用其析构函数。p450 返回const对象 返回const对象，该对象将不能作为右值，此时可以避免一些不必要的错误。p450 使用指向对象的指针 利用new创建一个对象并令指针指向它，该对象会被分配到堆内存中，直到使用delete为止，该对象一直存在。p453 1String * favorite = new String; 使用对象指针时，需要注意几点：p454 使用常规表示法来声明指向对象的指针：String * glamour; 可以将指针初始化为指向已有的对象：String * second = &amp;string_first; 想要将创建一个新的对象，可以使用new来初始化指针：String * glamour = new String 可以通过间接访问运算符-&gt;来调用类的方法。 可以通过解除引用运算符（ * ）来活得对象。 定位new运算符： 定位new运算符可以在分配内存时指定内存的位置：Sting * p1 = new (buffer) String; 。但是在使用时要注意以下几点：p457 确保定义不同的对象时，二者使用的内存地址是不同的，且内存单元之间没有重叠 delete可以与常规new运算符配合使用，但不能与定位new运算符配合使用。有时需要通过显示调用析构函数来释放对象的内存。 对于使用定位new运算符创建的对象，应以与创建顺序相反的顺序进行删除。原因在于，晚创建的对象可能依赖于早创建的对象。另外，仅当所有对象（定位new创建的）都被销毁后，才能释放用于存储这些对象的缓冲区。 复习各种技术 p459 队列模拟 如果Classy是一个类，而mem1、mem2和mem3都是这个类的数据成员，则类构造函数可以使用如下的语法来初始化数据成员。该语法需要注意以下几点：p464 这种格式只能由于构造函数; 必须用这种格式来初始化非静态const数据成员（C++11之前）; 必须用这种格式来初始化引用数据成员。123Classy:Classy(int n, int m) :mem1(n), mem2(0), mem3(n*m+2)&#123; ...&#125; 第十三章 类继承13.1 一个简单的基类 从一个类派生出另一个类时,原始类称为基类,继承类称为派生类。p481 13.1.1 派生一个类 使用公有派生，基类的公有成员将成为派生类的公有成员。基类的私有部分只能通过基类的公有和 保护 方法访问。 class A : public B //A继承自B，且是公有继承 p483 13.1.2 构造函数：访问权限的考虑创建派生类对象时，程序首先会创建基类对象，这意味着 基类对象应该在程序进入派生类构造函数之前被创建 。C++使用成员初始化列表语法来完成这种工作。 派生类构造函数必须调用基类的构造函数，利用成员初始化列表语法来显式调用基类构造函数，如果没有显式调用，那么就会调用默认的基类构造函数。p48412345678910derived::derived(type1 x, type2 y) : base(x,y)&#123; //显式调用基类B的构造函数 ...&#125;derived::derived(type1 x, type2 y)&#123; //该代码与下面的等效 ...&#125;derived::derived(type1 x, type2 y) : base()&#123; ...&#125; 有关派生类构造函数的要点如下： 首先创建基类对象（在进入派生类构造函数之前就被创建） 派生类构造函数应通过 成员初始化列表 将基类信息传递给基类构造函数 派生类构造函数应初始化派生类新增的数据成员 释放对象的顺序与创建对象的顺序相反，即首先执行派生类的析构函数，然后自动调用基类的析构函数。p485 如果没有在成员初始化列表中提供基类构造函数，程序将使用默认的基类构造函数，成员初始化列表只能用于构造函数。p486 派生类与基类之间的特殊关系 当基类的方法不是私有的（可以是公有或保护），派生类可以使用基类的方法。p488 基类指针/引用可以在不进行显式类型转换的情况下指向/引用派生类对象（反之不行）。但是只能调用基类方法。p488 继承：is-a关系 公有继承是最常用的方式（另外还有私有和保护继承），它建立一种is-a-kind-of（是一种）的关系，术语简称is-a。is-a关系的派生类对象也是一种基类对象，凡是可以对基类执行的操作，都可以对派生类执行。p489 多态公有继承 实现多态公有继承的方式有以下两种：p490 在派生类中重新定义基类的方法 使用虚方法（关键字virtual只用与类声明的方法原型中，不用于方法定义） 如果要在派生类中重新定义基类的方法，通常应将基类方法声明为虚的。这样，程序将根据对象类型而不是引用或指针的类型来选择方法版本。为基类声明一个虚析构函数也是一种惯例。p493 在派生类方法中，标准技术是使用作用域解析符来调用基类方法。p496 静态联编和动态联编 将源代码中的函数调用解释为执行特定的函数代码块被称为函数名联编（binding）。在编译过程中进行联编被称为静态联编（static binding），又称为早期联编（early binding）。但是有时候，无法在编译时确定使用哪个函数块（如虚函数），所以，编译器必须生成能够在程序运行时选择正确的虚方法的代码，这被成为动态联编（dynamic binding），又称为晚期联编（late binding）。p502 指针和引用类型的兼容性 将派生类引用或指针转换为基类引用或指针被称为向上强制转换（upcasting）。如果不使用显式类型转换，则向下强制转换是不允许的。p502 隐式向上强制转换使基类指针或引用可以指向基类对象或派生类对象，因此需要动态联编。C++使用虚成员函数来满足这种需求。p503 虚成员函数和动态联编 编译器对非虚方法使用静态联编，对虚方法使用动态联编。因为虚方法是根据对象类型来选择的，而对象类型只有在运行时才能确定。非虚方法则是根据引用或指针的类型来选择方法，它们可以在编译时确定。p503 为什么有两种联编类型以及为什么默认为静态联编： 动态联编的好处是可以重新定义类方法，但是在运行阶段跟踪对象类型会产生一定的开销，这使得动态联编没有静态联编效率高，这也是选择静态联编为默认方式的原因。p503 虚函数的工作原理： C++规定了虚函数的行为，但将实现方法留给了编译器作者。通常，编译器处理虚函数的方法是，给每个对象添加一个隐藏成员。隐藏成员中保存了一个指向函数地址数组的指针。这种数组成为虚函数表（virtual function table，vtbl）。虚函数表中存储了为类对象进行声明的虚函数的地址。 派生类对象将包含一个指向独立地址表的指针。如果派生类提供了虚函数的新定义，该虚函数表将保存新函数的地址;如果没有重新定义虚函数，则保存函数原始版本的地址。调用虚函数时，程序将查看存储在对象中的vtbl地址，然后转向相应的函数地址表。p504 根据工作原理可以得出，使用虚函数时，在内存和执行速度方面有一定的成本（虽然非虚函数效率高，但不具备动态联编功能），包括：p505 每个对象都将增大，增大量为存储地址的空间; 对于每个类，编译器都将创建一个虚函数地址表（数组）; 对于每个函数调用，都需要执行一项额外的操作，即到表中查找地址。 有关虚函数注意事项 虚函数的一些要点：p505 在基类方法的声明中使用关键字virtual可使该方法在基类以及所有的派生类（包括儿子的儿子）中是虚的。 如果使用指向对象的引用或指针来调用虚方法，程序将使用为对象类型定义的方法，而不使用为引用或指针类型定义的方法。这称为动态联编或晚期联编。这种行为非常重要，因为这样基类指针或引用可以指向派生类对象。 构造函数不能是虚函数。创建派生类对象时，将调用派生类的构造函数，而不是基类的构造函数，然后，派生类的构造函数会使用基类的构造函数，这种顺序不同于继承机制。因此，派生类不急成基类的构造函数。p505 除非类不是基类，否则应该将析构函数声明为虚函数。p505 友元不能是虚函数，因为友元不是类成员，而只有成员才能是虚函数。p505 如果派生类没有重新定义函数，将使用该函数的基类版本。如果派生类位于派生链中，则将使用最新的虚函数版本。p506 重新定义继承的方法并不是重载，而是将基类的方法隐藏，也可以看作是重写。由此，得出两条经验规则：第一，如果重新定义继承的方法，应确保与原来的原型完全相同，但如果返回类型是基类引用或指针，则可以修改为指向派生类的引用或指针。第二，如果基类声明被重载了，则应在派生类中重新定义所在的基类版本。如果只定义类部分版本，则其他版本将被隐藏。另外，如果不需要修改，则新定义直接调用基类版本即可，如void derived::show() { const(base::show()); } 访问控制：protected 对于外部世界来说，保护成员的行为与私有成员相似，但对于派生类来说，保护成员的行为与公有成员相似。p507 对于数据成员最好采用私有访问控制，同时通过基类方法使派生类能够访问基类数据。对于成员函数来说，保护访问控制很有用，它让派生类能够访问公众不能使用的内部函数。 抽象基类 从多个类中抽象出它们的共性，将这些共性放在一个抽象基类（abstract base class，ABC）中，然后再从该ABC派生出这些类。ABC中有些方法不能直接实现，C++通过纯虚函数（pure virtual function）提供未实现的函数。纯虚函数声明的结尾处为=0，如下所示： 1virtual double Area() const = 0; // a pure virtual function 当类声明中包含纯虚函数时，则不能创建该类的对象，而只能作为基类使用。要成为真正的ABC，必须至少包含一个纯虚函数，原型声明中的=0是虚函数成为纯虚函数，一般纯虚函数没有定义，但C++允许纯虚函数有定义，即可以把所有派生类的某个共同操作作为纯虚函数的定义，然后在派生类重写该纯虚函数时调用。p509 13.7 继承和动态内存分配如果基类使用动态内存分配，并重新定义赋值和复制构造函数，那么将怎么影响派生类的实现呢？有以下几种情况： 13.7.1 派生类不使用new 如果基类使用了动态内存分配，而派生类未使用，那么就不需要为派生类定义显式析构函数、赋值和复制构造函数。 p516 13.7.2 派生类使用new 如果派生类使用了new，就必须为派生类定义显示析构函数、赋值和复制构造函数。p517 13.8 类设计回顾13.8.1 编译器生成的成员函数 默认构造函数 &emsp;&emsp;如果没有定义任何构造函数，编译器将定义默认构造函数。 复制构造函数&emsp;&emsp;如果程序没有使用（显式或隐式）复制构造函数，编译器将提供原型，但不提供函数定义。 复制运算符&emsp;&emsp;默认的赋值运算符用于处理同类对象之间的赋值。不要将赋值与初始化混淆了。如果语句创建新的对象，则是用初始化。如果语句修改已有对象的值，则是赋值。 13.8.2 其他的类方法 构造函数 构造函数不同于其他类方法，因为它创建新的对象，而其他类方法只是被现有的对象调用。这是构造函数不被继承的原因之一，继承意味着派生类对象可以使用基类的方法，然而，构造函数在完成其工作之前，对象并不存在。 析构函数 一定要定义显式析构函数来世放类构造函数使用new分配的所有内存，并完成类对象所需的任何特殊的清理工作。对于基类，即使它不需要析构函数，也应提供一个虚析构函数。 转换 使用一个参数就可以调用的构造函数定义了从参数类型到类类型的转换。 按值传递对象引用传递 返回对象和返回引用 有些类方法返回对象，有些返回引用，返回对象涉及生成返回对象的临时副本。优先返回引用，但函数不能返回在函数中创建的临时对象的引用。 使用const可以是用const来确保方法不修改参数。 注意，如果函数将参数声明为指向const的引用或指针，则不能将该参数传递给另一个函数，除非后者也确保了参数不会被修改。 13.8.3 公有继承的考虑因素 is-a关系 要遵循is-a关系。如果派生类不是一个特殊的基类，则不用使用公有派生。 什么不能被继承 构造函数是不能继承的，也就是说，创建派生类对象时，必须调用派生类的构造函数。 C++11新增了一种能够继承构造函数的机制，但默认是不能继承构造函数。 析构函数也是不能继承的。 赋值运算符是不能继承的。 赋值运算符 私有成员与保护成员 虚方法 析构函数 友元函数]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DenseCap---CVPR2016]]></title>
    <url>%2Fz_post%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB-DenseCap%2F</url>
    <content type="text"><![CDATA[本篇论文解读的排版主要参见原文的格式，针对原文中的每一个小节进行展开，有的是对原文的一个提炼和简单概括，有的是对原文中涉及但是又没有详细介绍的技术的补充和说明。原文连接：https://cs.stanford.edu/people/karpathy/densecap/作者个人主页：https://cs.stanford.edu/people/jcjohns/PS：本篇博文不是对原文的简单翻译，论文中每一处涉及到的知识点以及论文中没有提及的技术细节，本文都会做一定的补充说明，如果还有什么看不懂的地方的话，可以留言一起讨论，我会尽量在24小时内回复。 (正文所有图片中的ksws0292756水印是我的CSDN博客) 这里输入题注 摘要&emsp;&emsp;这篇文章的主要工作是对图像的dense captioning。所谓dense captioning，就是要描述的对象不再是一幅简单的图片，而是要将图片中的许多局部细节都都用自然语言描述出来。这篇文章所做的工作可以说是object detection和image captioning的一般化，即当描述的语言是一个单词的时候，就可以看作是object detection，当描述的对象是整幅图片的时候，就成了普通的image captioning。这篇文章的主要贡献在于提出了一个Fully Convolutional Localization Network（FCLN）网络结构，该网络结构可以进行端到端式的训练，无需额外的候选区域生成模型（以及整合到网络内部），只需要进行一轮优化和前馈计算就可以得到输出结果。网络模型有三部分组成：卷积网络（Convolutional Network）、密集定位层（dense localization layer） 和RNN语言模型。 介绍&emsp;&emsp;本小节主要介绍了dense cationing任务的定义，以及相对应的object detection和image caotioning方面的研究。大家可以自己看一下原文 相关工作&emsp;&emsp;这里只给出重要的2篇论文（作者主要是在这两篇论文的几处上进行模型构建的），其他的可以参见原文 Faster R-CNNhttp://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networksDeep Visual-Semantic Alignments for Generating Image Descriptionshttps://cs.stanford.edu/people/karpathy/deepimagesent/ 模型总览目标：设计一个可以标定出感兴趣区域并且用自然语言描述其中内容的网络框架模型挑战与难点：在兼顾高效性和有效性的前提下，开发出一个可以支持端到端训练并且只需一次优化的模型 模型框架 卷积网络（Convalutional Network）&emsp;&emsp;作者采用了基于VGG-16的网络结构，包含13层卷积核为3×3的卷积层和4层池化核为2×2的最大池化层（原本的VGG是5层池化层，这里作者做了一些小改动，改为4层），因此，对于大小为$3×W×H$的图片，经过卷积网络后，输出结果是$C×W’×H’$的特征图谱，这里$C=512$，$W’=\lfloor\frac{W}{16}\rfloor$，$H’=\lfloor\frac{H}{16}\rfloor$，该特征图谱就是下一层Fully Convolutional Localization Layer的输入。 全卷积定位层（Fully Convolutional Localization Layer）输入和输出 输入 : 来自卷积网络的特征图谱$C×W’×H’$（size任意） 输出 : 输出B个候选区域的表征向量（定长），每个特征向量都包含下面三个关键信息： 候选区域的坐标：输出形式是一个$B×4$的矩阵，每行代表一个候选区域的坐标 候选区域的置信分数：一个长度为$B$的一维列向量，向量内每个元素都给出了候选区域的得分。得分越高说明越可能是真实区域 候选区域的特征：输出形式为$B×C×X×Y$的特征集合，这里B代表区域个数，$X×Y$表示特征图谱的大小（注意，这里的size已经是固定的），$C$代表特征的维度 &emsp;&emsp;这里额外说明一下，在CNN阶段我们不需要指定输入图片的大小（传统CNN分类任务由于FC全连接层的限制，使得输入图片的大小是固定的），因为这里我们关心的是图片的特征，而卷积层和池化层根本不care输出尺寸的多少，它们只负责拿到前一层的特征图谱（feature map）。&emsp;&emsp;但是为什么这里的输出必须是定长的向量呢？主要是因为后面RNN模型的制约，由于RNN模型接受的数据必须的定长的，所以在全卷积定位层（FCL）阶段的最后一步，我们需要使用双线性插值的方法来使输出成为定长的特征向量。 卷积锚点（Convolutional Anchors）&emsp;&emsp;这里的工作主要参考自Faster R-CNN。主要思想是借助一系列具有平移不变性的锚点（anchors）来预测候选区域的位置和大小，具体做法如下：&emsp;&emsp;对于大小为$W’×H’$的特征图谱来说，将图谱中的每一个像素点都做为一个锚点（anchor）（锚点数量为$W’×H’$个），将该点反向映射会原始图像$W*H$中，然后基于该锚点，画出不同宽高比和大小的若干个“锚箱”（anchor box）。下图所示是3个具有相同大小但是不同宽高比的锚箱示例（分别为1:1，1:2，2:1）。 &emsp;&emsp;如果采用Faster R-CNN的设置，即每个锚点对应3个不同的size取值（$128^2，256^2，512^2$）和3个不同的宽高比取值（1:1，1:2，2:1），因此，每个锚点对应的锚箱数量为$k=9$，在本文中采用的是$k=12$，具体对应多少个size和宽高比文中并没有给出。对于这$k$个锚箱，定位层（localization layer）会通过回归模型来预测相应的置信分数（score）和位置信息（scalars）。具体的计算过程是将特征图片作为输入，经过一个卷积核为$3×3$的卷积层（filter个数为256)，然后再经过一个卷积核为$1×1$卷积层（filter个数为$5k$，这里$k$代表anchor box的数量）,所以这一层的最终输出是$5k×W’×H’$的张量，包含了所有锚点对应的置信分数和位置信息。 边界回归（Box Regression）&emsp;&emsp;边界回归主要是对刚刚预测的候选区域的一次精修，进行边界回归的原因主要是当前的候选区域可能与真实区域并不是特别匹配，如下图所示： &emsp;&emsp;图中，绿色框代表真实区域，红色框代表目前的候选区域，我们可以看到，候选区域虽然可以判断出区域内存在物体（飞机），但是它的定位并不是很准取，这时候就可以利用box regression来对边框进行微调。核心思想是利用线性回归得到关于边框的四个位移参数$（t_x,t_y,t_w,t_h）$，然后通过下面的式子对候选区域的中点$（x,y）$和size$（w，h）$进行更新 x=x_a+t_xw_a$$$$ y=y_a+t_yh_a$$$$ w=w_aexp(t_w) $$$$h=h_aexp(h_w)有关box regression的详细讲解可以参考这篇论文：https://blog.csdn.net/zijin0802034/article/details/77685438（PS：这篇论文的讲解是基于R-CNN的，其中的符号表示与本文有些出入，如$t_x,t_y$在R-CNN中代表的是真实区域的中心坐标，看的时候注意一下各个符号都表达了什么，不要搞混了） 区域采样&emsp;&emsp;以图像大小为$W=720，H=540$，锚箱（anchor box）数量为$k=12$的情况为例，得到的候选区域的个数应该为$\lfloor\frac{720}{16}\rfloor×\lfloor\frac{540}{16}\rfloor×12=17820$（文章中写的是17280，我感觉应该是写错了）。为了降低成本，我们只取这些候选区域的子集来参与训练过程和测试过程，具体选取原则如下： 在训练阶段: 采用Faster R-CNN的方法，采集一个大小为$B=256$的minibatch来进行训练，在这$B$个候选区域中，有至多$B/2$个正样本，其余均为负样本。采集时，如果所有的候选区域中（这里为17280个）正样本的数量不足$B/2$个，那么就由负样本补充，所以，最终的minibatch中正样本的数量$B_P\le B/2$，而负样本的数量$B_N=B-B_P$。正样本和负样本的定义如下： 正样本：候选区域与一个或多个真实区域的面积相交部分大于70% 负样本： 候选区域与所有真实区域的面积相交部分小于30% 在测试阶段: 基于每个候选区域的置信分数，采用非极大抑制选取$B=300$个置信分数最高的候选区域 &emsp;&emsp;非极大抑制：这里的抑制就是忽略的意思，非极大抑制的意思就是忽略那些与具有最高score值的候选区域的相交面积大于设定阈值的其他候选区域。这样做的目的主要是为了减少重叠区域的输出，从而更精细化的定位目标位置。 &emsp;&emsp;经过以上操作，最终我们可以得到关于这B个候选区域的位置坐标和置信分数，表示为B×4和B×1的张量，这就是定位层（localization layer）的输出。 双线性插值（Bilinear Interpolaion） &emsp;&emsp;在经过采样后，我们得到的各个候选区域是具有不同大小和宽高比的矩形框。为了与全连接层（主要进行识别分类）和RNN语言模型的进行建立连接，我们必须将候选区域提取成固定大小的特征表示向量。对于这一问题，Faster R-CNN提出了感兴趣区域池化层（RoI pooling layer），具体方法是大小为$W’×H’$的卷积特征图谱进行划分，得到具有$X×Y$个小网格的网格图，然后根据最大池化的原理，将小网格内的像素最大值作为代表该网格的特征像素，最终可以得到定长为$X×Y$的特征向量。划分示意图如下所示。 &emsp;&emsp;RoI pooling layer需要两个输入：卷积特征图谱和候选区域坐标。但是在应用梯度下降时，该方法只能对特征图谱采用反向传播（BP）算法，而不能对候选区域坐标使用BP算法，为了克服这个缺点，在本文中，作者采用了双线性插值。&emsp;&emsp;具体来说，就是对于任意的特征图谱$U（C×W’×H’）$和候选区域，我们要将其放缩成大小为$（C×X×Y）$的特征图谱$V$，放缩过程按照如下步骤进行： 计算$V$到 $U$的反向投影坐标值，例如对于特征图谱$V$中的任意一点坐标$(x{i,j}^V,y{i,j}^V)$，投影到$U$中的坐标值为x_{i,j}=x_{i,j}^V*\frac{W'}{X}，y_{i,j}=y_{i,j}^V*\frac{H'}{Y}很容易看出，这里$x{i,j}和y{i,j}$的值均为浮点数，然而图像的像素坐标在计算机中必须为整数，所以这里坐标$(x{i,j},y{i,j})$对应的像素点是虚拟像素点，并不是$U$中实际存在的点。 按照双线性插值法，得到$U$中$(x{i,j}^U,y{i,j}^U)$坐标点的像素值，该像素值就是$V$中对应点的像素值$V{c,i,j}$，计算公式如下$$V{c,i,j}=\sum{i’=1}^{W’}\sum{j’=1}^{H’}U{c,j’,j’}k(i’-x{i,j})k(j’-y_{i,j})，其中 ，k(d)=max(0,1-|d|)$$ 利用上面的方法，计算$V$中所有像素点的坐标值，得到$C×X×Y$的特征图谱 &emsp;&emsp;对于上面的步骤可能理解起来不太直观，下面我们利用一个例子来帮助理解，我们假定源图谱U的大小为4×4，目的图谱V的大小为3×3，如下图所示 如果我们想要知道V中某点的坐标值，以V的中心点为例，我们先计算出V反向投影到U的坐标值$(x{i,j},y{i,j})$ x_{i,j}=1*\frac{4}{3}=1.333，y_{i,j}=1*\frac{4}{3}=1.333然后，利用上面的公式计算$V_{c,i,j}$的值 V_{c,i,j}=95*0.667*0.667+32*0.667*0.333+156*0.333*0.667+84*0.333*0.333=93.336\approx 93 最终，对于$B$个候选区域，我们会得到形式为$B×C×X×Y$的一个张量，这就是localization layer的最终输出。 识别网络（Recognition Network）&emsp;&emsp;识别网络以一个全连接的神经网络，它接受的是来自定位层的候选区域的特征矩阵（定长）。将每个候选区域的特征拉伸成一个一维列向量，令其经过两层全连接层，每次都使用ReLU激活函数和Dropout优化原则。最终，对于每一个候选区域，都会生成一个长度为$D=4096$的一维向量。&emsp;&emsp;将所有的正样本的存储起来，形成一个$B×D$形状的矩阵，将该矩阵传送到RNN语言模型中。另外，我们允许识别网络对候选区域的置信分数和位置信息进行二次精修，从而生成每个候选区域最终的置信分数和位置信息，这一次的精修与之前的box regression基本是一样的，只不过是针对这个长度$D$的向量又进行了一次box regression而已（在R-CNN论文中已经指出，理论上是可以通过迭代使用box regression来不断让候选区域无限逼近真实区域的，不过实现表明，对最终的结果提升并不大）。 RNN语言模型（RNN Language Model）&emsp;&emsp;将图片的特征图谱输入到RNN语言模型当中，从而获得基于图片内容的自然语言序列。基本方法是将识别网络的输出结果进行编码（每一个候选区域到对应一个编码），记为$x{-1}=CNN（I）$，然后将该区域对应的真实描述$s_1,…,s_T$也进行编码，记为$x_1,…x_T$，这里，$x_i$就是对应的$s_i$的向量编码。于是，我们就得到了长度为T+2的单词向量序列$x{-1},x0,x_1,…,x_T$，其中$x{-1}$代表这候选区域的图像信息，$x0$是特殊的开始标志，$x_1,…x_T$代表每一个单词的向量编码，将这T+2长度的向量序列feed到RNN中，训练出一个预测模型。接着，在预测阶段，训练好的RNN语言模型的 **输入是$x{-1}$和$x0$** （START token），然后根据公式$h_t,y_t=f(h{t-1},x_t)$分别计算出隐藏状态$h_0$和单词向量$y_0$。这里，$y_t$是一个长度为$|V|+1$的向量，$V$代表词库的size，多出来的1是一个特殊的END标志，根据$y_0$预测出第一个word，然后将该word再作为下一层LSTM网络（RNN中的语言模型网络）的输入，预测出第二个word，一直 递归 的重复这个过程，直到输出的word是END标志为止。该预测过程可以用下面的公式和两张示意图表示。 x_{-1}=CNN(I)$$$$x_t=W_eS_t，t\in \{ 0...N-1 \} $$$$p_{t+1}=LSTM(x_t)，t\in \{ 0...N-1\}&emsp;&emsp;上式中，$x{-1}$代表$CNN$生成的$D$维图像特征向量，并且它将作为整个$RNN$语言模型的初始输入，$S_t$代表RNN模型生成的一个个单词（word），其中$S_0$是一个特殊的开始标志，$p{t+1}$代表第$t+1$个单词在整个单词表中的分布率，它是$p(S_{t+1}|I,S_0,…,S_t)$的简写形式，之后，选取$p_t$概率最大的元素作为句子中第$t$个单词的输出，如果概率最大的元素对应的是$END$标识符，则句子生成结束，迭代终止。 有关RNN模型生成图片描述的详细介绍可以参考下面两篇论文：Show and Tell: A Neural Image Caption Generatorhttps://arxiv.org/abs/1411.4555Deep Visual-Semantic Alignments for Generating Image Descriptionshttps://arxiv.org/abs/1412.2306 损失函数（Loss function）&emsp;&emsp;这篇文章训练时的损失函数有五个，如下图所示，首先是lacalization layer定位层的边框位置回归和置信分数两处损失函数，前者使用smooth L1 loss，后者使用binary logistic loss。损失函数的数学定义可以参考Fast R-CNN和Faster R-CNN里面的损失函数。&emsp;&emsp;接下来是Recognition Network的两处损失函数，该层和localization layer一样，也是边框位置和置信分数两个损失函数，最后是语言模型的损失函数，采用的取交叉熵（cross-entropy）损失函数。&emsp;&emsp;作者利用bathch size和sequence length对所有的损失函数都进行了归一化。经过不断测试，作者发现将后续区域边框的初始权重设为0.1，将图片描述的置信权重设为1.0，是比较高效率的初始化设置。文中并没有对损失函数给出详细定义，通过查阅相关论文后，得到了各个损失函数的详细定义如下： 置信度损失函数（binary logistic loss） : l(w,b)=-\sum_{i=1}^{m}lnP(y_i|x_i;w,b)$$$$P(y=1|x)=\frac{e^{w^Tx+b}}{1+e^{w^Tx+b}}$$$$P(y=0|x)=\frac{1}{1+e^{w^Tx+b}}这里，$w$为矩阵，$b$为向量，$x_i$是输入的图像区域的特征图谱，$y_i$为期望的真实输出（is or not object） 边框位置回归损失函数（smooth L1 loss）: L_{loc}(t^u,v)=\sum_{i\in \{x,y,w,h\}}smooth_{L_1}(t_i^u-v_i) smooth_{L_1}(x)=\begin{cases} 0.5x^2& \text{if |x|]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>图片描述 image captioning</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《TensorFlow实战Google深度学习框架》]]></title>
    <url>%2Fz_post%2FTensorFLow-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-TF%E5%AE%9E%E6%88%98Google%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第九章～第十一章]]></title>
    <url>%2Fz_post%2FCpp-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CppPrimerPlusChapter9_11%2F</url>
    <content type="text"><![CDATA[第一章 预备知识第二章 开始学习C++第三章 处理数据第四章 复合类型第五章 循环和关系表达式第六章 分支语句和逻辑运算符第七章 函数——C++的编程模块第八章 函数探幽第九章 内存模型和名称空间单独编译 头文件中常包含的内容： （不能将函数定义放在头文件中，容易出现重定义错误） p301 函数原型 使用#define或const定义的符号常量 结构声明 （结构声明不创建变量，只是告诉编译器如果创建该结构变量） 类声明 模板声明 内联函数 在同一个文件中只能将同一个头文件包含一次，利用下述C/C++技术可以避免多次包含同一个头文件。p302 1234#ifndef COORDIN_H_#define COORDIN_H_...#endif 多个库的链接： 不同的编译器可能会为同一个函数生成不同的修饰名称（取决于编译器设计人员），名称的不同将使链接器无法将一个编译器生成的函数调用与另一个编译器生成的函数定义匹配。在链接编译模块时，请确保所有对象文件或库都是由同一个编译器生成的。（如果有源代码，通常可以用自己的编译器重新编译源代码来消除链接错误）。p304 存储持续性、作用域和链接性 C++使用三种（在C++11中是四种）不同的方案来存储数据，这些方案的区别就在于数据保留在内存中的时间：p304 自动存储持续性 静态存储持续性 线程存储持续性（C++11） 动态存储持续性 作用域和链接 作用域（scope）描述了名称在文件（翻译单元）的多大范围可见。链接性（linkage）描述了名称如何在不同单元间共享。 自动变量的名称没有链接性，因为它们不能共享。p305 全局作用域是名称空间作用域的特例。 p305 自动存储持续性 C++11中的auto： 在C++11中，auto关键字用于自动类型推断。但在C语言和以前的C++版本中，auto用于显式的指出变量为自动存储（实际中很少很使用，因为默认就是自动存储类型）。在C++11中，这种用法不再合法。p307 函数及其中的变量存放于“栈”中——这是专门流出来的一段内存，栈的长度由具体的实现决定。p308 寄存器变量：在C++11中，关键字register的作用只是显示地指出变量是自动的。鉴于它只能用于原本就是自动的变量，使用它的唯一原因是，指出程序员想使用一个自动变量。保留该关键字的原因是避免使用了该关键字的现有代码非法。p309 静态持续变量 和C语言一样，C++也为 静态 存储持续性变量提供了3种链接性，这三种链接性都在整个程序执行期间存在，与自动变量相比，它们的寿命更长。p309 外部链接性（可在其他文件中访问） 内部链接性（只能在当前文件中访问） 无链接性（只能在当前函数或代码块中访问，与自动变量不同的是，就算不在函数中，变量也存在，只是不能访问） 由于静态变量的数目在程序运行期间是不变的，因此程序不需要使用特殊的装置（如栈）来管理它们。编译器将分配固定的内存块来存储所有的静态变量，这些变量在整个程序执行期间一直存在。另外，如果没有显式地初始化静态变量，编译器将把它设置为0。在默认情况下，静态 数组和结构将每个元素或成员的所有位都设置为0。p309 创建三种链接性的静态持续变量：p309 外部链接性：必须在代码块的外面声明 内部链接性：必须在代码块的外面声明，并使用static限定符 无链接性：必须在代码块内部声明，并使用static限定符123456789int global = 1000; //静态持续变量，外部链接性，作用域为整个文件static int one_file = 50; //静态持续变量，内部链接性，作用域为整个文件int main()&#123; ...&#125;void funct1(int n)&#123; static int count = 0; //静态持续变量，无链接性，作用域为局部 int llama = 0;&#125; 五种变量存储方式：p310 自动 寄存器 静态，无链接 静态，外部链接 静态，内部链接 关键字重载： 关键字的含义取决于上下文，static用于局部声明，以指出变量是无链接性的静态变量时，表示的是存储持续性。而用于代码块外的声明时，static表示内部链接性，因为位于代码块外的变量已经是静态持续性了。p310 静态变量的初始化： 静态变量有三种初始化方式：零初始化（变量设为零）、常量表达式初始化和动态初始化。 零初始化和常量表达式初始化被统称为静态初始化，这意味着在编译器处理文件时初始化变量，动态初始化意味着变量将在编译后初始化。p310 静态变量的初始化过程： 首先，所有静态变量都被零初始化，而不管程序员是否显式地初始化了它。接下来，如果使用常量表达式初始化了变量，且编译器仅根据文件内容（包括被包含的头文件）就可计算表达式，编译器将执行常量表达式初始化。必要时，编译器将执行简单计算。最后，剩下的变量将被动态初始化。 常量表达式并非只能是使用字面常量的算术表达式。（sizeof运算符也可以）p310 链接性为外部的变量通常简称为外部变量，也称全局变量，它们的存储持续性为静态，作用域为整个文件。p310 静态持续性、外部链接性 单定义规则（One Definition Rule，ODR）： 变量只能定义一次。为满足这种需求，C++提供了两种变量声明：p311 定义声明（简称定义）：为变量分配存储空间。 引用声明（简称声明）：不给变量分配存储空间，引用已有的变量。使用关键字extern12double up; //定义声明exterm int blem; //blem在别处定义 如果要在多个文件中使用外部变量，只需在一个文件中包含该变量的定义（单定义规则），但在使用该变量的其他所有文件中，都必须使用关键字extern声明它。p311 1234567//file01.cppextern int cats = 20; // 由于初始化，所以这里是定义而非声明int dogs = 22; //定义//即使去掉file01.cpp文件中的extern也无妨，效果相同。//file02.cppextern int cats; //使用extern且无初始化，说明使用的是其他文件的catsextern int dogs; //同上 静态持续性、内部链接性 将作用域为整个文件的变量声明为静态外部变量（内部链接性），就不必担心其名称与其他文件中的外部变量发生冲突123456789101112131415//file1int errors = 20;//file2int errors = 5;int main()&#123; cout&lt;&lt;errors; //报错，errors与file1中的外部变量重定义 ...&#125;//解决方法：file2static int errors = 5;int main()&#123; cout&lt;&lt;errors; // 输出5&#125; 静态存储持续性、无链接性 局部静态变量：虽然该变量只在该代码块中可用，但它在该代码块不处于活动状态时仍然存在。因此在两次函数调用之间，静态局部变量的值将 保持不变 。另外，如果初始化了静态局部变量，则程序 只在启动时进行一次初始化 。以后再调用函数时，将不会被再次初始化。p315 说明符和限定符 存储说明符（storage class specifier）：p317 auto（在C++11中不再是说明符） register static extern thread_local（C++11新增的） mutable：即使结构（或类）变量为const，其某个成员也可以被修改 cv-限定符（cv-qualifer）：p317 const：内存被初始化后，程序便不能再对它进行修改 volatile：即使程序代码没有对内存单元进行修改，其值也可能发生变化 在默认情况下全局变量的链接性为外部，但const全局变量的链接性为内部。因此，将一组常量放在头文件中，其他引用该头文件的文件都相当于自己定义了私有的常量，这就是能够将常量定义放在头文件中而不会重定义的原因。p318 如果处于某种原因，程序员希望某个常量的链接性为外部的，则可以使用extern关键字来覆盖默认的内部链接性，extern const int states = 50;，在这种情况下，必须在所有使用该常量的文件中使用extern关键字来声明它。p318 函数和链接性 C++不允许在一个函数中定义另一个函数，因此所有函数的存储持续性都自动为静态，即在整个程序执行期间都一直存在。p318 在默认情况下，函数的链接性为外部。即可以在文件间共享，使用extern来指出函数实在另一个文件中定义的（可选）。p318 可以使用关键字static将函数的链接性设置为内部，使之只能在一个文件中使用，必须同时在原型和函数定义中使用该关键字。p318 内联函数不受单定义规则的约束，这允许程序员能够将内联函数的定义放在头文件中。但是C++要求同一个函数的所有内联定义都必须相同。 p319 C++查找函数顺序：静态（在本文件中找）——外部（在所有的程序文件中找）——在库函数中找。因此如果定义了一个与库函数同名的函数，编译器优先使用程序员定义的版本（C++不推荐这样做）。p319 语言链接性 不同的语言采用了不同的链接性，为了解决这种问题，需要特别指定函数采用的链接性（默认为C++链接性）。p319 存储方案和动态分配 前面介绍的分配内存的5种方案（线程内存除外），它们不适用于C++运算符new分配的内存，这种内存被称为动态内存。动态内存由运算符new和delete控制，而不是由作用域和链接性规则控制。 p320 使用new运算符初始化： 1234567891011//如果要为内置的标量类型分配存储空间并初始化，可在类型名后面加上括号和初始值int *pi = new int(6);double *pd = new double(99.99);//如果要初始化常规结构或数组，需要用大括号的列表初始化，这要求编译器支持C++11.struct where &#123;double x; double y; double z;&#125;;where *one = new where&#123;2.5, 5.3, 6.2&#125;;int *ar = new int [4]&#123;2,4,6,8&#125;;//列表初始化也可以用于单值变量int *pin = new int&#123;6&#125;;double *pdo = new doubel&#123;99.99&#125;; new失败时，在最初的10年中，C++在这种情况下让new返回空指针，但现在将引发异常std::bad_alloc。p320 运算符new和new[]分别调用函数1和2，同样delete和delete[]调用3和4。p320 123456789101112void * operator new(std::size_t);void * operator new[](std::size_t);void * operator delete(void *);void * operator delete[](void *);//std::size_t是一个typedef，对应于合适的整型int *pi = new int;//该式会被转换为下式int *pi = new(sizeof(int));int *pa = new int[40];//同样，转换为下式int *pa = new(40*sizeof(int));delete pi;//同样，转换为下式delete(pi); 定位new运算符。p321 名称空间传统的C++名称空间 一些基本术语：p324 声名区域：变量可以进行声明的区域。对于全局变量，其声明区域为所在的文件，对于局部变量，其声明区域为所在的代码块。 潜在作用域：变量的潜在作用域从声明点开始，到其声明区域的结尾。因此潜在作用域比声名区域小。 作用域：变量对程序而言可见的范围。变量并非在其潜在作用域内的任何位置都可见，如被另一个嵌套声明区域中的同名变量隐藏。作用域小于潜在作用域。 新的名称空间特性 一个名称空间中的名称不会和另一个名称空间的相同名称发生冲突，利用新的关键字namespace可以创建名称空间：p325 12345678910111213141516171819202122namespce Jack&#123; double pail; void fetch();&#125;namespace Jill&#123; double fetch; int pal;&#125;//名称空间是开放的，可以重复使用namespace来将名称添加到名称空间中namespace Jack&#123; char * goose(const char*); //将goose添加到Jack名称空间（已有pail和fetch）&#125;//可以在另一个文件中使用namespce为函数原型写出定义namespace Jack&#123; void fetch()&#123; ... &#125;&#125;//使用作用域解析运算符来使用名称空间Jack::pail = 12.35;Jill::pal = 1;Jack::fetch(); 名称空间可以是全局的，也可以位于另一个名称空间中，但不能位于代码块中。保持，在默认情况下，在名称空间中声明的名称的链接性是外部的（除非使用了const）。p326 using声明和using编译指令： p326 using声明：using Jack::fetch 使特定的标识符可用（可以用在代码块中）。 using编译指令：using namespace Jack 使整个名称空间可用（可以用在代码块中，放在代码块中时，虽然它只在该代码块中可见，但是其作用域不是布局的）。p328 使用using编译指令和使用多个using声明是不一样的。假设名称空间和声明区域定义了相同的名称。如果试图使用using声明将名称空间的名称导入该声明区域，则这两个名称会发生冲突，从而出错。如果使用using编译指令将该名称空间的名称导入该声明区域，则局部版本将隐藏名称空间版本。p328 推荐使用using声明而不是using编译指令，因为前者更安全。在引入的名称有相同局部名称时，前者会发出错误提示，后者只会隐藏名称空间版本而不进行提示。p329 名称空间可以嵌套：1234567891011121314151617181920namespce elements&#123; namespce fire&#123; int flame; &#125; using Jill::fetch; using namepace Jack; float water;&#125;using namespace elements;using namespace elements::fire;//访问Jill::fetch，由于在elements中声明了Jill::fetch，所以以下两种名称空间都可用Jill::fetch;elements::fetch;using namespace elements;//这条编译指令与下面两条编译指令等价using namespace elements;using namespace Jack;namespace ele = elements; //给elements创建别名 名称空间示例名称空间及其用途 指导原则：p334 使用在已命名的名称空间中声明的变量，而不是使用外部全局变量。 使用在已命名的名称空间中声明的变量，而不是使用静态全局变量。 如果开发了一个函数库或类库，将其放在一个名称空间中。 仅将编译指令using作为一种将旧代码转换为使用名称空间的权益之计。 不要在头文件中使用using编译指令。首先，这样做掩盖了要让哪些名称可用，另外，包含头文件的顺序可能影响程序的行为。 导入名称时，首选使用作用域解析运算符或using声明的办法。 对于using声明，首选将其作用域设置为局部而不是全局。 第十章 对象和类过程性编程和面向对象编程 面向对象变成（OOP），首先从用户的角度考虑对象——描述对象所需的数据以及描述用户与数据交互所需的操作。p341 抽象和类类型是什么 指定基本类型完成了三项工作：p342 决定数据对象需要的内存数量 决定如何解释内存中的位（long与float位数相同，但含义不同） 决定可使用数据对象执行的操作或方法 10.2.2 C++中的类 类规范由两个部分组成：p342 类声明：以数据成员的方式描述数据部分，以成员函数（方法）的方式描述公有接口——提供了类的蓝图。 类方法定义：描述如何实现类成员函数——提供了类的实现细节。 类对象成员访问类型默认为私有private。结构体成员访问类型默认为公有public。p345 类和结构的区别： 实际上，在C++中，对结构进行了扩展，使之具有与类相同的特性。它们之间唯一的区别是，结构的默认访问类型是public，而类的默认访问类型是private。C++程序员通常使用类来实现类描述，而把结构限制为只表示纯碎的数据对象。（看上去类可以完美替代结构体，事实上也是这样，C++保留结构体的主要原因是为了向C兼容）。 实现类成员函数 定义成员函数时，使用作用域解析符（::）来标识函数所属的类。类方法可以直接访问类的组件（private和public均可，并且无需使用作用域解析符）。 p345 1234//无需使用public，因为在声明函数原型时已经指明了访问类型void Stock::update(double price)&#123; ...&#125; 内联方法： 方法定义位于类声明处的函数都将自动成为内联函数。类声明常常将短小的成员函数作为内联函数。内联函数的特殊规则要求在每个使用它们的文件中都对其进行定义，因此通常将内联定义放在定义类的头文件中。p347 12345678class Stock&#123; private: int shares; double share_val; void set_tot() &#123;total_val = shares*share_val;&#125; //自动成为内联函数 public: ...&#125; 类的每个新对象都有自己的存储空间，用于存储其内部变量和类成员。但是同一个类的所有对象共享同一组类方法，即每种方法只有一个副本。p348 使用类 要创建类对象，可以像基本类型一样声明类对象Stock kate，joe; //声明了2个对象kate和joe，也可以使用new为类对象分配存储空间。p349 修改实现 利用setf()控制输出格式，并将修改限定在实现文件中，以免影响程序的其他方面。p351 类的构造函数和析构函数声明和定义构造函数 构造函数没有返回类型。并且，构造函数的形参名称不能与类成员变量的形参名称完全相同，一种常见做法是在数据成员中使用m_前缀，或者用this指针this-&gt;company = company。p3531234567891011class Stock&#123; private: string m_company; ... public: Stock(const string &amp;company);更&#125;Stock::Stock(const string &amp;company)&#123; m_company = company;&#125; 使用构造函数 C++提供了两种使用构造函数来初始化对象的方式。p35412Stock garment = Stock(&quot;Furry&quot;); //显示调用构造函数Stock garment(&quot;Furry&quot;); //隐式调用构造函数，二者等价 默认构造函数 当且进党没有定义任何构造函数时，编译器会提供一个默认构造函数，它不接受任何参数，也不做任何操作。它可以使得下述语句正常运行：p354 1Stock cat; //隐式地调用了默认构造函数 如果为类定义了构造函数，程序员就必须为它显式提供默认构造函数，除非不使用无参数的对象声明Stock cat;，否则会报错。定义默认构造函数的方式有两种：p354 12Stock(const string &amp; company = &quot;default_company&quot;); //为所有参数提供默认值Stock(); //函数重载定义无参数的构造函数 隐式地调用默认构造函数时，不要使用圆括号：p355 1234Stock first(&quot;Furry&quot;); //隐式调用非默认构造函数Stock second(); //这是一条声明语句，指出second()是一个返回Stock对象的函数Stock third; //隐式调用默认构造参数Stock third = Stock(); //显式调用默认构造参数 接受一个参数的构造函数（或者其它的参数提供了默认值）允许使用赋值语法将对象初始化为一个值。p362 1Classname object = value; 带参数的构造函数也可以是默认的构造函数，只要所有参数都有默认值。但是只能有一个默认构造参数，也就是说，一旦所有参数都提供了默认值，就不能再声明无参数的构造函数，否则会产生二义性错误。 p433 析构函数 如果程序员没有提供析构函数，编译器将隐式的声明一个析构函数，析构函数没有返回类型，也没有参数，在声明时，需要在类型前加上波浪号：p355 1234567class Stock&#123; public: ~Stock(); //声明 &#125;Stock::~Stock()&#123; //定义&#125; 编译器调用析构函数的时机：p356 静态存储类对象：在程序结束时自动被调用 自动存储类对象：在程序执行完代码块时自动被调用 new创建的对象：当使用delete来释放对象内存时自动被调用 构造函数的另一种用法——赋值。语句1为初始化语句，语句2为赋值语句，构造函数会创建一个 临时 的对象，然后将该对象的值赋给已经存在的对象stock1，之后编译器会自动调用析构函数 删除该临时对象 。p361 123Stock stock1 = Stock(&quot;test1&quot;);stock1 = Stock(&quot;test2&quot;);//如果既可以通过初始化，也可以通过赋值来设置对象的值，则应采用初始化方式，通常这种方式的效率更高。 可以使用C++11的列表初始化方式来作用于类，前提是提供了相应的构造函数。p361 12Stock hot_tip = &#123;&quot;Plus&quot; ,100, 45.0&#125;;Stock jock&#123;&quot;Sport&quot;&#125;; 以上两个声明中，用大括号括起的列表与下面的构造函数匹配：1Stock::Stock(const std::string&amp; co, long n =0, double pr = 0.0); 另外，C++11还提供了名为std::initialize_list的类，可将其用作函数参数或方法参数的类型。这个类可表示任意长度的列表，只要所有的列表项的类型都相同或可转换为相同的类型。（在16章介绍）。 C++的成员函数如果不修改调用对象，则应将其声明为const，将const关键字放在函数的括号后面。（放在前面就变成了返回类型为const double了）p36212345678class Stock&#123; public: double show() const; //const成员函数声明&#125;double Stock::show() const&#123; //const成员函数定义&#125; this指针 this指针指向用来调用成员函数的对象（this被作为隐藏参数传递给方法）。一定要注意this是一个指向对象的指针，所以在使用时要按照指针的方式。p36412this-&gt;shares; //用间接成员运算符-&gt;引用对象的成员return *this; //返回this指向的对象 对象数组 利用对象数组可以创建同一个类的多个对象。p368 123456Stock mystuff[4]; //调用默认构造函数Stock stocks[4]=&#123; //为每个元素调用指定的构造函数 Stock(&quot;NanoSmar&quot;); Stock(); //显示调用默认构造函数 //stocks[2]和stock[3]未指明构造函数，将调用默认构成函数&#125; 初始化对象数组的方案是，首先使用默认构造函数创建数组元素，然后花括号中的构造函数将创建临时对象，然后将临时对象的内容复制到相应的元素中。因此，要创建类对象数组，则这个类必须有默认构造函数。p369 类作用域 C++类引入了一种新的作用域：类作用域。在类中定义的名称（如类数据成员名和类成员函数名）的作用域都为整个类，作用域为整个类的名称只在该类中是已知的，在类外是不可知的。要调用公有成员函数，必须通过对象访问。同样，在定义成员函数时，必须使用作用域解析符。 作用域为类的常量 直接在类中声明const常量是非法的，因为声明类只是描述了对象的形式，并没有创建对象。因此，在创建对象前，将没有用于储存值的空间。p371 实现“类的常量”的两种方式： 方式1：使用枚举，在类中声明一个枚举，用枚举为 整型常量 提供作用域为整个类的符号名称。 方式2：使用static，这将创建一个常量，该常量将于其他静态变量存储在一起，而不是存储在对象中。该常量被所有的类对象共享。123456class Bakery&#123; private: const int Months = 12; //非法，无法编译 enum &#123;Months = 12&#125;; //未提供枚举名，这种方式声明枚举并不会创建类数据成员，Months只是一个符号名称，在编译时，将用12来替换它。 static const int Months = 12; //C++98中，不能存储double常量，C++11消除了这种限制&#125; 作用域内枚举 传统的枚举如果两个枚举定义中的枚举量名称相同，则会发生冲突，C++利用类作用域的方法消除了这种冲突。p372 123456789//传统枚举量，产生冲突enum egg &#123;Small, Medium, Large, Jumbo&#125;;enum t_shirt &#123;Small, Medium, Large, Xlarge&#125;;//类作用域，不冲突。 也可以利用关键字struct代替class。enum class egg &#123;Small, Medium, Large, Jumbo&#125;;enum class t_shirt &#123;Small, Medium, Large, Xlarge&#125;;//使用时用枚举名和作用域解析符来限定枚举量：egg choice = egg::Large;t_shirt t_choice = t_shirt::Large; C++11还提高了作用域内枚举的类型安全，在有些情况下，常规枚举将自动转换为整型，如将其赋给int变量或用于比较表达式时，但作用域内枚举不能隐式地转换为整型。p372 枚举有某种底层整型类型表示，在C++98中，如何选择取决于实现，因此包含枚举的结构的长度可能随系统而异。对于作用域内枚举，C++11消除了这种依赖性。默认情况下，C++11作用域内枚举的底层类型为int。而常规枚举的底层类型依然随实现而异。另外，C++11提供了指定底层类型的语法。p3721enum class :short pizza &#123;Small,Medium,Large,XLarge&#125;; //:short将底层类型指定为short 抽象数据类型 类很适合描述ADT。公有成员函数接口提供了ADT描述的服务，类的私有部分和类方法的代码提供了实现，这些实现对类的客户隐藏。p373 第十一章 使用类运算符重载 要重载运算符，需使用被成为运算符函数的特殊函数形式。op必须是有效的C++运算符，不能虚构一个新的符号。p381123456789101112operatorop(argument-list)&#123;&#125;Stock::operator+(...)&#123;&#125;Stock::operator*(...)&#123;&#125;//当编译器发现了运算符的操作数是对应的对象是，会自动替换运算符为重载函数stock3 = stock1 + stock2; //左侧的操作数为调用对象，右侧为重载函数的参数stock3 = stock1.operator+(stock2); //用operaotr+重载函数替换“+” 计算时间：一个运算符重载示例添加加法运算符 对于连加或连乘，需要函数返回的是正确的对象类型。p38712t4 = t1 + t2 + t3;t4 = t1.operator+(t2.opertor+(t3)); //当operator+返回的函数类型复合其参数列表要求时，合法。 重载限制 重载的运算符不必是成员函数，但必须至少有一个操作数是用户定义的类型，这是为了防止用户为标准类型重载运算符。p387 使用运算符时不能违反运算符原来的语法规则，如双目不能重载成单目，同时，重载不会修改运算符的优先级。p387 不能创建新的运算符。p387 不能重载下面的运算符： p387 “sizeof”运算符 “.”成员运算符 “.* ”成员指针运算符 “::” 作用域解析运算符 “? :” 三目条件运算符 “typeid” 一个RTTI运算符 “const_cast” 强制类型转换运算符 “dynamic_cast” 强制类型转换运算符 “reinterpret_cast” 强制类型转换运算符。 “static_cast” 强制类型转换运算符 大多数运算符都可以通过成员或非成员函数进行重载，但下面 的运算符只能通过成员函数进行重载： p387 “=” 赋值运算符 “()” 函数调用运算符 “[]” 下标运算符 “-&gt;” 通过指针访问类成员的运算符 友元 除了private，public和protect控制的类访问权限外，C++提供了另外一种形式的方式权限：友元。通过让函数成为类的友元，可以赋予该函数与类的成员函数相同的访问权限。友元有3种： p391 友元函数 友元类 友元成员函数 创建友元 创建友元的第一步是将其原型 放在类声明中 ，并在原型声明前加上关键字friend：p391 123friend Time operator*(double m, const Time &amp; t);//可以解决2.85*time的乘法重载的问题，2.85不是Time对象，因此无法调用成员重载函数，需要借助友元非成员函数实现。//该声明意味着：1、虽然该函数是在类声明中声明的，但它不是成员函数，因此不能使用成员运算符来调用; 2、虽然该函数不是成员函数，但它与成员函数的访问权限相同。 编写友元函数的定义。因为它不是成员函数，所以无需使用类名::限定符，另外，定义时不要在函数头使用关键字friend。p392 常用的友元：重载&lt;&lt;运算符 cout是一个ostream对象，对于每种基本类型ostream类声明中都包含了相应的重载的operator&lt;&lt;()定义。因此，对于不同的基本类型，&lt;&lt;运算符在cout对象中可以表现出不同行为。p392 &lt;&lt;的第一种重载版本 如果直接通过类声明来重载operator&lt;&lt;()函数，那么在使用时就会像这样，time&lt;&lt;cout;，其中，time是Time类的实例，而cout是Time类重载函数的参数，为了看起来不那么迷惑，利用友元函数，使其第一个参数为ostream对象，这样一来，就可以使用cout&lt;&lt;time的形式（运算符左侧操作数是第一个参数）。p393 123456void operator&lt;&lt;(ostream &amp;os, const Time &amp;t)&#123; os&lt;&lt;t.hours&lt;&lt;t.minutes; //os是cout的引用，别名，省去了拷贝副本的时间&#125;cout&lt;&lt;time1; //等价于下式operator&lt;&lt;(cout,time1); &lt;&lt;的第二种重载版本 上面的重载方法有一些问题，那就是无法使用cout&lt;&lt;time1&lt;&lt;time2&lt;&lt;endl;这样的形式，解决方法如下：p394 1234ostream &amp; operator&lt;&lt;(ostream &amp; os, const Time &amp; t)&#123; os&lt;&lt;t.hours&lt;&lt;t.minutes; return os; //返回os的引用，以便实现连续使用&lt;&lt;的操作。&#125; 重载运算符：作为成员函数还是非成员函数 成员函数和非成员函数的实现方法二者均可，但不能都实现，否则会产生二义性错误。p398 再谈重载：一个矢量类 一个应用了运算符重载和友元设计的例子——矢量类。p398 类的自动转换和强制类型转换 只有一个参数的构造函数可以作为转换函数。如果使用关键字explicit限定了这种构造函数，则它只能用于显示转换，否则也可以用于隐式转换。p413 转换函数 转进行从对象到基本类型的转换，必须使用特殊的C++运算符——转换函数operator typeName()。创建转换函数时，需要注意以下几点：p415 转换函数必须是类方法 转换函数不能指定返回类型 转换函数不能有参数12345678operator double() const; //转换为double类型的函数原型。Stonewt::operator double() const&#123; // 转换函数的定义 return pounds;&#125;double d = stonewt; //隐式调用转换函数double d = double(stonewt); //显式调用转换函数 在进行类型转换时，一定要注意是否有二义性，如果有，编译器将产生错误。p418 提供执行自动、隐式的转换函数存在的问题是，在用户不希望进行转换时，转换函数也可能进行转换。消除这种隐患的方式是在转换函数原型前加上关键字explicit。（C++98不能将explicit用于转换函数，C++11可以）。另一种方法是使用功能相同的非转换函数，在进行转换时显式调用该函数即可。p419 总之，C++为类提供了下面的类型转换：p419 只有一个参数的类构造函数用于将类型与该参数相同的值转换为类类型。在构造函数声明中使用explicit可防止隐式转换。 被称为转换函数的特殊类成员运算符函数，用于将类对象转换为其他类型。没有返回类型、没有参数，名为operator typeName()。 将加法等二元运算符定义为友元可以让程序更容易适应自动类型转换。因为这会可以自动将对象类型转换成基本类型，或者将基本类型转换为对象类型进行运算。p420 将double变量与对象相加，由两种选择。一种是借助类型转换，另一种是在重载函数中显式接受double参数而不进行类型转换。 前者定义简单，但需要类型转换，增加了内存和时间开销。后面定义麻烦，需要写更多逻辑，但运行速度快。p421]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-Ubuntu个人必装软件]]></title>
    <url>%2Fz_post%2FLinux-Ubuntu%E4%B8%AA%E4%BA%BA%E5%BF%85%E8%A3%85%E8%BD%AF%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[vimoh-my-zshChromeAtomGuake TerminalEverNoteFoxit ReaderTeamViewerSogouinputVMware WorkstationGpartedVCL]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《C++ PrimerPlus》 第一章～第八章]]></title>
    <url>%2Fz_post%2FCpp-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-CppPrimerPlusChapter1_8%2F</url>
    <content type="text"><![CDATA[第一章 预备知识C++简介 C++融合了三种不同的变成方式：1、C语言代表的过程性语言 2、带有类的面向对象语言 3、C++模板支持的泛型编程 C++简史20世纪70年代早期，贝尔实验室的Dennis Ritchie开发了C语言。 20世纪80年代，贝尔实验室的Bjarne Stroustrup开发了C++语言。 可移植性和标准C++98 C++11 程序创建的技巧编译和链接 第二章 开始学习C++进入C++输入输出：C++能在使用printf()、scanf()和其他所有标准的C输入输出函数，只需要包含常规的C语言的stdio.h文件即可 main函数： main函数是被操作系统调用的，他是程序与操作系统之间的接口。p14 int main( void ) 在括号中用void明确指出，函数不接受任何参数，在CPP中，让括号空着与使用void完全等效。但是在C中，让括号空着意味着对于是否接受参数保持沉默。p15 许多程序员喜欢使用下面的函数头，并省略返回语句：void main()。这在逻辑上是可以理解的，大部分系统也适用，但由于它不是当前标准的内容，因此在有些系统上不能工作。新的标准中对这一点作出了让步，如果编译器到达main()函数末尾时没有遇到返回语句，则自动添加return 0语句 （只对main函数有效，对其他函数不会隐含return 0）。p15 （疑问：在测试的时候报错说main函数必须是int返回类型？同时，非main函数也可以不写明return语句，但是返回的值是6295680？？） 有一些非标准函数，他们使用_tmain() 形式，这种情况下，有一个隐藏的main（）调用它，但是常规的独立程序都需要main()。p15 头文件名，名称空间： 新标准的CPP不适用头文件的.h扩展名，而利用命名空间机制。 新的cout，cin为了避免产生函数名冲突，需要使用std::cout，std::cin来使用 如果使用using namespace std； 则表示std名称空间中的所要名称都可用，但这是一个隐患，推荐使用using std::cout的方式（为了方便，大多会使用using namespace std） p33：using namespace std可以放在main中，表示只有main可以访问其命名空间，也可以放在iostream下面，表示文件中的所有函数都能访问 使用cout进行输出： cout是一个预定义的对象，是某个类的特定实例，&lt;&lt;符号表示它将后面的字符串发送给cout：cout&lt;&lt;string 从概念上看，输出是一个流，即从程序流出的一系列字符。cout对象表示这种流，其属性定义在iostream文件中，&lt;&lt;是cout对象的一个属性，它表示将其右侧的信息插入到流中，该符号与按位左移运算符实际上是重载关系 打印的时候，cout会将整数形式的数字自动转换成字符串形式，注意整数25与字符串25有天壤之别 endl确保程序继续运行前刷新输出？控制符：诸如endl等对于cout来说有特殊含义的符号（manipulator）传统Cpp不能把回车放在字符串中间，但是C++11新增的原始字符串可以包含回车 C++语句其他C++语句 cin.get（） 一般需要两条，一条用于接受多余的换行，有一条用于让程序暂停。cin使用&gt;&gt;运算符才输入流中抽取字符。p24 函数 C++函数和C一样，不允许嵌套定义。p30 main不是关键字，因为它不是语言的组成部分，可以做关键字，但最好别这样，会引起其他错误。cout也不是关键字，而是一个对象名，所以可以在不适用cout的程序中，将cout用作变量名。p31 第三章 处理数据简单变量变量名，符号类型： CPP命名规则：以两个下划线或下划线和大写字母打头的名称被保留给实现（编译器及其使用的资源）。p38 CPP的字节位数根据字符集的大小而定，对于基本字符集ASCII和EBCDIC来说，一字节为8为，而对于国际编程Unicode来说，一字节可能为16为或32位，int在老式机器中一般为16位，而在现在多为32位。p39 预编译指令#define是c遗留下来的，cpp中多用const关键字p42。 cpp中有一种c没有的初始化赋值语法：int a（42）。C++11具有新的初始化方式。p42 常数后缀，ul，lu，uL，LU等等都可以，均表示unsigned long常量。在cpp中，对十进制整数采用的长度规则，与16进制和8进制略有不同。p47 通用字符名，以/u开头 Unicode与ISO 10646。p52 char默认情况下既不是无符号，也不是有符号。 wcha_t 与 underlying（底层类型） cin和cout将输入和输出看做是char流，因此不适合用来处理wchar_t类型，以l或L为前缀应用wcin和wcout。cpp11新增的char16_t char32_t分别以u和U为前缀。p53 const限定符 p54：const比#define更好，1.它可以明确指定类型，2.cpp的作用于规则将定义限制在特定的函数或头文件中，3.const可用于复杂类型，如数组和结构体 浮点数C++算术运算符 求模运算符只能用于整形。p59 对于float类型，11.17+50.25=61.419998 具体愿意是float的精度限制所导致的（将操作数转化成二进制即可理解）。p60 数值类型转换，对于精度丢失的情况，最终结果会根据系统的不同而不同。p63 c++11中的{}初始化赋值法不允许narrowing缩窄，即只能小赋给大，不能大赋给小（但是const可以，只要能hold住要赋的值即可）。p64整型提升：c++在计算表达式时自动将bool char unsigned char signed char short转换为int。如果shot比int短，则unsigned short类型将被转化为int，如果长度相同，则unsigned short将被转化为unsigned int，以此确保在对unsigned short进行提升时不会损失数据。wchar_t被提升为下列类型中第一个宽度足够的类型：int，unsigned int，long，unsigned long。更多转化规则可以查看校验表p64 强制类型转化通用格式：（typeName）value；typeName（value）第一种格式来自C语法，第二种是纯粹C++语法。p65 c++11中新增了auto类型声明的用法，让编译器根据初始值的类型推断变量的类型。主要用于复杂类型。p66 第四章 复合类型数组 c++中数组的arraySize只能是常量，const，或常量表达式，不能是变量。p71 字符串 c++11初始化数组时，可以省略等号。c++标准模板库（STL）提供了一种数组替代品模板类vector，c++11新增了模板类array。p74 ‘s’表示83 “s”表示的是某块内存的地址。 cout会默认自动拼接两段字符串，并且可以不在同一行。p75 c++使用空白（空格，制表，换行）来确定字符串的结束位置。为了读取空白可以采用cin的成员函数面向行的输入：cin.getline（）和cin.get（）。二者以换行为结束，前者会舍弃换行符，后者会将其保留在输入队列中（注意是输入队列，这相当于输入缓冲区，下面读取函数有可能会读到这个换行符）。二者的返回值为cin对象，可以继续调用函数。getline（）使用起来更简单方便，但get（）更能检查出错误。另外要注意二者读取空行时的区别。p78 string类 string对象和字符数组之间的主要区别是string对象可以声明为简单变量，类设计让程序能够自动处理string的大小。p83 原始字符串 raw。p87 结构 p89：C++允许在声明结构变量时省略关键字struct。但是C不允许 p92：c++的结构特性比C更多。 位字段，共用体（长度为其最大成员长度） 共用体枚举 对于枚举变量，只有赋值运算符，枚举创建的是符号常量，可以代替const。枚举量的值可以重复。p96 指针：*运算符称为间接值（indirect value）或解除引用（dereferencing）。p101：不管是指向何种类型的指针，其指针变量本身的长度是一定的。p9917.10.19 指针和自由存储空间 C++利用new关键字代替了malloc（）来分配内存：int* p=new int; 用指针和new进行的内存分配是在程序运行时进行的（只有运行时，指针才知道它指向的是哪一块地址）。p102 delete关键字只能释放new的内存，不能用于一般变量，同时，不可以重复释放，否则结果未知。 不能用sizeof运算符确定动态数组包含的字节数。p104 指针、数组和指针算术 指向数组的指针和数组名基本等价，区别是：1，指针值可以变，而数组名的值不能变。2，sizeof用在数组名上返回数组长度，用在指针上放回指针的长度。注意short tell[10]; 中tell与&amp;tell的关系。p109 cout打印字符数组的关键不在于变量是一个数组名，而在于它是一个char的地址！在cout和多数c++表达式中，char数组名，char指针和双引号下的字符串常量都被解释为字符串第一个字符的地址。p109 第五章 循环和关系表达式for循环while循环do while循环基于范围的for循环（C++11) c++11新增了一种基于范围的for循环，它简化了一种常见的循环任务：对数组或容器类的循环for（int x：arr）和for（int &amp;x：arr），前者不可以改变x的值，后者可以。5.5节详解cin.get（）函数。p152 循环和文本输入 cin在获取用户输入的字符时，将忽略空格和换行符，并且，发送给cin的输入会被缓冲，只有在用户按下回车键后，他输入的内容才会被发送给程序，为了读取空格和换行符，可以利用cin.get（char）进行补救，char的函数声明是引用，所以，可以改变char的值。p154 第六章 分支语句和逻辑运算符if语句逻辑表达式字符函数库cctype?:运算符switch语句 p181 ：c++的switch语句中必须是整数表达式，一般为int或char或枚举 break和continue语句读取数字的循环简单文件输入/输出 打开已经存在的文件，接受输出时，默认将它的长度截断为零，文件原来的内容会丢失。p194 函数exit（）的原型是在头文件cstdlib中定义的，在该头文件中，还定义了一个用于操作系统通信的参数值EXIT_FAILURE。p195 windows系统中的文本文件每行都已回车字符和换行符两个字符结尾，在通常情况下，C++在读取文件时将这两个字符转换为换行符，并在写入文件时执行相反的转换。有些文本编辑器不会自动在文件的最后一行加上换行符，因此，需要手动按下回车键再保存文件。p196 第七章 函数——C++的编程模块复习函数的基本知识 在C++中不能将数组作为函数返回值 （但是可以将数组作为结构或这对象的组成部分返回）。p204 函数定义必须提供标识符，而函数原型不要求，有类型列表就足够了：void cheers（int），通常，在原型的参数列表中，可以包括变量名，也可以不包括。原型中的变量名相当于占位符，因此不必与函数定义中的变量名相同。但是，好的变量名可以帮助理解程序功能，所以一般建议加上。p206 C++与接受可变参数的C函数交互时可能用到：void say（…）的形式。p206 通常，函数原型会自动将被传递的参数强制转换为期望的类型。（但函数重载可以导致二义性，因此不允许某些自动强制类型转换） 函数参数和按值传递 C++通常按值传递参数，这会让函数在自身的作用域内保持实参的副本，这种方式在一定程度上可以确保数据的完整性和安全性。 函数和数组 在C++中，当且仅当用于函数头或函数原型中，int *arr和int arr[]的含义才是相同的。在其他的环境下，二者的含义并不同，前者代表指向int类型的指针，后者代表数组名。p213 以下程序说明了数组函数一些有趣的地方，首先，cookies和arr指向同一个地址，但sizeof cookies的值是32，而sizeof arr的值是4。sizeof cookies是整个数组的长度，sizeof arr只是指针变量的长度。这也是必须显示传递数组长度，而不能在函数中使用sizeof arr的原因，因为指针本身并没有指出数组的长度。p215 12int cookies[size]=&#123;1,2,3,4,5,6,7,8&#125;;int *arr = cookies 由为防止函数中无意中修改数组的内容，可以在声明形参的时候使用关键字const，但应注意，这并不是意味着原始数组必须是常量而只意味着不能在函数中修改数组中的值。（对于普通变量来说，由于C++默认按值传递的特性，这种保护会自动实现）p217 使用数组区间（range）的函数 ：对于处理数组的函数，必须将数组的数据种类、起始位置和元素个数传递给它，传统的方法是传递数组名和数组个数n。另一种方法是传递两个指针，分别标识数组的开头和结尾，即数组区间。STL方法使用“超尾”的概念来指定区间，即end指针的是最后一个元素后面的指针。p220 指针和const： 情况1，pt指向一个const int，因此不能使用pt来修改这个值，但是这并不意味着age是一个常量，而只是说对于pt来说这是一个常量，我们依然可以直接通过age来修改age的值，但不能通过pt来修改它。同时，我们可以修改pt的值，即pt可以重新指向另一个地址。 情况2，finger只能指向age，但是允许使用finger来修改age。简而言之，finger和ps都是const，而*finger和ps不是。 情况3，stick只能指向age，并且不能通过stick修改age的值。p2211234int age=30；const int *pt=&amp;age；int *const finger=&amp;age;const int * const stick=&amp;age； 函数和二维数组 数组作参数的函数，必须牢记，数组名被视为地址，因此，相应的形参是一个指针，正确的函数原型如下所示，二者含义完全相同，后者可读性更强。注意，前者的括号是必不可少的，式子3代表的是指针数组，而不是指向二维数组的指针。123int sum (int (*arr)[4])int sum (int arr[][4])int *arr[4] 函数和C-风格字符串 C-风格字符串与常规char数组之间的区别：字符串有内置的结束字符’\0’。p225 空字符’\0’值等于0，因此可以直接用于while（）里的循环判定。p227 函数无法返回一个字符串，但是可以返回字符串的地址。p227 函数和结构 在涉及到函数时，结构变量的行为更接近与基本的单值变量，默认情况下是按值传递的，函数将使用原始结构的副本。当结构非常大时，这会增加内存要求，因此更推荐使用指针来传递结构体。指针传递时使用间接成员运算符’-&gt;’访问，值传递时使用成员运算符’.’访问。p228 当程序在输入循环以后还需要进行输入时，可以使用 cin.clear() 重置输入。p233 函数和string对象 虽然C-风格字符串和string对象的用途几乎相同，但与char数组相比，string对象更像是一个单一变量，可以将string直接复制，也可以直接在函数中传递。 函数和array对象 在C++中，类对象是基于结构的，因此结构变成方面的考虑因素也适用于类，所以可以按值将对象传递给函数。p236 array模板并非只能存储基本类型数据，它还可以存储类对象。p237 递归 C++函数允许自己调用自己（然而，与C语言不同，C++不允许main()调用自己） 函数指针 与数据项类似，函数也有地址，函数名即为函数的地址，它是存储其机器语言代码的内存的开始地址。p241 使用场景：要在当前函数中使用不同的算法来实现灵活的功能，可以将算法的函数地址作为参数进行传递，这就是函数指针。p241 注意以下代码的区别。p242 123int think ();process(think); //传递了函数的地址，process函数能够在其内部调用think函数thought(think()); //传递了函数的返回值 声明函数指针，最简单的方法就是，先写出该函数的原型，然后用(*pf)替换函数名即可，如下所示,pf即为函数指针。注意，括号的优先级比星号高，所以这里括号不可少。p242 1234double pam(int,double);double (*pf)(int,double); //pf是一个指针，指向doubel （int，double）类型的函数double *pf(int,double); //pf是一个函数，返回double *类型的数据pf = pam; //正确声明函数指针后，便可以将相应的函数赋给它 在使用函数指针时，下面两种方法等价！这很神奇！前者的好处是强调当前正在使用函数指针，后者的好处是使用起来很方便。至于为什么会这样，主要是因为有两种流派的声音，C++对这两种流派进行了折衷，认为二者都正确。p243 12345678double pam(int);double (*pf)(int);pf = pam;double y;y = pam(5);//下面两种方法等价y = (*pf)(5);y = pf(5); C++11的自动类型推断功能在函数指针声明并初始化时十分方便，以下两种声明初始化方式等价。p245 123const double *f1(const double ar[], int n);const bouble *(*pf)(const double ar[], int n) = f1;auto pf = f1; 函数指针数组,[]的优先级高级星号，所以先指明了这是一个包含3个元素的数组，声明的其他部分指出了元素的类型。所以pa是一个包含三个指针的数组，每个指针都指向一个函数，该函数返回指向double类型的指针。p245 1234567const double *(*pa[3])(const double *,int) = &#123;f1,f2,f3&#125;;auto pb = &#123;f1,f2,f3&#125; //非法！ auto只能用于单值初始化，不能用于初始化列表。auto pb=pa //但可以利用声明好的pa数组，来声明同样类型的数组。//使用时，想使用数组一样即可const double *px = pa[0](av,3);const double *py = (*pb[0])(av,3); //前面的括号必不可少 下面的声明，表示pd首先是一个指针，它指向一个包含三个元素的数组，数组中的元素是函数指针。这里pd其实就是指向pa的地址，pa是上面声明的函数指针数组的名字，也就是函数指针数组的首地址。p245 123456const double* (*(*pd)[3])(const double*,int) = &amp;pa;//调用方法，用``(*pd)``代替``pa``即可(*pd)[i](av,3); //返回指针(*(*pd)[i])(av,3); //与上面等价， 返回指针*(*pd)[i](av,3); //注意如果不带括号，先返回指针，然和用星号得到指针指向的值*(*(*pd)[i])(av,3) //与上一条等价，先返回指针，然和用星号得到指针指向的值 函数指针的声明有时候会很长，此时可使用auto（C++11）或typedef来对代码进行简化，方便编程。p248 12345678910//下面两条语句等价，前者使用方便，缺点就是无法直观看出pc的类型，后续程序可能会不小心产生类型赋值错误auto pc = &amp;pa;const double* (*(*pd)[3])(const double*,int) = &amp;pa;// 可以用typedef简化声明typedef double real; //正常声明变量，前面加上typedef，即可用后者代替前者typedef const double* (*p_fun)(const double*, int);p_fun pa[3] = &#123;f1,f2,f3&#125;;p_fun (*pa)[3] = &amp;pa; 第八章 函数探幽C++内联函数 常规函数与内敛函数之间的主要区别在于C++编译器如何将它们组合到程序中。 传统函数在被调用后，会立即存储该指令的内存地址，并将函数参数复制到堆栈，跳到函数起点的内存单元，然后执行函数的机器代码，之后再跳回到地址被保存的指令处。 来回跳跃并记录跳跃位置需要一定的开销。p253 内联函数的编译代码与其他程序的代码“内联”起来了，即编译器会使用相应的函数代码来替换函数调用（这就省去了来回跳跃的时间开销和内存开销）。 内联函数无需跳跃时间，因此加快了运行速度，但同时增加了存储内联函数的内存开销，如果程序在10个不同的地方调用同一个内联函数，就需要存储10个副本。 当函数的代码执行时间很短（函数很小），则内联调用可以省去调用时间。但是由于这个过程相当快，因此尽管接伸了该调用过程的大部分时间，但节省的时间绝对值并不大，除非该函数被经常调用。p253 使用内联时，在函数声明或定义前加上关键字inline。通常的做法是省略原型，将整个定义放在原型处，并加上内联关键字。p254 1inline double square(double x) &#123; return x*x&#125; inline工具是C++新增的特性，原始的C语言使用#define来实现内联（文本替换）p255 引用变量 引用变量，是 已定义的变量的别名 ，他的主要作用是用作函数的形参，如此一来，函数将使用原始数据，而不是其副本。 &amp;符号在变量前（右值）是代表“取地址”，在类型附近时（左值）代表“引用” 引用和指针的区别（引用看上去很像伪装的指针 “&amp;rodents=prats”）： 123int rats = 101;int &amp; rodents = rats; //rodents是rats的别名，二者指向同一块内存地址int * prats = &amp;rats; //prats指向rats的内存地址 引用在声明的同时必须进行初始化（做函数参数时，在函数调用时使用实参初始化），而不能像指针那样，先声明，在赋值 。引用更接近const指针，必须在创建时进行初始化，一旦与某个变量关联起来，就将一直效忠于它。p256123456789int rats = 101;int &amp; rodents = rats;int * const pr = &amp;rats; //上式是该式的伪装表示int bunnies = 50;rodents = bunnies; //试图将rodents变成bunnies的别名cout&lt;&lt;rodents&lt;&lt;endl; //输出50,和rodents值一样count&lt;&lt;rats&lt;&lt;endl; //但同时rats的值也变成了50cout&lt;&lt;&amp;rodents&lt;&lt;endl;cout&lt;&lt;&amp;bunnies&lt;&lt;endl; //二者的内存地址并不相同 const double &amp;ra用作函数参数时，在函数内不能修改ra的值（会报错），这在行为上与按值传递类似，但是当ra内存占用比较大时（结构或对象），就会很省内存（按值传递会生成副本，内存消耗大）。p261 对于基本类型，使用按值传递兼容性更好，因为按值传递可以自动强制类型转换，而const引用的限制更严格，因为它是别名，所以不能将表达式赋给引用。p261 12//现代C++中会报错，但早期C++只会警告，会创建一个临时变量，并将其初始化为x+3.0的值double &amp; ra = x + 1.0; 临时变量、引用参数和const： 当前，如果实参与引用参数不匹配，仅当引用参数为const引用时，C++将生成临时变量。创建临时变量的两种情况：p262 实参的类型正确，但不是左值。（字面常量，表达式） 实参的类型不正确，但可以转换为正确的类型。（int转double） 左值：左值参数是可以被引用的数据对象，例如，变量、数组元素、结构成员、引用和接触引用的指针都是左值。 非左值：字面常量（用引号扩起的字符串除外，它们由其地址表示）和包含多项的表达式。 （C语言中，左值最初指的是可出现在赋值语句左边的实体，引入const关键字后，const变量，虽然一般不出现在左边，但是可以通过地址访问它们） 非const引用无法生成临时变量，这是因为如果接受引用参数的函数的意图是修改作为参数传递的变量，临时变量将无法实现修改，所以现在的C++标准禁止创建临时变量（老的编译器只会发出警告”Warning: Temporary used for parameter ‘ra’ in call to refcube(double &amp;)”，遇到这种警告，一定要排除）。p263 将引用参数声明为const引用的理由有三个： p263 使用const可以避免无意中修改数据的变成错误; 使用const使函数能够处理cnost和非const实参，否则只能接受非const数据; 使用const引用能使函数能够正确生成并使用临时变量。 C++11新增了另一种引用—— 右值引用（rvalue reference） 。这种引用可指向右值，是使用&amp;&amp;声明的。新增右值引用的主要目的是，让库设计人员能够提供有些操作的更有效实现，实例见18章。&amp;声明的叫左值引用。：p263 123double &amp;&amp; rref = std::sqrt(36.00); // not allowed for double &amp;double j = 15.0;double &amp;&amp; jref = 2.0*j + 15.6; //not allowed for double &amp; 返回引用与传统返回机制的区别： 传统返回机制是按值传递函数参数类似，计算关键字return后面的表达式，并将结果返回给调用参数。而返回引用是返回return后面的变量的别名，并不会生成新的副本。p267 返回引用需要注意的问题： 最重要的是要避免返回函数终止时不再存在的内存单元的引用。（同样，也应避免返回指向临时变量的指针）。如下面的情况：p267 123456const double &amp; clone(double &amp; dref)&#123; double newguy; newguy = dref; return newguy; //返回newguy的引用，但是newguy在函数结束时会释放内存,会报错 return dref; //返回dref的引用，可行&#125; 前者可以编译，后者不可以。因为前者是指针，指向x，而后者是变量，是独立于x的副本。指针和副本都会在函数结束时释放，但是x并不会释放。p268 1234567891011#include &lt;iostream&gt;using namespace std;const int &amp; clone(int &amp; x)&#123; //可以编译 int *y = &amp;x; return *y;&#125;const int &amp; clone(int &amp; x)&#123; //不可以编译 int y = x; return y;&#125; 将C-风格字符串用作string对象引用参数，形参类型为const string &amp;时，实参类型可以为char*, const char*, string等（“abc”类型为const char*）。原因如下：p270 string类定义了一种char*到string的转换功能，这使得可以使用C-风格字符串来初始化string对象 const引用形参具有创建临时变量的属性。因此，当类型不符合时，会创建临时变量 对象、继承和引用： 除了可以使用父类的方法外，继承的另一个特征是，基类引用可以指向派生类对象，而无需进行强制类型转换。这种特征的实际结果是，可以定义一个接受基类引用作为参数的函数，调用该函数时，可以将基类对象作为实参，也可以将派生类对象作为实参。p271 使用引用参数两个主要原因： p274 程序员能够修改调用函数中的数据对象; 通过传递引用而不是整个数据对象，可以提高程序的运行速度。 指导原则： p274 对于使用传递的值而不作修改的函数 如果数据对象很小，如内置数据类型或小型结构，则按值传递; 如果数据对象是数组，则使用指针，因为这是唯一的选择，并将指针声明为指向const的指针; 如果数据对象是较大的结构，则是用const指针或const引用，以提高程序的效率。这样可以节省复制结构所需的时间和空间; 如果数据对象是类对象，则是用const引用。传递类对象参数的标准方式是按引用传递。 对于修改调用函数中的数据的函数 如果数据对象是内置数据类型，则是用指针; 如果数据对象是数组，则只能使用指针; 如果数据对象是结构，则使用引用或指针; 如果数据对象是类，则使用引用。 默认参数 对于带参数列表的函数，必须从右向左添加默认值。（即带默认值的参数的右边所有参数都要有默认值）。p275 12int harpo(int n, int m=4, int j=5); //validint chico(int n, int m=6, int j); //invalid 实参按从左到右的顺序一次被赋给相应的形参，而不能跳过任何参数。（这点与python不同） p275 123beeps = harpo(2); //same as harpo(2,4,5)beeps = harpo(1,8); //same as harpo(1,8,5)beeps = harpo(3, ,8); /invalid 函数重载 “多态”指的是函数有多种形式，“重载”指的是可以有多个同名的函数。二者指的是一回事 。p276 函数重载的关键是函数的参数列表——函数特征标（function signature）。如果两个函数的参数数目和类型相同，同时参数的排列顺序也相同，则它们的特征标相同，而 参数变量名是无关紧要的 。p277 编译器在检查函数特征标时，将把 类型引用和类型本身视为同一个特征标 。如以下两个看起来不同的特征标是不能共存的(它们都接受同一个参数x，会使得程序具有二义性)：p277 12double cube(double x);double cube(double &amp;x); 函数重载只看特征标是否相同，不关心函数返回类型。p278 当传入参数类型可以被强制转换时，将调用最匹配的版本：p278 123456void staff(double &amp; rs); // matches modifiable lvaluevoid staff(const double &amp; rcs); //matches rvalue, const lvaluevoid stove(double &amp; r1); // matches modifiable lvaluevoid stove(const double &amp; r2); //matches const lvaluevoid stove(double &amp;&amp; r3); //matches rvalue 名称修饰： C++通过名称修饰（name decoration）或名称矫正（name mangling）来区分重载函数，它会根据函数原型中指定的形参类型对每个函数名进行加密。p289 函数模板 函数模板是通用的函数描述，它们使用泛型来定义函数。模板并不创建任何函数，而只是告诉编译器如何定义函数。在标准C++98添加关键字typename之前，C++使用关键字class来创建模板。p281 12345678//如果需要多个将同一种算法用于不同类型的函数，可以使用模板template &lt;typename AnyType&gt; //注意没有分号;void Swap(AnyType &amp;a, AnyType &amp;b)&#123; //可以交换多种类型 AnyType temp; temp = a; a = b; b = temp;&#125; 函数模板不能缩短可执行程序。对于以不同类型多次调用模板的程序来说，最终仍然会生成多个独立的函数定义，就像以手工方式定义一样。 最终的代码不包含任何模板，而只包含了为程序生成的实际函数。p283 重载的模板： 被重载的模板的函数特征标必须不同：p283 1234template &lt;typename T&gt;void Swap(T &amp;a, T &amp;b);template &lt;typename T&gt;void Swap(T *a, T *b, int n); 显式具体化： （具体机制随着C++的演变而不断变化，下面是ISO/ANSI C++标准）p286 对于给定的函数名，可以有非模板函数、模板函数和显式具体化模板函数以及它们的重载版本。 显式具体化的原型和定义应以template&lt;&gt;打头，并通过名称来指出类型。 具体化优先于常规模板，而非模板函数优先于具体化和常规模板。12345struct job&#123;...&#125;;void Swap(job &amp;, job &amp;); //非模板函数template &lt;typename T&gt;void Swap(T &amp;, T &amp;); //模板函数template &lt;&gt; void Swap&lt;job&gt;(job &amp;, job &amp;); //显式具体化 实例化和具体化： 在代码中包含函数模板本身并不会生成函数定义，它只是一个用于生成函数定义的方案。编译器使用模板为特定类型生成函数定义时，得到的是模板实例（instantiation）。也就是说，模板并非函数定义，模板实例才是函数定义。p288 隐式实例化和显式实例化： p288 隐式(implicit)：通过函数调用导致编译器生成模板实例（大多数情况下都是隐式） 显示(explicit)：直接命令编译器创建特定的实例，方法如下：1template void Swap&lt;int&gt;(int, int); //explicit instantiation 显式实例化和显式具体化的区别： p288 显式实例化：使用Swap()模板来生成int类型的函数定义 1template void Swap&lt;int&gt;(int, int); //explicit instantiation 显式具体化(explicit specialization)：不要使用Swap()模板来生成函数定义，而应使用专门为int类型显式定义的函数定义。这些原型必须有自己的函数定义。 12template &lt;&gt; void Swap&lt;int&gt;(int &amp;, int &amp;);template &lt;&gt; void Swap(int &amp;, int &amp;); //这两句声明等价，任选其一 警告： 试图在同一个文件（或转换单元）中使用同一种类型的显式实例化和显式具体化将出错。 隐式实例化、显式实例化和显式具体化统称为具体化（specialization）。 它们的相同之处在于，它们表示的都是使用具体类型的函数定义，而不是通用描述。p289 重载解析（overloading resolution）： 对于函数重载、函数模板和函数模板重载，C++需要（且有）一个定义良好的策略，来决定为函数调用使用哪一个函数定义，尤其是有多个参数时。该策略大概过程如下：p289 第一步：创建候选函数列表。其中包含与被调用函数的名称相同的函数和模板函数。 第二步：使用候选函数列表创建可行函数列表。这些都是参数数目正确的函数，为此有一个隐式转换序列，其中包括实参类型与相应的形参类型完全匹配的情况。 第三步：确定是否有最佳的可行函数。如果有，则使用它，否则该函数调用出错。 匹配顺序： p290 完全匹配，但常规函数优先于模板。 提升转换（如，char和shorts自动转换为int，float自动转换为double）。 标准转换（如，int转换为char，long转换为double）。 用户自定义的转换（如，类声明中定义的转换）。 完全匹配与最佳匹配 完全匹配不等于最佳匹配，通常，有两个函数完全匹配是一种错误，但这一规则有两个例外。即有时候，即使两个函数都完全匹配，仍可完成重载解析。p290 指向非const数据的指针和引用，优先与非const指针和引用参数匹配。 下面两个式子都是完全匹配，但程序会选择前者，而不是报错： 1234567891011void recycle(blot &amp;); //#1void recycle(const blot &amp;); //#2struct blot &#123;int a; char b[10];&#125;;blot ink = &#123;25,&quot;spots&quot;&#125;;recycle(ink); //选择#1，因为ink没有被声明为const//然而，const和非const之间的区别只适用于指针和引用指向的数据//即，如果是如下定义，则将出现二义性错误void recycle(blot);void recycle(const blot); 两个完全匹配的函数，一个是非模板函数，另一个不是。此时，非模板函数将优先于模板函数（包括显式具体化）。如果两个完全匹配的函数都是模板函数，则较具体的模板函数优先。 C++98新增的特性—— 部分排序规则（partial ordering rules） 可以找出最具体的模板。 8.5小节涵盖的知识点很多，并且由于篇幅原因，没有详细展开，需要多看。]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机视觉面试问题汇总]]></title>
    <url>%2Fz_post%2F%E9%9D%A2%E8%AF%95-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[谈谈你参加的比赛对于一个比赛任务, 我会首先进行预处理, 之后, 会根据数据集的数据分布来对参数进行调整, 比如, 先只训练顶层, 然后逐步放开, 最后再训练所有层的参数. 在训练的时候,我一般都会采用bagging的思想, 将训练集随机28分, 分成3份, 然后训练, 最后进行模型融合, 融合的时候我一般都是对训练结果进行融合. 如果是目标检测累任务, 那么就:… 如果是实力分割类任务, 那么就: (对于一个新任务,) 你一般都会使用那些数据预处理方法 训练数据可视化 首先, 不论是什么样的数据集, 我都会先随机挑选 20 到 100张 的训练数据, 然后根据标签, 将图片数据可视化出来, 比如说如果是目标检测的任务, 我就会用opencv 的cv2.rectangle() 函数和 cv2.putText() 函数将标签里面的bbox标签和类别标签画到图片上去, 并且建立一个字典结构, 将不同的class-id对应到不同的颜色, 如果是实力分割任务, 我就会将mask标签反应到图片上去, 一般就是先将单通道的mask扩展成多通道的, 同时根据不同的class-id赋予不同的颜色, 最后利用numpy的where方法和原始图片进行叠加. 一般对于这种几十张的smaple图片, 我都是直接保存, 这样以后想再看的时候也不用重新跑脚本了. 之后, 我就会先简单浏览一下这些数据, 对整个数据集有一个初步的把握, 大概知道哪些物体被标注了, 有时候也能发现很多标注存在问题, 不过这也没有办法, 毕竟标注是一个很费时费力的工作, 错误在所难免. 计算数据分布信息 然后我就会写个脚本对整个数据集和标签进行遍历, 统计一些信息, 通常我会检测这么几个信息: 图像的平均尺寸, 整个数据集的像素平均值, 每张图片平均包含的目标个数, 每个类别的目标个数以及目标的平均大小, 同时, 因为平均值有时候往往反应不出来太多信息, 所以我还会用matplotlib把每种信息的直方图画出来, 然后看一下数据的整体分布是什么样子的, 比如图片size的分布, 目标大小的分布等等, 我主要就是根据这些分布信息来决定我最开始的参数设置. 主要调的参数就是imagesize,anchors相关的参数, 其他的还有就非极大抑制和置信度的阈值, 有时候还会试一下BN的作用(默认是关闭的) 然后一般情况下我都会对数据集做增广 常用的就是裁剪, 反转, 虚化, 颜色变换等等, 增广我不会做太多, 一般就用一些常用的增广方法 神经网络参数初始化分类问题为什么用交叉熵典型错误答案1: 如果用交叉熵，能保证神经网络训练时是一个凸优化问题 错误原因: 凸函数的复合并不一定是凸函数 典型错误答案2: 如果当前值与目标值相差很远，则梯度下降法迭代时收敛的更快一些 错误原因: 欧式距离(平方损失)也能起到这个作用, 为什么不用? 正确答案: Cross-Entropy vs. Squared Error Training: a Theoretical and Experimental Comparison. Relu和Dropout都具有正则化作用, 它们在正则化方面的区别是什么?Relu是强制正则化(所有神经元的输出值, 只要小于0, 就置为0) Dropout是随机正则化(随机让一些神经元的不起作用) 明日学习二叉树后续非递归遍历 完善右值引用 ZeroTensor你的项目和tiny dnn有什么区别。比它优势在哪里？你从tiny dnn这个项目中学到了什么？anchor的参数设值怎么选的？ 为什么这么设置在调试RPN网络时有没有遇到什么问题？简述一下faster rcnn模型简述一下ResNet模型及它解决的问题简述一下BN首先标准化就是将数据归一到一个希望的区间内, 一般都是归一化到激活函数敏感区域内, 而BN和传统标准标准化的区别主要有两点: BN是在每一个batch上做标准化的, 并且不仅仅只对输入层数据做标准化, 对网络内部的隐藏层输入也会进行标准话 第二就是BN并不是在标准的减均值初标准差之后, 还会进行一个线性变换,其本质就是改变数据分布的方差和均值. 对应的两个参数是通过学习学出来的. 其主要思想是考虑到数据可能本身就具有一定的不对称性, 并且激活函数也不一定就在面对标准数据时才有最好的表现, 因此 关于BN的详细解析可以看: 在点石竞赛上，使用了有哪些提升最终精度的方法各种初始化方式，及公式各个参数对训练的影响目标检测，数据不平衡问题怎么解决你的zerotensor和TF比性能上有优势吗常用的数据增强技术水平或垂直翻转图像、裁剪、色彩变换、扩展和旋转 有哪些可以避免过拟合的办法数据增强, 正则化, 模型融合(其中dropout是模型融合方法中最高效和常用的技巧) 为了防止过拟合，增加训练样本是一个好的解决方案。此外，还可使用数据增强、L1 正则化、L2 正则化、Dropout、DropConnect 和早停（Early stopping）法等 正则化L1和L2的区别rcnn。。在多线程和大量并发环境下，如果有一个平均运行一百万次出现一次的bug， 你如何调试这个bug。解决Bug，第一步就是重现，第二步定位以及Reduce，第三步再来解。所以，不管百万次还是十万次，首先要重现出来，然后找出重现出来的计算机状态。计算机不会欺骗人，每一个问题出来肯定是有原因的，唯一要做的就是如何把这个计算机状态信息还原出来，你可以使用log跟踪等，怎么纪录还原都是工程师的选择。而若能把相关的状态信息拿到，剩下的就是定位是哪里的问题，而这时候最好的就是模拟和Reduce，把问题缩小，排除其它信息干扰。模拟与Reduce成功以后，再想办法解决，然后再来估计解决问题的难度与成本问题等，有些BUG我们是知道，但是解决太麻烦了，影响也不大，就放着。 作者：蓝色链接：https://www.zhihu.com/question/43416744/answer/95944740来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 另一方面，从管理上应该要考虑 bug 的严重性与成本／时间的问题。如果最终能找出问题，需要研究怎样防范相似的 bug。 这个bug很难重现，这个时候你要怎么处理或者重现呢。有一个类指针，指向类实例化的对象，在这个对象程序的运行过程中，程序崩溃了，后来发现是这个类指针的虚函数表被破坏了，现在如何定位这个问题。需要先限定编译器和环节，比如，virtual table 在 Linux 下 GCC 4.9 的实现就是放在read only 段 .rodata，怎么可能被修改？好，就算可以被修改，我第一反应就是上GDB与Valgrind，被破坏的原因很多，你不让我调，我怎么跟你继续说下去，不如直接给我代码，我调给你看？ 那你首先准备一个这样的代码？ 作者：蓝色链接：https://www.zhihu.com/question/43416744/answer/95944740来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 如果商汤/face++和我们公司同时给了你offer, 你会怎么选择从三个方面选择-- 薪资 三个方面的权重分别是 4:4:2 说说你的职业规划技术总结擅长 C++、Python 编程语言算法基础扎实，具有良好的代码风格和质量意识对CNN 等深度学习技术了解透彻，擅长 TensorFlow 深度学习框架熟悉GPU并行计算及CUDA编程语言 自我评价代码工程能力强,可快速将想法付诸于代码实现, 对计算机技术充满热情，尤其是对计算机视觉领域，有极大的兴趣和求知欲，喜欢面对挑战，敢于尝试，有良好的沟通能力和团队合作精神 模型压缩cuda作者：oncecoder链接：https://www.nowcoder.com/discuss/23418来源：牛客网 面试官：看你简历上写熟悉CUDA，你能具体讲讲吗。 我：写过图片的resize,padding,卷积，提取hog特征等的gpu代码（kernel函数），效果还不错。 面试官问：具体说说怎么做到提升速度的。 我：把处理安排到gpu的每个thread上。 面试官：那看来你就相当于简单的利用了gpu的多核的特性？ 我一听感觉面试官不是很满意，于是扯了扯：还用了share_memory,const_memory等来提升速度，用了原子操作等来保证安全性。 面试官：你能讲讲使用shared memory为什么快吗？ 我：在某些应用场景下会快，一来和使用场景有关，讲了下哪些场景用这个会好一些，二来可能是硬件方面的原因吧，硬件原理方面的我也不清楚。 然后面试官从内存的金字塔结构，以及gpu的一些特性给我展开讲了很多，这个面试官感觉是gpu方面的行家，人非常好，感觉给我做了个讲座。。。 然后面试官问：你知道warp这个概念吗？ 我说知道，就是gpu底层同时执行的指令数量，现在一般是32.所以在写内核函数的时候，thread的数目最好是32的倍数。其他的不太清楚。 面试官好像点了点头，又给我balabala做了一次讲座。。。。 面试官问：假如要申请一大片空间，一次性申请这么大的，和分多次申请很多小的，但总数一样，哪个快，为什么。 我：在做项目的时候遇到过这种情况，前者会快很多，然后说了原因（答得不太标准，就不误导大家了） 面试官：其实cpu和gpu在这方面是一样的， 都会维护一个表什么的，记不太清楚了。 面试官：怎么看gpu使用情况。我：nvidia-smi(我用的是nvidia的卡) face++ 面经作者：一一后链接：https://www.nowcoder.com/discuss/119900来源：牛客网 一面（30分钟+ 撸项目（很细节，第一个项目每一步都要问为什么不用某个其他的方法） 讲讲adaboost和random frost的相同之处和不同，各自应用范围，实际应用选择 对SVM的理解，简单推导SVM，为什么要用对偶问题（二次规划+核化）具体讲一下为什么要核化，核化的过程 讲一下DL中目标检测的大类和特点（one stage、two stage）为什么two stage比one stage慢，为什么one stage比two stage精度高？one stage在哪些具体方面检测精度不高（ROI+default box的深层理解） 讲讲梯度消失问题及其应对方案（BN、Relu、初始化） 讲讲BN的细节（过程，公式，作用）为什么BN可以加快优化算法的速度 有什么问题 总结：问得很深入，基本都要非常理解才行，提到某个细节之后可能会深入问这个细节更细节的东西，千万别在回答的时候给自己挖坑。 二面：（40分钟+ 自我介绍；链表的倒数第k个结点（双指针） 应用场景题 抛一个不均匀的硬币，设计策略能得到1/2的概率（抛两次）如果要求得到1/3和2/3呢？设计策略（抛四次，我想着抛6次，小哥哥提醒了） 给出一个0到n的随机数生成器，设计策略，让不得到x的条件下，得到其他数的均匀分布（只能生成一次）（hash映射，但是我找不到合适的映射函数，小哥哥提醒了）扩展：不得到两个数呢？m个数呢？（一样） 房子500万，每年涨10%，程序员工资100万，不涨，问多少年能全款买房（几秒钟估算了一下，永远买不起…）（总觉得小哥哥在暗示我什么） 堆介绍，插入元素时调整的时间复杂度（变成二叉树，递归定义）堆排序、其他排序方法介绍和特点（按时间复杂度分了三种去介绍），最常用哪种 有什么问题（小哥哥建议多看些ML的实际场景（我其实想问智商怎么提升…） 总结：二面考基本功，数学算法和ML的熟练运用能力。 三面（院长大佬面）（挂） 自我介绍 用到深度学习的项目（大部分时间聊项目） 深度学习的前沿知识（最新的网络结构、精度最高的目标检测模型等） 有什么问题（大佬很委婉地劝我说他们主要收深度学习方向的…） 作者：jucic 链接：https://www.nowcoder.com/discuss/108078 来源：牛客网 CV岗： 一面： 用C++将一个类改造成线程安全的类 凸优化了解吗 SLAM里面闭环检测是什么怎么做 用深度学习做SLAM了解吗 兼职offer上一原题 交叉熵是什么 二面: 链表反转 快排 三面（院长面） 一直在聊项目 算法细节部分被怼的很厉害 某个函数只能随机产生0或1，利用这个实现一个函数能等概率的返回1-n之间的数，手撕实现代码 一个文件有一亿条整数数据，算一下占用多大磁盘，里面有几十个重复的数据，怎么找出来，内存占用不要超过本身的文件大小 推导svma) 概率是抽样的题目居多，计算正确，错误或者抽中没抽中的概率，与腾讯考察的要求差不多，但稍难其中一题，第一题，问试卷中的10道题，每到5个选项，如果瞎猜，每道题的数学期望是多少，如果每道题猜错的概率是92%，那么每道题的数学期望是多少？b) 计算甲乙两地距离的问题，甲乙分别从AB两地相向而行，甲乙速度比是常数，第一次相遇在距离甲地80KM处，分别到达对方起点后，再返回来相向而行，第二次相遇在距离甲地40KM处，计算甲乙两地相距多远的问题c) 研究基础，问到了RANSAC抽样的问题，将它与概率结合，抽取两个样本，抽取10次，问抽样概率d) ICCV会议2013与2015年分别是在哪里开的e) 选做题：写HOG的伪代码；关于图像模糊问题；问常见的跟踪方法有哪些，简述他们的优缺点，举一个近五年CVPR中流行的跟踪方法，写出它的思想 作者：牛客网链接：https://zhuanlan.zhihu.com/p/29695077来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 中国平安 - 实习生(上海/北京) 1.卷积正向和反向传播 2.Caffe源码 3.斐波那契 memcpy 4.pooling反向 5.项目介绍 6.override overload 纯虚函数等 阿里巴巴 - 2017.3.23 - 实习生 - idst - 非内推 1.linux 修改环境变量 2.sql语句 3.gbdt xgboost区别 4.kaggle项目 30min 5.融合方法，改进 阿里巴巴 - 2017.3.28 - 实习生 - 淘宝搜索 - 内推一面 1.项目介绍(30分钟)—项目过程，融合方法，训练方法，augmentation等 2.batch normalization 3.有没有了解其他机器学习算法 4.介绍一个熟悉的算法(决策树) 5.在线写线性回归 6.对深度学习框架有没有了解，还是只是停留在使用的层面 7.有没有什么想问的 阿里巴巴 - 2017.3.31 - 实习生 - 淘宝搜索 - 内推二面 1.项目介绍 2.kd-tree 3.开放问题 100w商品 50个推荐窗口，怎么安排推荐 腾讯 - 2017.4.10 - 实习生非内推 - 优图实验室 - 一面 1.项目介绍 2.计算卷积核参数数量 3.如何处理深度学习overfitting 4.如何在测试中，加速1000倍(不改变网络结构) 5.pooling层的作用，以及为什么会选择maxpooling 6.有没有从头开始训练一个模型 vgg16 resnet googlenet收敛问题 今日头条 - 2017.4.11 - 日常实习生非内推 - 一面 1.项目介绍 2.如何训练深度学习网络 3.如何处理样本分布不均衡的问题 4.手写代码-反转链表 5.手写代码-前序遍历 今日头条 - 2017.4.11 - 日常实习生非内推 - 二面 1.项目介绍（为什么不尝试xgboost以外的模型） 2.xgboost gbdt区别 3.深度学习训练方法 4.改进方法 5.caffe框架结构 6.手写代码-旋转数组找出最大数字 今日头条 - 2017.4.13 - 日常实习生非内推 - 三面 1.前两面反应较好，聊天 2.对前两个面试官有什么看法 3.有什么问题 #腾讯挺坑的，一面过了，二面面试官打电话确认了面试时间，收到了确认邮件，然后鸽了 腾讯游戏 - 校招内推 - 一面 1.实习介绍 2.介绍svm，为什么要求对偶 3.介绍一个熟悉的算法 4.全局变量 局部变量存储位置不同，静态变量初始化，生存周期 5.python多线程的实现，死锁 6.优化算法 sgd 牛顿法。为什么牛顿法快？及其缺点？ 网易 - 内推校招 - 人工智能事业部 - 一面 1.实习介绍 2.kaggle 深度学习项目介绍 3.几个框架对比 4.模型融合策略和方法 网易 - 内推校招 - 人工智能事业部 - 二面 1.项目介绍，讲你最好的项目 2.实习介绍 3.svm手推 4.kaggle融合的策略和方法 #前3面反映较好，加面 网易 - 内推校招 - 人工智能事业部 - special 加面 1.最好的项目介绍 2.batch normalization算法 3.实习经历 4.cnn现在发展以及不足 5.说对游戏ai感兴趣 - alphago的技术点，强化学习等 华为 - 内推校招 - 1,2,3面 #略 #Nvidia Deeplearning software 面试官很客气，提前定好这次面试时长40分钟 Nvidia - 内推校招 - 一面 1.项目介绍 30min 2.编程题2道 3.过拟合欠拟合 以及其背后本质，偏差方差角度如何理解 #Sensetime 商汤科技 每面30min #号称最难进公司之一？ Sensetime - 2017.9.11 - 校招内推 - 计算机视觉&amp;深度学习 - 一面 1.kaggle比赛 问的比较详细 包括 data augmentation， KNN的trick， 模型融合等 2.实习经历 3.有什么问题 Sensetime - 2017.9.11 - 校招内推 - 计算机视觉&amp;深度学习 - 二面 1.kaggle比赛 2.头条实习 3.python set-list转化 4.caffe框架结构，learning rate设置 5.第K大的数 6.sgd adam区别 7.resnet vgg区别 8.python 变量拷贝规则 9.有什么要问的 Sensetime - 2017.9.11 - 内推校招 计算机视觉&amp;深度学习 - 三面 1.头条实习 比较详细以及为什么头条推荐这么厉害 #面试官是在做dl+推荐，所以比较关心头条所做的东西 2.熟悉什么框架 3.喜欢什么方向，cv还是推荐等，以及个人认为他们的前景 4.学术型硕士还是工程型硕士？ 5.有什么问题 阿里巴巴 - 2017.9.13 - 校招 - 初面 1.头条实习 ——- 特征维度，为什么时延很低，在头条做了哪些，头条的算法 2.深度学习和传统机器学习 3.深度学习最近的发展和技术突破点 4.GBDT是什么 — 加法模型 5.为什么现在推荐可以使用GBDT的内部结点当做LR的特征 — 特征选择和子集评价，还是stack模型融合？ 6.RF GBDT区别 — 方差偏差理论，bagging&amp;boost区别 7.GBDT xgboost区别 —泰勒二阶，并行化，正则项 8.手写MergeSort 9.熟悉什么语言 10.用什么框架 11.深度学习正则化 12.GBDT分布式如何实现 #没有了解过，然后简单说了自己的想法，面试官给我讲了许多这方面 阿里巴巴 - 2017.9.15 - 校招 - 终面 1.头条实习 ——- 模型介绍 2.GBDT xgboost区别 3.kaggle比赛 4.一个整数数组中，寻找3个数乘积最大 5.GBDT与bagging等方法区别 6.linux常用指令 sort grep等 阿里巴巴 - 2017.9.15 - 校招 - 加面 #压力面？ 1.头条实习ffm替换skip gram模型，为什么？效果如何？为什么会有提速效果？线上如何部署等 2.头条所做？训练两个大模型，效果如何？ 3.kaggle比赛 4.vgg16 resnet googlenet区别 5.手写代码-旋转数组找出最小数字 #其余记不清了 大疆 - 2017.9.17 - 校招 - 初面 1.头条实习 2.kaggle项目 卷积层的参数计算公式是：输入的filers×kernerl size ×输出的filters。如： （3×3×256）×512 括号前面是每一个卷积核的大小，后面的是总共有512个卷积核 梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法详见梯度消失和梯度爆炸问题深入解析 关于各种激活函数的解析与讨论简述ResNet嵌入式开发很底层 一般还是倾向于做一些上层的东西推导SVM]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>知识点梳理</tag>
      </tags>
  </entry>
</search>
